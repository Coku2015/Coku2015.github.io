[{"categories":[],"content":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具 Vibe coding 非常火爆，Claude Code 和 Codex 打的异常激烈，感谢有这么好的 AI 工具，给我们数据保护和数据安全行业也带来了全新的能力和全新的想法。本期开始，我想给大家分享下，使用这些 AI 工具，能给我们的数据保护带来一些什么样的不一样的能力，近距离带大家看看 AI 给我们的行业带来的变化。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:0:0","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"什么是 Claude Code？ 鼎鼎大名 Claude Code，不用多说啦，https://code.claude.com/docs/en/overview 有兴趣可以看一下，网络上各大平台的介绍也很多，不仅有关于 AI 编程的，更有一些奇奇怪怪的用法的，像生活助理、博客写作、旅游助手等等。能做的事情就怕你想不到。 本文从零开始带大家看看，如何使用 Claude Code。我的目标并不是教大家如何 Vibe Coding 进行 AI 编程，而是想借着 Claude Code 这个工具给大家一些新的启示。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:1:0","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"基础环境准备 首先来看看环境准备，Claude Code 它是纯 CLI 形态的工具，和我们通常网页版的 AI 工具，比如 ChatGPT、Copilot 或者豆包等不太一样。因此在使用时，最好为它配上合适的编辑器，这样一边使用一边能观察它创建和修改的相关文件。在基础环境准备的时候，首先我会安装上一款比较好用的 AI 编辑器，我推荐使用 Cursor 编辑器，当然你可以选择任何你顺手的编辑器来使用。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:2:0","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"安装 Cursor 编辑器 我选 Cursor 开始，原因很简单：AI 集成做得好，界面跟 VS Code 几乎一样，不用重新学习。 这个编辑器同时支持 Windows、Linux 和 macOS，下载安装非常简单。 访问 Cursor.com 下载对应平台的版本 运行安装程序，一路 Next 完成安装 首次启动需要登录，可以注册个新账号登陆即可。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:2:1","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"环境依赖：Git 和 Node.js 安装 Claude Code 之前，要配置 Git 和 Node.js 环境，因此特别对于 Windows，需要手工去git网站下载 git 工具，然后去去Node.js 网站下载 Node.js 工具。对于 Linux 和 macOS，相对友好一些，安装 git 和 node.js 也都不太费劲，这里不在赘述。等待两个前置工具都安装成功之后，可以通过以下命令确认： $ git -v $ node -v $ npm -v 确认都安装完成后，有时候需要重启下 Terminal。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:2:2","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"安装和配置 Claude Code ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:3:0","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"安装 Claude Code 软件 环境准备好后，安装 Claude Code 就很简单了。打开任意一个 Terminal： npm install -g @anthropic-ai/claude-code 安装完成后验证： claude --version 首次运行需要登录：打开会提示登录 Anthropic 账号，这时候如果在国内使用，可能会碰到一些麻烦，不过不要紧，我今天的教程带大家更换一下 Claude Code 的大模型，我们就只使用 Claude Code 提供的 CLI 软件，它后台的大模型，我们切换成性价比更高，国内一流的 Coding 模型，智谱 AI 的 GLM-4.6 模型。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:3:1","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"注册 GLM-4.6 智谱 AI 国庆期间，发布了它的全新旗舰 Coding 模型 - GLM-4.6。根据各大媒体和国内外用户评测，它的 Coding 能力已经和 Claude Code 官网的非常接近了，但是其价格却是只要 Claude Code 的 1/7，并且新用户注册，还赠送免费的 Token 体验包，大家扫码注册就能直接领取赠送的 2000 万 Token 体验包了。 另外，通过我上面这个扫码激活 Coding Plan，还能再折 10%，这个简直白菜价了，每月低至 18 元。Token 的使用量来说，我自己体验下来，是基本上没碰到过 5 小时的 Limit。这里我推荐先上手试用 GLM Coding Lite 20 元的第一个月订阅，当第一个月结束之后，如果还想继续，可以接着取消续订后，选择 3 个月 60 元档的继续优惠订阅，最后一个是一年 240 元的优惠订阅，基本上这样一年多下来，都是在每月 18 元这一档使用，单价远比 Claude Code 原版的$20/月的大模型便宜，但是分量更足。 注册完成后，可以在网页上找到主页右上角的 API Key，从里面可以找到自己的 API Key，一会儿我们需要用这个来 Claude Code 中进行配置，为 Claude Code 更换“🧠大脑”。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:3:2","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"为 Claude Code 配置 GLM 4.6 这个配置页非常简单，GLM 4.6 官网手册清清楚楚的写具体配置方法。具体可以查看以下网站： https://docs.bigmodel.cn/cn/coding-plan/tool/claude 在这个网站说明里，甚至给出了自动化配置的脚本，不想自己修改的同学可以直接运行脚本解决。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:3:3","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"创建并配置项目文件夹 接着我们开始使用 Claude Code，我们通常会在某个工作目录下进行 Claude Code 的 coding 操作，因此我们需要打开 Cursor，并指定工作目录。在 Cursor 中，打开一个项目文件夹，同时激活下 Cursor 中的 Terminal，在 Terminal 中输入 Claude，即可进入 Claude Code 的主界面，如下图： ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:3:4","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"下一步 除了 GLM - 4.6 之外，国内还有不少优秀模型，比如 Kimi K2 等，但是性价比就和 GLM - 4.6 差远了。大家有兴趣可以自行探索以下。 基础环境到这里就搭建完了，这样我们就可以在 CLI 界面和 AI 进行直接对话了，因为具备了操作文件和运行本地程序的权限，Claude Code 几乎能干任何电脑上的事情，查询任何我们想要让他查询的信息，因此它能做的事情是非常多的，在下一期开始，我将以一个 VBR 项目为例带大家看看如果使用 Claude Code 帮我执行各种命令。 ","date":"2025-11-11","objectID":"/2025/11/AI-Reshapes-Data-Protection-01/:4:0","tags":["Backup","AI","Veeam","Vibe Coding"],"title":"AI 重塑数据保护：Claude Code + GLM-4.6 实战，从零搭建 AI CLI 工具","uri":"/2025/11/AI-Reshapes-Data-Protection-01/"},{"categories":[],"content":"我们在之前的文章中介绍了 Veeam v13 版本继续加强了 YARA 恶意软件扫描功能，但官方规则库有限的问题很现实。互联网上免费的 YARA 规则源本来就不多，质量好的更是稀缺。今天给大家推荐一个宝藏网站：Ransomware.live - 一个专业的开源勒索软件威胁情报平台，它提供 62 个主流勒索软件团伙的免费 YARA 规则，正好可以作为 Veeam YARA 扫描功能的绝佳补充。 ","date":"2025-11-10","objectID":"/2025/11/veeam13-security-features-03/:0:0","tags":["Backup","Security","Veeam"],"title":"Veeam YARA 扫描的免费规则库 - Ransomware.live 实战指南","uri":"/2025/11/veeam13-security-features-03/"},{"categories":[],"content":"认识 Ransomware.live：专业的勒索软件威胁情报平台 Ransomware.live 是由安全专家 Julien Mousqueton 维护的开源威胁情报平台，专注于勒索软件攻击的实时监控和分析。平台跟踪 297 个攻击团伙，记录超过 23,126 个受害者案例，最核心的价值是提供了 62 个主流勒索软件团伙的专业 YARA 规则库。 平台核心功能： 实时攻击监控- 跟踪全球勒索软件攻击活动，显示 297 个攻击团伙、23,126+ 个受害者案例例 攻击统计 - 按时间、地域、行业维度分析勒索软件趋势 团伙档案 - 详细记录各个勒索软件团伙的攻击特征和历史活动 受害者数据库 - 可搜索的受害者信息，便于威胁关联分析 YARA规则库 - 按勒索软件团伙分类的检测规则，支持直接下载 这些规则由安全专家基于真实攻击样本编写，质量远超通用检测规则。Ransomware.live 的 YARA 页面能够查看并手工获取相关的 YARA 规则。有需要的用户可以按需查找相关规则。 除了手工获取之外，平台还提供 Pro API 服务，对于需要自动化批量下载的 Veeam 用户来说，Pro 版本的结构化 API 接口服务特别实用，我们只需要通过 Get your free API Key 服务获取相关下载 API key 即可。 ","date":"2025-11-10","objectID":"/2025/11/veeam13-security-features-03/:1:0","tags":["Backup","Security","Veeam"],"title":"Veeam YARA 扫描的免费规则库 - Ransomware.live 实战指南","uri":"/2025/11/veeam13-security-features-03/"},{"categories":[],"content":"Pro API：自动化 YARA 规则获取 对于有规则需要离线使用的用户，我为大家提供了一个一键下载所有规则的脚本，专门为 Veeam 用户设计，能够自动下载所有 62 个团伙的 YARA 规则文件。脚本使用 jq 解析 JSON 响应，自动处理文件命名和验证，还包含详细的下载日志。 ","date":"2025-11-10","objectID":"/2025/11/veeam13-security-features-03/:2:0","tags":["Backup","Security","Veeam"],"title":"Veeam YARA 扫描的免费规则库 - Ransomware.live 实战指南","uri":"/2025/11/veeam13-security-features-03/"},{"categories":[],"content":"完整自动化下载脚本 #!/bin/bash # Ransomware.live YARA规则全自动下载脚本 set -e set -o pipefail # 用户配置 TARGET_DIR=\"./yara_rules\" API_KEY=\"your-api-key-here\" API_BASE=\"https://api-pro.ransomware.live\" # 创建目录 mkdir -p \"$TARGET_DIR\" LOG_FILE=\"${TARGET_DIR}/download_$(date +%Y%m%d_%H%M%S).log\" log() { echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$LOG_FILE\" } # 检查工具 if ! command -v jq \u003e/dev/null 2\u003e\u00261; then echo \"需要安装jq: sudo apt-get install jq 或 brew install jq\" exit 1 fi log \"开始下载Ransomware.live YARA规则...\" # 获取所有团伙YARA规则 API_RESPONSE=$(curl -s -H \"X-API-KEY: $API_KEY\" \"$API_BASE/yara\") if ! echo \"$API_RESPONSE\" | jq -e '.groups' \u003e/dev/null 2\u003e\u00261; then log \"API响应异常，请检查API密钥\" exit 1 fi # 批量下载规则 echo \"$API_RESPONSE\" | jq -r '.groups[].group' | while read -r group; do if [ -n \"$group\" ]; then log \"下载: $group\" YARA_RESPONSE=$(curl -s -H \"X-API-KEY: $API_KEY\" \"$API_BASE/yara/$group\") if echo \"$YARA_RESPONSE\" | jq -e '.rules[0]' \u003e/dev/null 2\u003e\u00261; then YARA_CONTENT=$(echo \"$YARA_RESPONSE\" | jq -r '.rules[0].content') FILENAME=$(echo \"$YARA_RESPONSE\" | jq -r '.rules[0].filename') if [ -n \"$YARA_CONTENT\" ] \u0026\u0026 [ \"$YARA_CONTENT\" != \"null\" ]; then OUTPUT_FILE=\"${TARGET_DIR}/${FILENAME:-${group}.yar}\" echo \"$YARA_CONTENT\" \u003e \"$OUTPUT_FILE\" if [ -s \"$OUTPUT_FILE\" ] \u0026\u0026 grep -q \"^rule \" \"$OUTPUT_FILE\"; then RULE_COUNT=$(grep -c \"^rule \" \"$OUTPUT_FILE\") log \"✓ $(basename \"$OUTPUT_FILE\") (${RULE_COUNT}条规则)\" else log \"✗ 文件无效: $group\" rm -f \"$OUTPUT_FILE\" fi fi fi sleep 0.5 fi done log \"下载完成！规则文件保存在: $TARGET_DIR\" ","date":"2025-11-10","objectID":"/2025/11/veeam13-security-features-03/:2:1","tags":["Backup","Security","Veeam"],"title":"Veeam YARA 扫描的免费规则库 - Ransomware.live 实战指南","uri":"/2025/11/veeam13-security-features-03/"},{"categories":[],"content":"脚本使用方法 环境准备 # 安装必要工具 sudo apt-get install curl jq # Ubuntu/Debian # 或 brew install curl jq # macOS 配置脚本 # 修改 TARGET_DIR 为你的目标目录 # 修改 API_KEY 为你的实际 API 密钥 chmod +x download_yara_rules.sh 运行脚本 ./download_yara_rules.sh 脚本特性： 一键下载所有 62 个勒索软件团伙的 YARA 规则，如果后续有新的规则更新，本脚本也能同样一键获取相关更新规则。 自动处理文件命名和格式验证 详细的下载日志和错误处理 支持自定义下载目录 ","date":"2025-11-10","objectID":"/2025/11/veeam13-security-features-03/:2:2","tags":["Backup","Security","Veeam"],"title":"Veeam YARA 扫描的免费规则库 - Ransomware.live 实战指南","uri":"/2025/11/veeam13-security-features-03/"},{"categories":[],"content":"Veeam 集成部署方法 规则下载完成后，可以通过 VBR console 上传和导入。 来到 VBR console 中，打开下方的三个点，激活 Files 窗口 在 Files 窗口中，能看到当前 Console 所在的 Windows 的文件夹和 VBR Server 的文件夹。 从当前电脑的 YARA 规则存放路径中，选中所有需要拷贝的规则，右键点击 Copy 按钮。 来到 VBR Server 的 yara_rules 目录，右键菜单选择 Paste 按钮 稍等片刻后，yara 规则文件就会被传输到 vbr 服务器上。 找任意一个备份存档，选中 Scan backup 操作，能够在 YARA 下来菜单中实时看到规则名称，选取作为扫描规则即可。 ","date":"2025-11-10","objectID":"/2025/11/veeam13-security-features-03/:3:0","tags":["Backup","Security","Veeam"],"title":"Veeam YARA 扫描的免费规则库 - Ransomware.live 实战指南","uri":"/2025/11/veeam13-security-features-03/"},{"categories":[],"content":"总结 Ransomware.live 作为免费开源的威胁情报平台，为 Veeam 用户提供了零成本的 YARA 规则增强方案。目前已包含 62 个专业级勒索软件检测规则、持续更新的威胁情报、再加上自动化下载工具，这套组合让 Veeam v13 的恶意软件检测能力有了质的提升。配合免费的 Pro 版本的 RestAPI 和我的自动下载脚本，能够实现全自动的规则更新。 实际应用建议： 定期更新：建议每周执行一次，保持威胁情报最新 测试验证：先在测试环境验证新规则的检测效果 监控日志：关注下载成功率和文件有效性，如果有可能，可以进行人工核对 面对日益复杂的勒索软件威胁，这种免费但专业的威胁情报源值得每个 Veeam 用户关注和使用。通过合理配置 Ransomware.live 的 YARA 规则，可以显著提升 Veeam 环境对勒索软件的检测和防护能力。 ","date":"2025-11-10","objectID":"/2025/11/veeam13-security-features-03/:4:0","tags":["Backup","Security","Veeam"],"title":"Veeam YARA 扫描的免费规则库 - Ransomware.live 实战指南","uri":"/2025/11/veeam13-security-features-03/"},{"categories":[],"content":"v13 版本，恶意软件检测功能实现了重要的能力跃升。相比 v12 时代已经具备的实时检测能力，v13 在威胁响应机制、平台覆盖范围和智能化程度上都有了质的改进。在我之前的文章中，已经详细介绍了 v12 的勒索攻击侦测原理和配置方法，今天我们在此基础上，看看 v13 带来了哪些关键的升级。 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:0:0","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"v12 检测能力回顾：检测与响应的分离 在 v12 时代，Veeam 的恶意软件检测主要依赖两种机制： Inline Entropy Scan - 备份过程中实时分析数据块的熵值变化，检测加密行为 Index Scan - 通过文件系统索引分析异常行为模式 这两个功能的特点是检测归检测，处理归处理 - 系统能够实时检测威胁，但响应过程需要人工干预。在 v12 版本的实际使用中，这种机制存在几个明显的局限性： 响应自动化程度低：检测到可疑活动后主要依赖管理员手动处理 平台支持有限：检测能力主要集中在 Windows 环境 深度分析不足：检测到威胁后缺乏进一步的威胁分析能力 v13 在这一检测能力上，我认为有了长足的进步，开始从\"检测\"向\"智能响应\"的进化。 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:1:0","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"V13 主动响应机制：从检测到自动防护 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:2:0","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"Proactive investigation：加强的威胁验证手段 v13 最重要的改进是引入了主动备份扫描机制。这个功能的核心思路是：一旦在备份过程中检测到可疑活动，系统会立即触发更深入的签名扫描，而不是等待用户人工做其他判断。 软件中的设置： 打开 VBR 控制台，进入左上角 Hamburger 菜单 → Malware Detection Setting 在原有的 Signature Detection 设置中，v13 新增了 Proactive investigation 选项： 第一个复选框为启用主动扫描机制，第二个选项则进一步处理，它允许系统根据扫描结果自动解决恶意软件事件。 实际使用效果： 在一个模拟的勒索攻击测试环境中，当备份作业检测到文件被大规模加密时： v12 检测到恶意软件：标记备份为 Suspicious，发送告警，等待管理员处理 v13 检测到恶意软件：立即触发签名扫描，确认威胁后直接标记为 Infected 或者没有威胁重新标记为 Clean。 我在 v12 时，经常听到有客户发现了 Veeam 报告备份存档是 Suspcious 状态后无从下手，不知道咋回事发生了什么，现在有了 v13 的这个选项后，我们可以无需等待，立刻由 Veeam 触发检测，真正找到是否存在问题。 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:2:1","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"跨平台统一防护：Linux 和云环境不再是被遗忘的角落 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:3:0","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"Linux 环境的全面支持 v13 另外一个突破是恶意软件检测功能在 Linux 平台的全覆盖，我认为这也是全面支持 Linux 环境的一个重要部分。 Linux 支持的检测能力： 可疑文件系统活动分析- 与 Windows 平台相同的检测逻辑辑 Veeam Threat Hunter 扫描 - 基于签名的恶意软件检测 YARA 规则支持 - 自定义威胁检测规则 实战配置要点： 对于 Linux 环境的恶意软件检测，需要注意几个特殊配置： 文件系统选择：某些文件系统（如 Btrfs、ZFS）的特殊特性可能影响检测准确性 权限管理：确保备份代理有足够权限读取所有需要检测的文件 性能影响：在资源受限的 Linux 环境中，可能需要调整检测频率 具体操作步骤： 对于基于 Agent 的 Linux 备份，恶意软件检测的配置与 Windows 环境基本一致，主要通过 VBR 控制台的 Malware Detection 设置进行全局配置，然后在具体的备份作业中启用相关功能。 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:3:1","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"云端备份的安全防护 随着越来越多的用户使用公有云，云环境的安全也变得至关重要。v13 将恶意软件检测能力扩展到云端备份： 支持的云平台： Veeam Backup for Microsoft Azure Veeam Backup for AWS Veeam Backup for Google Cloud 具体使用和配置，包括支持的能力，基本上和 Linux 都一致，不在赘述。 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:3:2","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"Linux 挂载服务器的杀毒集成 v13 中支持 Linux Server 作为 Mount Server，这可是一个全功能的 Mount Server，在 Windows Mount Server 上的 Secure Restore 和 Security Scan 能力同样扩展到了 Linux Mount Server 上，并且同样支持 Veeam Threat Hunter 进行签名扫描： 已宣布支持的 Linux 版本的杀毒软件： ClamAV - 开源免费，适合预算有限的环境 ESET - 商业解决方案，检测能力强 Sophos - 企业级防护，管理界面友好 配置示例： 以 ClamAV 为例，需要在 Linux 挂载服务器上安装 ClamAV，然后在 VBR 控制台的 Backup Infrastructure → Mount Servers 中选择相应的 Linux 服务器。使用的时候，从 scan backup 或者 Secure restore 都可以调用到杀毒软件进行扫描。 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:3:3","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"总结与建议 v13 的恶意软件检测功能是一个质的飞跃，从原来的被动检测进化到了主动防护。在实际部署中，有几点建议： 循序渐进：先在测试环境验证所有新功能，再逐步推广到生产环境 性能监控：密切监控新功能对备份性能的影响，必要时进行调整 策略优化：根据业务特点定制检测策略，避免一刀切的配置 定期演练：定期进行恶意软件检测演练，确保响应流程的有效性 v13 的这些改进让我们看到了备份系统在整体安全架构中的新定位 - 不再只是数据的被动保护者，而是主动的安全防线参与者。在实际使用中，合理配置这些功能，能够显著提升组织应对勒索攻击等现代威胁的能力。 ","date":"2025-11-07","objectID":"/2025/11/veeam13-security-features-02/:4:0","tags":["Backup","Security","Veeam"],"title":"V13 恶意软件检测全面升级：从被动防护到主动响应的实战进阶","uri":"/2025/11/veeam13-security-features-02/"},{"categories":[],"content":"关于我 “技术不是目的，理解与掌控复杂系统的能力，才是终极浪漫。” ","date":"2025-10-30","objectID":"/about/:0:0","tags":["about","profile","Lei Wei","数据保护","虚拟化","AI"],"title":"关于我","uri":"/about/"},{"categories":[],"content":"Lei Wei — 数据保护与云原生专家 🚀 深耕数据保护与云计算行业超过 15 年 🎯 现任 Veeam Software 中国区资深顾问级专家 📍 坐标：上海 | Global View · Engineering Mindset 🧩 本博客已连续更新 8+ 年 大家好，我是 Lei Wei，一名在 数据保护与云计算领域深耕十五年 的技术专家。 从虚拟化时代的 VMware / Hyper-V / KVM，到当下的 公有云与云原生容器生态，我始终活跃在基础架构与数据安全的最前线。 精通多云、混合云环境的数据保护与自动化体系设计，对 业务连续性、灾备架构、数据可用性 拥有丰富的实战经验。 🎓 拥有多项业界权威认证： 🟢 Veeam Certified Engineer 🟢 Veeam Certified Architect ☁️ AWS Certified Solutions Architect 🐳 Certified Kubernetes Administrator (CKA) 🐳 Certified Kubernetes Administrator Developer (CKAD) 🟢 Certified Cloud Security Professional (CCSP) 近年来，我专注于 Data + AI 与 AI + Security 的交叉研究，探索如何让人工智能赋能数据保护、威胁检测与智能化运维。 目前就职于 Veeam Software，担任中国区资深顾问级专家，致力于推动 企业级数据保护、云原生备份、AI 驱动安全防御体系 的落地与最佳实践。 🧭 本博客 是我职业生涯的记录本，也是思维的延伸空间。 持续更新 8 年，聚焦于数据保护、虚拟化、云原生、AI 与安全交叉领域的技术洞察与实践反思。 💬 “如果你热爱技术、崇尚实战、追求极致，这里就是你的共鸣空间。” ","date":"2025-10-30","objectID":"/about/:1:0","tags":["about","profile","Lei Wei","数据保护","虚拟化","AI"],"title":"关于我","uri":"/about/"},{"categories":[],"content":"联系我 💼 LinkedIn: https://www.linkedin.com/in/lei-wei-96727950/ 🌐 Blog: https://blog.backupnext.cloud/ 📧 Email: lei.wei@backupnext.cloud 我的证书 在 Credly 查看全部证书 “Build. Protect. Evolve. Repeat.” ","date":"2025-10-30","objectID":"/about/:2:0","tags":["about","profile","Lei Wei","数据保护","虚拟化","AI"],"title":"关于我","uri":"/about/"},{"categories":[],"content":"v13 版本，新增的功能中，最重要的是安全特性的加强。从本期开始，我会为大家通过实战应用的方式，详细介绍 v13 中推出的全新安全功能。 今天先来说说身份认证。在企业级备份架构中，管理控制台的账户安全与访问治理至关重要。Veeam Backup \u0026 Replication（VBR）在 v13 中支持基于 SAML 的单点登录（SSO），这意味着可以把身份认证集中到组织现有的身份提供者（IdP）——例如 Azure EntraID。通过 SAML 集成，你可以把 VBR 的登录与公司的账号生命周期、组策略、MFA 和审计统一管理：运维更加清晰，权限回收更及时，实现更高的合规性。本文以 Azure EntraID 为例，为大家详细展示这个集成的具体方法。其他类似方案，比如国内的 Authing 或者国外的 Okta 和 Auth0 大家可以自己按照 Azure 的方法试试看。 ","date":"2025-09-25","objectID":"/2025/09/veeam13-security-features-01/:0:0","tags":["Backup","Security"],"title":"让 VBR 登陆更安全：v13 版本 SAML + Azure EntraID 集成全攻略","uri":"/2025/09/veeam13-security-features-01/"},{"categories":[],"content":"配置准备 要配置和使用 SAML 集成，前提条件非常简单，使用最新上线的 Veeam Software Appliance 安装 VBR 即可。当然因为使用网络服务，这时候配置 SSO 还是有些必要条件的： VBR 服务器必须能够访问 Azure 的 EntraID 的相关 endpoint。 时间同步，VBR 上必须正确配置 NTP 服务器，时间不能有偏差，SAML 是基于时间戳的，如果偏差会认证失败。 Azure EntraID 的管理员账号，要有创建企业应用和分配用户的权限。 VBR 管理员权限，这是配置 VBR 账号和身份集成的基础。 VBR Console 所在的 Windows 必须正确解析 VBR 的主机名或者 FQDN，否则 SP/IdP Metadata 里的 URL 对不上。 ","date":"2025-09-25","objectID":"/2025/09/veeam13-security-features-01/:1:0","tags":["Backup","Security"],"title":"让 VBR 登陆更安全：v13 版本 SAML + Azure EntraID 集成全攻略","uri":"/2025/09/veeam13-security-features-01/"},{"categories":[],"content":"配置方法 以下配置，分为 Azure 部分和 VBR 部分，并且有一定的顺序，因此推荐按顺序进行。 ","date":"2025-09-25","objectID":"/2025/09/veeam13-security-features-01/:2:0","tags":["Backup","Security"],"title":"让 VBR 登陆更安全：v13 版本 SAML + Azure EntraID 集成全攻略","uri":"/2025/09/veeam13-security-features-01/"},{"categories":[],"content":"在 VBR 中生成 SP 信息并导出 Metadata 首先用 veeamadmin 账号登入 VBR 控制台，在 VBR 中，打开左上角三条横线的汉堡图标，在下拉菜单中选择Users and Roles 切换到 v13 新增的 Identity Provider 界面，默认情况下，这里的Enable SAML Authentication处于未被选中的状态，勾选启用，然后在下面先看到 Service Provider（SP）Information 部分。在身份认证中，VBR 现在就相当于是应用程序的服务提供者（SP），因此我们在这里要先为 VBR 安装一个证书，点击 Install。 可以从本地的证书库中选择一个，选择Select an existing certificate from the certificate store，点击下一步。 在证书库中，找到 Friendly Name 为Veeam Backup Server Certificate的这个证书后，点击 Finish 完成。 此时，SP Information 部分会看到 Certificate 已经有信息出现了，CN=\u003c备份服务器FQDN\u003e。接下去的操作，我们需要点击 Install 下方的 Download 按钮，将 SP 这边的 xml 文件下载下来，保存好。这个文件会在稍后 Azure 那边配置时使用到。 ","date":"2025-09-25","objectID":"/2025/09/veeam13-security-features-01/:2:1","tags":["Backup","Security"],"title":"让 VBR 登陆更安全：v13 版本 SAML + Azure EntraID 集成全攻略","uri":"/2025/09/veeam13-security-features-01/"},{"categories":[],"content":"在 Azure EntraID 中上传 SP Metadata 并分配用户。 首先来为 VBR 创建一个安全组，命名为 VBR Users。并为这个组添加一个 User，比如我把我自己的账号加了进来。 在 EntraID 中，找到 Enterprise apps，我们需要为 VBR 的身份认证，创建一个新的 Application，点击New Application来创建。 在创建时，不要从 catalog 中选择，点击Create your own application然后在右边的弹框中，输入 app 名称，然后选择Integrate any other application you don't find in the gallery(Non-gallery),比如我的叫 vbrsso。 这个 Application 创建完成后，会自动转到 Application Overview 界面，上面的 Getting Started 界面已经清楚的列出了接下去的步骤。可以按照上面 1、2、3、4、5 的步骤根据需要逐个配置。对于 VBR 来说，我们只需要配置两个Assign users and groups和Set up single sign on。 将第一步中创建的 Group，VBR Users 分配给这个应用后，点击第二个步骤，Set up single sign on，会进入单点登陆的配置界面，在这里，我们选择 SAML 这个选项来和 VBR 集成。 进入 SAML 配置界面后，这里清晰的列出了 1-2-3-4 的步骤，然而我们不需要逐个去编辑这里的内容，只需要找到上方Upload metadata file，点击后将我们刚刚从 VBR 上导出的 xml 文件上传后保存，即可完成这里单点登陆的配置。上传后可以看到 Basic SAML Configuration 中 URL 已经被正确的更新成我的 VBR 的 FQDN 了。 接下去，找到上图中第三步中的 SAML Certificates 框里的最后一行，Federation Metadata XML 旁边的 Download 按钮，再从 Azure EntraID 中下载一份自动生成的 XML 文件。 至此，Azure 上的设置就全部完成了。 ","date":"2025-09-25","objectID":"/2025/09/veeam13-security-features-01/:2:2","tags":["Backup","Security"],"title":"让 VBR 登陆更安全：v13 版本 SAML + Azure EntraID 集成全攻略","uri":"/2025/09/veeam13-security-features-01/"},{"categories":[],"content":"回 VBR，更新配置 IdP 信息 还是回到 VBR 中 Users \u0026 Roles 下的 Identity Provider 界面，找到 Identity Provider（IdP）Information 设置，这是单点登陆中身份提供商的信息，也就是 Azure EntraID 来作为这个身份提供商。点击旁边的 Browse，上传刚刚从 Azure 中下载下来的 XML 文件。上传完成后，会看到下面所有 IdP 的信息已经正确更新成微软的网址了。 点击 OK 完成设置后，我们就可以重新再打开Users and Roles，来增加 User 了。点击Add...后，会出现External user or group的选项，我们选择它。 在弹出的 Add User 对话框中，输入完整的 Azure EntraID 的邮箱，比如我的是lei.wei@xbbm365.backupnext.cloud。 这样，整个配置就完成了，我们来试试登陆。打开 VBR 客户端，我们能看到客户端上已经出现Sign in with SSO选项，我们直接点击这个。 点击后，登陆窗口会自动弹出标准的微软登陆界面，输入密码后，还会弹出微软的 MFA 批准登陆。 手机 Authenticator 批准后，VBR Console 就能顺利跳转登陆啦。 我们再打开网页试试看，在 WebUI 中，我们一样能看到有新的 Sign in With SSO 选项啦。 同样，批准登陆后，我们能够访问 Veeam 权限的 Web UI，而在 Web UI 的右上角，我们还能看到已经正确显示访问用户的账号和邮箱了。 ","date":"2025-09-25","objectID":"/2025/09/veeam13-security-features-01/:2:3","tags":["Backup","Security"],"title":"让 VBR 登陆更安全：v13 版本 SAML + Azure EntraID 集成全攻略","uri":"/2025/09/veeam13-security-features-01/"},{"categories":[],"content":"在 Azure 中查看登录审计信息 在 Azure EntraID 的管理审计界面中，能够清晰的看到 VBR 中登陆的信息。 ","date":"2025-09-25","objectID":"/2025/09/veeam13-security-features-01/:2:4","tags":["Backup","Security"],"title":"让 VBR 登陆更安全：v13 版本 SAML + Azure EntraID 集成全攻略","uri":"/2025/09/veeam13-security-features-01/"},{"categories":[],"content":"配置小结 按照以上方法，VBR 和 Azure EntraID 的集成就能轻松配置完成。需要注意的是，这样配置的用户它仅仅是备份系统的用户，它并不能像 veeamadmin 和 veeamso 账号一样去登陆 Appliance 的 Veeam Management Console，这个 SSO 账号是无法管理 Appliance 的。 从安全上来看，这样的配置能够有效的分离备份系统的权限，备份系统的身份认证和备份基础架构的账号完全分离开来了，这也更加符合大型企业和组织的使用规范。 ","date":"2025-09-25","objectID":"/2025/09/veeam13-security-features-01/:3:0","tags":["Backup","Security"],"title":"让 VBR 登陆更安全：v13 版本 SAML + Azure EntraID 集成全攻略","uri":"/2025/09/veeam13-security-features-01/"},{"categories":[],"content":"最近，Veeam 在 R\u0026D 论坛上由首席产品官 Anton Gostev 发布了一篇 FAQ，把 V13 的发布节奏、部署选项、许可与迁移策略讲得非常清楚。对于客户和合作伙伴工程师来说，这不是一条“新闻”，而是一份足以影响“是否立即升级、如何规划迁移路径”的实战指南。本文以该帖为切入点，结合官方发布信息，解读它对不同规模用户的实际影响，并提出可操作的建议。 ","date":"2025-09-23","objectID":"/2025/09/veeam-software-appliance-06/:0:0","tags":["VBR"],"title":"深度解读：Veeam V13 的发布策略与部署选择","uri":"/2025/09/veeam-software-appliance-06/"},{"categories":[],"content":"要点回顾 首先，V13 将提供两种部署形态：既保留可安装在 Windows 上的传统安装包，又新增基于 Linux 的 Veeam Software Appliance。两种方式运行的是同一套跨平台 VBR 代码，功能保持一致，只是在底层操作系统管理上体现出“Appliance 特性”。换句话说，无论你选择 Appliance 还是 Windows，都不会丢失功能。 其次，Veeam 这次采用“early release”策略：先发布 Software Appliance（13.0.0），把完整的 Windows installable（以及某些复杂特性）放到 13.0.1 完整版（计划 Q4 2025）。早期版本面向“全新部署”，官方声明其功能“可用于生产并受支持”，但部分对 QA 要求更高的功能（如从 V12 直接迁移、Veeam Cloud Connect 等）在初版暂不提供。 第三，风险与回报并存：跨平台改造意味着大规模代码调整（帖子提到约 60% 的代码库变化），因此早期用户可能遇到 bug；但整体性能和可扩展性提升显著，早期使用者能享受更低的部署成本、“开箱即用”的安全合规特性以及自动补丁等带来的 TCO 优势。 最后是许可与迁移：Windows installable 的授权模式不变；但 Software Appliance 初期仅支持 VUL、Rental、NFR 等许可类型（Essentials 暂有限制）。并且早期版本不支持从 V12 直接在线转换到 Appliance。官方计划在后续提供转换工具，并可能通过受控报名和 Professional Services 逐步推进迁移。 ","date":"2025-09-23","objectID":"/2025/09/veeam-software-appliance-06/:0:1","tags":["VBR"],"title":"深度解读：Veeam V13 的发布策略与部署选择","uri":"/2025/09/veeam-software-appliance-06/"},{"categories":[],"content":"这些事实对你意味着什么 1) 小型实验室 / 新项目：可以大胆尝试早期 Appliance 对于全新部署或实验环境，早期 Appliance 很有吸引力。它免去了操作系统安装、加固、补丁管理的环节，让你快速搭建一个“完整备份域”，好处包括更少的运维工作、自动补丁、现代化 WebUI 和管理体验。当然，早期用户需要随时准备在遇到问题时与 Veeam Support 沟通。 2) 大规模生产环境 / 关键业务系统：建议观望或谨慎评估 生产环境更看重稳定性和支持风险。由于早期版本暂不支持从 V12 直接迁移，如果你希望平滑升级，最佳做法是等 13.0.1（Windows installable + 完整迁移路径）或至少先在灰度/测试环境做充分评估后再切换。若依赖的功能（如 Veeam Cloud Connect、特定插件或第三方集成）在 early release 中延后提供，也要慎重决策。官方明确会以“受控方式”推动大规模迁移，以保护 Support SLA。 3) 许可与成本 Appliance 初期仅支持特定许可类型（VUL 等），对仍使用旧 Socket 许可或 Community 版本的用户有一定影响。好消息是 Socket 转 VUL 的流程据称更方便，但仍涉及维保续费。建议提前与财务/采购确认许可方式，评估整体 TCO（包括迁移测试、潜在 Professional Services 费用）。 ","date":"2025-09-23","objectID":"/2025/09/veeam-software-appliance-06/:0:2","tags":["VBR"],"title":"深度解读：Veeam V13 的发布策略与部署选择","uri":"/2025/09/veeam-software-appliance-06/"},{"categories":[],"content":"七条可直接执行的建议 先测试再推广：在 1~2 台非业务 VM 上先装 V13 Appliance 做功能验证（WebUI、备份/恢复、Hardened Repo 等）。 不要在生产上直接迁移：若你在用 V12 且有大量历史配置或老旧插件，等待 13.0.1 的 Windows installable 和转换工具。 提前评估许可：确认当前许可是否被 Appliance 支持；如需从 Socket 转 VUL，提前与销售沟通成本和时间窗口。 制定备份导入计划：准备新装 Appliance 时，先验证“导入历史备份”的流程（导入元数据、存储库访问等），并测试并规划回退步骤。 规划合规与自动更新策略：用好 Appliance 的自动更新和 JeOS 安全基线，但把更新安排在维护窗口并做好变更记录，参考官方 Release Notes 验证兼容性。 考虑专业支持：若计划大规模迁移，提前申请官方升级服务，准备 Professional Services 预算分阶段有序迁移。 监测并保留回退方案：任何早期评估都要有回退计划（如保留 V12 快照、回滚脚本、恢复验证流程）。 ","date":"2025-09-23","objectID":"/2025/09/veeam-software-appliance-06/:0:3","tags":["VBR"],"title":"深度解读：Veeam V13 的发布策略与部署选择","uri":"/2025/09/veeam-software-appliance-06/"},{"categories":[],"content":"对产品方向的补充看法 Appliance 先行发布有几个原因：一是降低运维门槛并把安全合规做成“默认值”，对新客户极有吸引力；二是提前收集底层平台的真实反馈，为后续 Windows 迁移工具打下更稳固的基础。正因如此，Veeam 选择“受控放量”策略——既能展示 V13 的性能提升，也能避免一次性把所有客户推到尚在磨合的迁移工具上。 ","date":"2025-09-23","objectID":"/2025/09/veeam-software-appliance-06/:0:4","tags":["VBR"],"title":"深度解读：Veeam V13 的发布策略与部署选择","uri":"/2025/09/veeam-software-appliance-06/"},{"categories":[],"content":"在窗口期做最稳妥的决策 如果你希望“尽快升级并简化运维”，可以先在非关键环境尝试 Appliance，把流程、脚本和回滚办法固化；如果你追求零风险生产，建议等待 13.0.1 完整版和官方迁移工具，同时在测试环境做全面兼容性测试。不论选择哪条路径，关键都是“测试—记录—自动化—回滚”四步循环：先测、写 SOP、自动化、确保能回滚。 最后，建议在任何迁移或大规模变更前，关注官方 Release Notes / KB（如 VBR 13 Release Information）以及 Gostev FAQ 帖子的更新。 ","date":"2025-09-23","objectID":"/2025/09/veeam-software-appliance-06/:0:5","tags":["VBR"],"title":"深度解读：Veeam V13 的发布策略与部署选择","uri":"/2025/09/veeam-software-appliance-06/"},{"categories":[],"content":"写在最后 本篇是我本次 Veeam Software Appliance 发布系列的收官文章，前面我们详细梳理了新发布的软件。本系列之后，我还会继续推出 V13 新功能集锦系列，欢迎持续关注。 ","date":"2025-09-23","objectID":"/2025/09/veeam-software-appliance-06/:0:6","tags":["VBR"],"title":"深度解读：Veeam V13 的发布策略与部署选择","uri":"/2025/09/veeam-software-appliance-06/"},{"categories":[],"content":"Veeam 在 v13 中不仅把备份主服务器做成了预加固的 Software Appliance，同时也推出了专门用于承载角色服务的 Veeam Infrastructure Appliance。如果把 Software Appliance 看作“指挥中心”，那么 Infrastructure Appliance 更像是一台预配置、上手即用的“任务执行单位”：它为 Proxy、Mount Server、Hardened Repository 等角色提供了一个统一、受控并且合规的运行环境。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:0:0","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"一、为什么选用 Infrastructure Appliance 选择 Infrastructure Appliance 的理由可以归结为三句话：快速、简单、安全。Veeam 基于 Rocky 9 构建的 JeOS（Just enough OS）镜像，把操作系统和运行时依赖做成了受控的、最小化的分发单元。你部署一个 Infrastructure Appliance，等于把一台仅用于备份角色的、按最佳实践调优过的 Linux 服务器直接“拿来即用”。 从实务角度看，这带来的好处很直接：部署不再受传统操作系统安装和补丁管理的复杂性所拖累；角色支持覆盖 Proxy、Mount Server、Gateway Server、Hardened Repository 等常见组件；而在安全合规上，Appliance 出厂即内置 DISA STIG 与 FIPS 策略、默认启用 UEFI Secure Boot，并通过证书认证替代开放式 SSH 登录，显著缩减攻击面。对分布式或多站点部署而言，Infrastructure Appliance 能快速扩展执行节点的能力，并把维护复杂度降到最低。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:1:0","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"二、部署与配置：一步到位的体验 在部署 Veeam Infrastructure Appliance 之前，需要先确认目标资源满足最基本的要求。建议的最小配置常见如下： 四核 x86-64 CPU 或 vCPU 8 GB RAM 至少两个 120 GiB 的磁盘，系统盘推荐 SSD/NVMe（系统盘必须是容量最小的盘） 1 Gbps 或更高的网络带宽。 若在 vSphere 中部署，请把虚拟机 OS 类型设为 RHEL 9（或兼容的选项），以便与 Rocky Linux 9 的内核/驱动匹配。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:2:0","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"安装 实际部署流程并不复杂：下载官方提供的 ISO，将其挂载到目标主机或虚拟机并引导启动，安装菜单会列出 Infrastructure Appliance 的多个安装选项（含对 iSCSI \u0026 NVMe/TCP 的支持以及 Hardened Repository 角色）。 接着选择 Install（或在恢复场景选择 Reinstall），等待自动化步骤完成并重启，系统随后会进入初始化向导。 整个过程和 Veeam Software Appliance 几乎完全一致，具体可以参考之前的帖子。初始化配置完成后，可直接通过 Host Management 的 WebUI 或 TUI 进行后续管理：包括网络与主机名设置、时间同步（NTP/NTS）、证书与访问控制配置等。对于没有 Linux 经验的用户，这种“向导式”的体验大幅降低了上手门槛，没有 Linux 经验都能轻松通过 Host Management WebUI 和 TUI 完成所有必要的操作。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:2:1","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"在 VBR 中添加普通受管理的 Linux 角色服务器 通过 Veeam Infrastructure Appliance ISO 安装完成后，需要到 VBR 中添加，Backup Infrastructure 下找到 Managed Servers 中找到 Linux Server 的添加向导，选择 Add New 就行了。在向导的 Access 步骤中，和以往不一样，直接选择 Connect using certificate-based authentication(recommand)即可，这个选项不需要打开 SSH 端口，也无需输入用户名密码，而是直接通过 Veeam 自有的协议和证书进行连接。 其他步骤，没有任何改变，和以往老版本的配置完全一致。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:2:2","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"在 VBR 中配置 Hardened Repository 对于 Hardened Repository，添加 Linux 角色服务器的过程完全一致，但是在 Server 的目录呈现部分，Veeam 对于 Linux 系统的路径做了处理，仅将 Hardened Repository 中唯一可以存放数据的路径呈现给客户： 在文件夹设置中，一样只列出了仅限备份可选的文件夹，当然New Folder的选项还是保留了，用户可以在这个设定 Folder 的时候创建新的文件夹，选择新的文件夹。 其他的设置，和之前版本的 Hardened Repository 保持一致。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:2:3","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"三、实践中的最佳做法与安全设计原则 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:3:0","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"最佳实践 把 Appliance 当作“黑盒”并不等于把它丢进机房就完事了，要让它稳定跑起来，实际上只需要遵循以下这些： **角色与资源匹配：**在部署前先确认该节点要承担的角色（Proxy、Mount Server、Hardened Repository 等），并据此划分资源。举例来说，Proxy 的计算需求会随并发任务上升而增加；建议至少 2 核 CPU 起步，并按每两个并发任务额外增加 1 核；内存从 2 GB 起跳，且对 I/O 敏感的 Repository 应优先选用企业级 SSD/NVMe 和硬件 RAID，当然 SATA 盘作为备份存储性价比之王，也是非常推荐的。 硬件和固件兼容： Infrastructure Appliance 要求启用 UEFI Secure Boot；对于 Hardened Repository，推荐硬件 RAID 控制器并避免使用一些不受支持的虚拟化或软件 RAID 方案。提前确认固件/BIOS 与 NVMe 控制器兼容性，能够避免后续无法识别系统盘或性能异常的问题。 网络与时间： 建议为 Appliance 使用静态 IP，并配置至少三台以上可信的 NTP/NTS 源，确保时间同步稳定；时间漂移会导致 MFA、证书验证或计划任务出现异常。 **集中化管理与配对：**初始配置完成后应立刻通过 Backup Console 把 Appliance 配对到 Veeam Backup \u0026 Replication（VBR）管理下，纳入统一策略、日志与补丁管理体系；这样可以保证策略一致性与便于后续审计。同时，还可以在配置完成后，关闭 Host Management WebUI 的访问，进一步减少系统的受攻击面。 保持 JeOS 原设。 JeOS 被设计为“只装必要组件”的最小系统，内置 DISA STIG、FIPS 与自动更新机制。擅自修改底层系统设置（例如随意开启额外服务、手动更改内核参数或使用包管理器随意升级）会带来风险：可能导致系统无法正常接受官方更新、失去合规性，甚至影响 VBR 对该节点的识别与支持。因此，除非官方指示或有充分验证，建议只通过 Host Management 或 VBR 提供的接口进行所有配置变更。目前，Veeam 官网已经更新了KB4772 来明确说明这个问题。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:3:1","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"安全特性 Infrastructure Appliance 的安全与更新设计是其核心特点之一。系统默认启用多项安全控制措施，例如 UEFI Secure Boot、DISA STIG 与 FIPS 策略，Host Management 提供对证书、访问请求、基础设施锁定与审批流程的集中化控制；其中 Security Officer 的审批机制可用于启用 SSH、授权临时 root 访问、重置用户密码、批准配对请求等敏感操作，从而实现内置的“四眼”审计流程。 更新方面，Appliance 使用 Veeam Updater 组件进行集中化的补丁管理。管理员可以在每个 Appliance 的 Host Management 中设定更新策略，也可以通过 Veeam Backup \u0026 Replication 的备份控制台集中管理所有 Appliance 的更新。系统会对更新包做数字签名与校验，确保来源可信、避免篡改。所有更新操作与日志均可在控制台中查看与导出，便于合规审计。 此外，Appliance 还提供一套应急维护功能：可以通过 Recovery LiveCD 的 ISO 来进行应急系统修复和维护。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:3:2","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"四、结语：把复杂留给 Veeam，把安全留给你 Veeam Infrastructure Appliance 的价值并非只在“省事”，而在于把基础设施中的重复性、风险性工作封装成受控、可审计的流程，让运维把注意力放在架构与策略上，而不是日常的系统修补与兼容调试。把 Software Appliance 作为中枢、Infrastructure Appliance 作为可复制的执行单元，你可以在多站点、分布式场景下快速扩容、统一管理并保持合规与安全。 如果你刚开始规划和试用新版本，建议先在测试环境中演练几次完整的安装与配对流程：明确每台 Appliance 的角色、调整资源配比、验证时间与网络配置，然后把这些步骤固化成标准操作流程。这样既能享受 Appliance 带来的“即装即用”，也能把长期运维的复杂性和风险降到最低。 ","date":"2025-09-22","objectID":"/2025/09/veeam-software-appliance-05/:4:0","tags":["VBR"],"title":"把复杂留给 Veeam：Infrastructure Appliance 上手指南","uri":"/2025/09/veeam-software-appliance-05/"},{"categories":[],"content":"在前几篇文章里，我们把 Veeam Software Appliance 装了起来、跑了起来，也体验了它“安全默认”的管理方式。这次我们要解决很多人真正关心的问题：在没有互联网的环境里，如何让 Veeam Software Appliance 也能像在线环境一样自动获取更新。官方手册提到可以指定本地镜像仓库，但具体怎么搭建、怎么同步、怎么配证书，却没有细说。这篇就基于我自己实验室的操作，完整复刻一遍，大家可以直接照着做。 ","date":"2025-09-09","objectID":"/2025/09/veeam-software-appliance-04/:0:0","tags":["VBR"],"title":"让 Veeam 更新既安全又快速：本地更新镜像服务器搭建全攻略","uri":"/2025/09/veeam-software-appliance-04/"},{"categories":[],"content":"一、为什么要自己搭建更新仓库 Veeam Software Appliance 自带的 Veeam Updater 服务每天会自动连到 https://repository.veeam.com 拉取补丁和元数据，这对有外网的环境很方便。但在隔离区、测试区或者合规要求不能访问公网的场景，就会面临补丁滞后、手工更新麻烦的问题。 本地更新仓库的作用就是：在内网搭一个“翻版”的 Veeam 官方仓库，用 HTTPS 提供服务，并且让 Appliance 信任它，这样即使断网也能自动检查和安装更新。你只需要周期性地把官方仓库镜像下来，内网的 Appliance 就能像连公网一样更新了。 ","date":"2025-09-09","objectID":"/2025/09/veeam-software-appliance-04/:1:0","tags":["VBR"],"title":"让 Veeam 更新既安全又快速：本地更新镜像服务器搭建全攻略","uri":"/2025/09/veeam-software-appliance-04/"},{"categories":[],"content":"二、在 Ubuntu 上部署 nginx + 自签名证书 + 镜像同步 本教程演示如何在 Ubuntu 虚拟机 上搭建一套完整的 Veeam 官方仓库镜像服务： 使用 nginx 提供 HTTPS 访问； 通过 自签名证书（或替换为 Let’s Encrypt 证书）提供传输安全，满足 Veeam 官方要求； 利用 wget 镜像模式定时同步官方仓库内容； 我这里的实验室环境是 Proxmox 上的 虚拟机，CPU 和内存配置按需即可，磁盘空间需预留足够（例如 rocky 仓库约 17 GB，完整仓库可能超 100 GB）。 接下来就可以按以下步骤操作。 # 安装 nginx apt install nginx -y # 创建存放镜像和证书的目录 mkdir -p /var/www/veeam-repo mkdir -p /etc/nginx/ssl cd /etc/nginx/ssl # 生成自签名证书 openssl genrsa -out veeamrepo.key 2048 openssl req -new -key veeamrepo.key -out veeamrepo.csr \\ -subj \"/C=CN/ST=Beijing/L=Beijing/O=Lab/OU=IT/CN=veeamupdater.backupnext.home\" openssl x509 -req -days 3650 -in veeamrepo.csr -signkey veeamrepo.key -out veeamrepo.crt 其中这里 veeamupdater.backupnext.home 这里是我家里的域名解析，如果大家自己搭建镜像服务器，可以根据自己的情况设置域名。在后面的步骤中，会需要用到这个域名。 配置 nginx 虚拟主机（/etc/nginx/sites-available/veeamrepo.conf）： server { listen 443 ssl; server_name veeamupdater.backupnext.home; ssl_certificate /etc/nginx/ssl/veeamrepo.crt; ssl_certificate_key /etc/nginx/ssl/veeamrepo.key; root /var/www/veeam-repo; index index.html index.htm; autoindex on; autoindex_exact_size off; autoindex_localtime on; location / { allow all; } } server { listen 80; server_name veeamupdater.backupnext.home; return 301 https://$host$request_uri; } 启用并检查配置： ln -s /etc/nginx/sites-available/veeamrepo.conf /etc/nginx/sites-enabled/ nginx -t \u0026\u0026 systemctl reload nginx 接下来编写镜像同步脚本（只同步需要的路径，这里以 rocky 为例）： #!/bin/sh MIRROR_DIR=\"/var/www/veeam-repo\" LOG_FILE=\"/root/sync_vbr_only.log\" URL=\"https://repository.veeam.com/rocky/\" cd \"$MIRROR_DIR\" || exit 1 wget -m -c -np -nH --cut-dirs=0 \\ -e robots=off \\ -t 3 -T 30 \\ -R \"index.html*\" \\ -l inf \\ \"$URL\" \u003e\u003e \"$LOG_FILE\" 2\u003e\u00261 echo \"Sync completed at $(date)\" \u003e\u003e \"$LOG_FILE\" 给脚本执行权限，并通过 crontab 定时执行： chmod +x /root/sync_veeam_vbr.sh crontab -e # 每天早上 9 点同步一次 0 9 * * * /root/sync_veeam_vbr.sh 第一次可以手动运行脚本立即下载，约 17 GB，取决于网速。下载后无需重启 nginx，目录内容更新后 Web 服务即可直接提供新文件。 ","date":"2025-09-09","objectID":"/2025/09/veeam-software-appliance-04/:2:0","tags":["VBR"],"title":"让 Veeam 更新既安全又快速：本地更新镜像服务器搭建全攻略","uri":"/2025/09/veeam-software-appliance-04/"},{"categories":[],"content":"三、在 Veeam Software Appliance 中配置本地仓库 镜像服务器准备就绪后，接下来就是在 Veeam Software Appliance 中启用它。操作思路很简单：把自签名证书导入控制台 → 指定镜像地址 → 测试更新。 具体步骤如下： 将刚才在 nginx 服务器上生成的 veeamrepo.crt 自签名证书拷贝到 Veeam Backup Console 所在的服务器； 打开 Veeam Backup Console，进入 Update Settings 界面。 点击下方的 Software repository 设置，，在“Mirror repository”里填写你的地址（例如 https://veeamupdater.backupnext.home/rocky）； 上传 .crt 证书并保存设置； 在 Console 左上角，继续点击“检查更新”，跳转到 updater 的网页。点击Check update如果提示成功并能正常下载更新，说明内网镜像仓库已配置完成。 这个过程也可以在 web Console 中设置。 以上，即便在完全隔离的内网环境中，Veeam Software Appliance 也能像在公网下一样自动获取补丁与更新，无需再手工下载导入。同时，这个内网更新服务不仅适用于单台 Appliance，还可以为整个 Veeam Infrastructure Appliance 环境提供统一的更新源——所有设备的更新请求都会自动重定向到你的内网镜像仓库，真正实现集中、快速又安全的升级体验。 在下一篇文章中，我将继续深入，带大家了解 Veeam Infrastructure Appliance 的使用与管理。 ","date":"2025-09-09","objectID":"/2025/09/veeam-software-appliance-04/:3:0","tags":["VBR"],"title":"让 Veeam 更新既安全又快速：本地更新镜像服务器搭建全攻略","uri":"/2025/09/veeam-software-appliance-04/"},{"categories":[],"content":"在前两期里，我们一起完成了 Veeam Software Appliance 的“落地”——从下载 ISO、制作启动盘到自动化安装，再到最初的 TUI 初始化和基本管理，很多小伙伴已经顺利把这台“备份小钢炮”跑了起来。 但当系统真正跑起来之后，新的问题也随之而来： Veeam Software Appliance 到底有哪些新功能？ 这个基于 Linux 的 Appliance 和以前的 Windows 版有什么不同？ WebUI 和 TUI 两个控制台该用哪个？ 用户管理如何完成？ 升级更新又该怎么做？ 本期，我们就从这些大家最关心的问题入手，带你熟悉 Veeam Software Appliance 新功能 和 Appliance 独有的管理方式，并且手把手梳理 两个主机控制台 UI 的使用场景，让你在安装完之后也能用得顺手、管得安心。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:0:0","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"开箱即用，安全默认 说到 Veeam Software Appliance，最直观的感受就是：不用再担心安全加固和补丁维护。以往我们习惯了在 Windows 上安装 Veeam，再自己做补丁、调权限、配防火墙；而 Appliance 则是 出厂就预先加固好的 Linux 平台，系统内核、权限模型、服务状态都按最佳实践配置完毕，从安装那一刻起就是“安全默认”（Secure-by-Default）。 更重要的是，这种内置的安全和简化管理不仅体现在系统管理层面，还延伸到用户体系访问控制和自动化升级和更新等方面。换句话说，你不需要成为 Linux 安全专家，也能在 Veeam Software Appliance 上用到这些“硬核”的安全特性。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:1:0","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"Appliance 独有的管理方式 很多小伙伴装好 Veeam Software Appliance 后，第一反应还是像管理传统 Linux 服务器那样，想着能不能 ssh 进去改配置、自己跑 yum update。其实大可不必——也不建议这样做。 Appliance 对底层 Linux 已经做了深度封装和加固，系统内核、软件包、服务依赖都按 Veeam 的最佳实践打包好了。你无需、也不应该手动改动这些底层组件，而是要通过它自带的管理工具和界面来操作： 平时的网络、主机名、时区、服务启停等基础设置，直接在 Host Management Web UI 或 TUI 中完成，避免自己去编辑系统文件； 如果确实要调整 Veeam 相关的配置文件，比如修改/etc/hosts文件，可以借助 Import / Export Configuration 功能：在 Logs and Services → Host Configuration 下导出配置、修改后再导入，这样系统才能正确识别并应用； 升级或打补丁也要用 Appliance 内置的更新机制，不要用 yum 之类的包管理器手动更新。 这样既能保证系统稳定和安全，又能在需要调整时保持“官方支持”的姿势，一举两得。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:2:0","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"Host Management：WebUI 与 TUI 功能对比表 Appliance 有着独特的管理方式，两个 UI 需要交替使用，功能一览表如下： 功能类别 操作项 WebUI 支持 TUI 支持 网络配置 修改主机名 ✅ ✅ 管理域设置 ✅ ❌ 配置网络接口 ✅ ✅ 配置 HTTP/HTTPS 代理 ❌ ✅ 时间设置 修改时区、配置 NTP 时间服务器 ✅ ✅ 远程访问 禁用 WebUI ✅ ✅ 启用 WebUI ❌ ✅ 启用/禁用 SSH ✅ ✅ 打开 root shell ❌ ✅ 用户与权限 添加用户、编辑用户、重置用户密码 ✅ ❌ 修改 Host Admin 密码 ✅ ✅ 解锁用户、启用/禁用 MFA、重置 MFA ✅ ❌ 重置 Security Officer 密码恢复令牌 ✅ ❌ 备份基础设施 启用远程数据收集、启用/禁用基础设施锁定、启用托管服务器配对 ✅ ❌ 更新管理 配置更新策略、检查更新、安装更新、查看更新历史 ✅ ❌ 系统维护 启动/停止/重启 Veeam 服务 ✅ ❌ 重启 Veeam Appliance ✅ ✅ 查看/导出事件日志、导入/导出配置文件、下载日志包 ✅ ❌ 查看证书指纹 ✅ ✅ 生成新 WebUI 证书 ❌ ✅ 安全控制 审批授权请求、管理配置备份口令 ✅ ❌ ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:2:1","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"重构的用户体系 在传统的 Veeam Backup \u0026 Replication（以下简称 VBR）中，用户权限管理主要依赖于 Windows 本地或域账户，并通过 VBR 控制台进行角色分配。而在 Veeam Software Appliance 中，用户体系被重新设计，Host Management 层引入了独立的用户角色模型，实现了更细致的安全隔离与运维控制。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:3:0","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"一、Host Management 用户角色体系概览 Veeam Software Appliance 的 Host Management 控制台（WebUI）内置了四类用户角色，每类角色对应不同的管理职责： 角色名称 描述 使用场景 Host Administrator（veeamadmin） 拥有完整主机管理权限，可访问 WebUI 与 TUI，执行网络配置、用户管理、更新维护等操作。 适用于负责 Appliance 运维的系统管理员 Security Officer（veeamso） 专注于安全控制，仅可访问 WebUI，负责审批敏感操作、管理密码恢复令牌、配置备份口令等。 适用于安全审计、合规管理人员 User 权限受限，无法访问 Host Management 控制台，仅用于标识普通用户身份。 适用于需要登录但无主机管理权限的用户 Service Account 用于系统服务或自动化任务，权限受限，不支持 MFA。 适用于脚本、API 调用或集成服务账号 ⚠️ 默认账户 veeamadmin 与 veeamso 不可删除，建议在部署完成后立即修改密码并启用 MFA。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:3:1","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"二、用户创建与角色分配流程 用户创建需通过 WebUI 完成，流程如下： 登录 Veeam Host Management WebUI。 进入主菜单 Users and Roles。 点击 Add，填写用户名、密码、描述。 选择角色（每个用户仅能分配一个角色）。 根据角色类型启用或跳过 MFA 配置。 审核信息并点击 Finish 完成创建。 密码必须满足复杂度要求：至少 15 位，包含大小写字母、数字、特殊字符，且同类字符不得连续超过 3 个。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:3:2","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"三、角色使用建议与场景匹配 为确保系统安全与职责清晰，建议按以下场景分配用户角色： Host Administrator：用于日常运维人员，负责主机配置、更新、用户管理等操作。 Security Officer：用于安全审计人员，负责审批敏感操作、管理配置备份口令等。 User：用于需要登录但无管理权限的普通用户，例如查看日志或接收通知。 Service Account：用于自动化脚本、API 调用等场景，建议禁用 MFA 并限制权限。 📌 注意：Host Administrator 与 Security Officer 的职责分离是 Veeam Software Appliance 安全架构的核心，建议启用“四眼审批”机制，确保敏感操作需双人确认。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:3:3","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"四、用户管理操作能力 操作项 Host Administrator Security Officer 添加/编辑/删除用户 ✅ ❌ 重置密码 ✅ ✅（需审批） 解锁用户 ✅ ❌ 启用/禁用 MFA ✅ ❌ 审批敏感操作（如 SSH、root shell） ❌ ✅ 管理配置备份口令 ❌ ✅ ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:3:4","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"五、MFA 与安全官机制 MFA 支持：基于 TOTP，兼容主流认证器（如 Microsoft Authenticator）。 Security Officer 登录流程： 首次登录需设置强密码并启用 MFA。 系统生成恢复令牌，用于未来敏感操作审批。 该令牌必须妥善保存，遗失将无法恢复。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:3:5","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"六、与 VBR RBAC 的区别说明 Veeam Software Appliance 的 Host Management 用户体系仅用于主机层管理，与 VBR 控制台中的 RBAC（如 Backup Operator、Restore Operator 等）是两个独立体系。 Host Management 用户仅管理 Appliance 本身，不涉及备份任务权限。 VBR 控制台中的 RBAC 将在后续文章中详细介绍，适用于备份任务、恢复操作等权限控制。 通过合理配置 Host Management 用户体系，Veeam Software Appliance 实现了运维与安全职责的分离，构建了更安全、可审计的管理架构。建议在部署初期就明确角色分配，避免权限滥用或安全隐患。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:3:6","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"升级和更新 在传统的 Veeam Backup \u0026 Replication 部署中，升级往往意味着管理员需要手动下载补丁、验证兼容性、安排维护窗口，甚至还要处理操作系统层面的更新。这种方式既繁琐又容易因人为操作失误或补丁遗漏带来安全隐患。而在 Veeam Software Appliance 中，升级机制被彻底重构，成为其“天生安全”架构的重要组成部分。 Veeam Software Appliance 内置的 Veeam Updater 服务 会每日自动向 Veeam 官方仓库（repository.veeam.com）获取最新更新信息并写入配置数据库。更新内容不仅包括操作系统与安全补丁（强制安装，无法跳过或取消，确保系统始终合规），也包括 Veeam B\u0026R 组件（支持主版本、次版本及私有修复补丁，可按策略自动或手动安装）。整个过程通过 REST API 与 Veeam Identity Service 进行授权通信，确保更新操作的完整性与安全性。 管理员可以通过 WebUI 或 Veeam 控制台灵活配置更新策略，例如： 仅自动安装安全更新或扩展到次版本更新 按周或月设定维护窗口 设置强制更新的最大延迟时间（默认 30 天，可延长至 90 天） 配置 HTTP/HTTPS 代理访问外部仓库。 即使选择手动安装，超过合规期限后仍会强制安装更新，即使当前有备份任务运行也会中断作业以完成更新。 对于无法访问互联网的环境，Veeam Software Appliance 也支持配置本地离线镜像仓库作为更新源。只需提供本地仓库地址及其服务器证书，就能获得与在线仓库相同的自动更新体验。 相比传统 Veeam 软件的手动更新，Veeam Software Appliance 在操作系统和组件更新、安全性保障、更新源配置、以及日志与审计方面都有显著不同：系统补丁自动推送并强制安装，Veeam 组件可自动检测并按策略安装，支持离线镜像仓库，同时所有更新日志集中管理且可导出审计。 在执行更新之前，仍建议管理员先导出配置文件备份当前设置；可通过 WebUI 查看更新历史与详细日志（路径 https://\u003chostname\u003e/updater/updates）；若收到 Veeam Support 提供的 Private Hotfix，也可以通过 WebUI 上传并安装。 这一全新的更新机制不仅让补丁管理从繁琐的手动操作变成可控、可审计、可自动化的流程，也在安全性与合规性上树立了新的标杆，为现代化备份基础设施提供了更高的可靠性与运维效率。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:4:0","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"小结 Veeam Software Appliance 把很多复杂工作隐藏在了“界面后面”，这既是优势也是责任——把管理、权限、更新节奏都规划好，才能既享受“开箱即用”的便利，又保证长期安全与合规。下一篇我会分享大家关心的离线镜像仓库搭建，手把手带你把本地仓库搭起来并保持同步，感兴趣的别错过。 ","date":"2025-09-08","objectID":"/2025/09/veeam-software-appliance-03/:5:0","tags":["VBR"],"title":"你必须知道的：Veeam Software Appliance 全新的管理使用方法","uri":"/2025/09/veeam-software-appliance-03/"},{"categories":[],"content":"在上一篇文章里，我们和大家一起认识了 Veeam 最新发布的几款产品，尤其是 Veeam Software Appliance 这个全新的备份软件“本体”。很多朋友可能看完之后觉得概念上有点明白了，但还是不清楚真正下载回来以后应该怎么用、怎么装、怎么配置。别急，从这篇开始，我们就动手实战，带大家一步步搞定 Veeam Software Appliance 的部署和使用。 Veeam 官方为这个 Appliance 提供了两种部署方式：ISO 镜像和 OVA 模板。为了不让大家一上来就“菜单太多”，本篇我们先专注在 ISO 镜像这种方式上。和我们平时在操作系统里“挂载一个 ISO 文件”不一样，这个 ISO 是一张完整的系统引导盘，你需要用它来启动服务器或虚拟机，就像给一台新电脑装系统一样。 ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:0:0","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"准备工作：获取 ISO 镜像 上一篇我们已经给出了下载链接，这里就不再重复贴地址，但在正式动手之前，我一定要郑重提醒大家一件事：无论你从哪里下载 Veeam Software Appliance 的 ISO，一定要校验你下载的 ISO 文件的 MD5/SHA-1 校验值！ 为什么要这么做？ 在今天的网络环境里，下载大文件并不总是“干干净净”的。比如： 有些公共 Wi-Fi 或被恶意软件感染的电脑，会劫持浏览器的下载请求，把你重定向到看似一样的“下载地址”； 攻击者也可能在中间链路里“掉包”，把原本的官方包替换成植入后门的恶意版本； 即便是官方站点，如果遭遇短暂的入侵或 DNS 污染，也有可能导致你拿到的不是原版文件。 这些情况用户肉眼完全看不出来，界面、文件名、大小都可能一模一样。 唯一可靠的办法就是比对 Veeam 官网提供的 MD5 或 SHA-1 校验码——就像比对“指纹”，指纹一致才是真身。 ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:1:0","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"不同系统的比对方法 无论是 Windows、Linux 还是 macOS 用户，现在我们都有非常方便的比对方法，这里大家一定要记得快速比较下载到的文件。下面我把比较方法列出，不同的系统只要复制粘贴到命令行，就能直接比较啦。 💻 Windows 在 PowerShell 中执行（官网文件名为 VeeamSoftwareAppliance_13.0.0.4967_20250822.iso）： # 校验 MD5 if ((Get-FileHash .\\VeeamSoftwareAppliance_13.0.0.4967_20250822.iso -Algorithm MD5).Hash.ToLower() -eq \"30bb0eef0dca6544c36a2728642d35c9\") { Write-Host \"✅ MD5 校验一致\" } else { Write-Host \"❌ MD5 校验不一致，请重新下载\" } # 校验 SHA-1 if ((Get-FileHash .\\VeeamSoftwareAppliance_13.0.0.4967_20250822.iso -Algorithm SHA1).Hash.ToLower() -eq \"1aa8624419c71adcf5425d87c8cf53f90fafd1f6\") { Write-Host \"✅ SHA-1 校验一致\" } else { Write-Host \"❌ SHA-1 校验不一致，请重新下载\" } 🍏macOS # 校验 MD5 if [ \"$(md5 -q VeeamSoftwareAppliance_13.0.0.4967_20250822.iso)\" = \"30bb0eef0dca6544c36a2728642d35c9\" ]; then echo \"✅ MD5 校验一致\" else echo \"❌ MD5 校验不一致，请重新下载\" fi # 校验 SHA-1 if [ \"$(shasum -a 1 VeeamSoftwareAppliance_13.0.0.4967_20250822.iso | awk '{print tolower($1)}')\" = \"1aa8624419c71adcf5425d87c8cf53f90fafd1f6\" ]; then echo \"✅ SHA-1 校验一致\" else echo \"❌ SHA-1 校验不一致，请重新下载\" fi 💻Linux # 校验 MD5 if [ \"$(md5sum VeeamSoftwareAppliance_13.0.0.4967_20250822.iso | awk '{print tolower($1)}')\" = \"30bb0eef0dca6544c36a2728642d35c9\" ]; then echo \"✅ MD5 校验一致\" else echo \"❌ MD5 校验不一致，请重新下载\" fi # 校验 SHA-1 if [ \"$(sha1sum VeeamSoftwareAppliance_13.0.0.4967_20250822.iso | awk '{print tolower($1)}')\" = \"1aa8624419c71adcf5425d87c8cf53f90fafd1f6\" ]; then echo \"✅ SHA-1 校验一致\" else echo \"❌ SHA-1 校验不一致，请重新下载\" fi 校验码就是“官方指纹”，只有完全一致才能确定拿到的是真正的官方原版文件，这是避开网上下载的程序被植入恶意程序的唯一方法。 ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:1:1","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"ISO 使用方式详解 在文章开头我们提到过，这个 ISO 与以往的 Veeam 软件安装包不同，它并不是单纯的软件 ISO，而是包含操作系统和 Veeam 软件的一体化镜像。换句话说，这个 ISO 本身就能像全新的操作系统安装盘一样，引导服务器或虚拟机启动，并进行完整的系统部署。 由于如今大家很少有“全新装系统”的需求，很多读者朋友拿到这种 ISO 可能会一时不知如何下手。其实，它大致有三种典型的使用场景： 光盘刻录（传统方式，方法简单，这里不展开） 虚拟机挂载 ISO（直接在虚拟化平台加载 ISO 启动，方法也很直观） 制作可启动 U 盘（将 ISO 烧录进 U 盘，插入服务器用 U 盘引导即可安装） 前两种方式相对容易操作，这里就不详细展开了；我们重点介绍第三种方式——用 Rufus 制作启动 U 盘。 Rufus 是一款非常轻量级、无需安装、功能强大的 U 盘启动盘制作工具，尤其值得一提的是，它内置了 MD5 与 SHA-1 校验功能，正好可以配合我们上一章节中提到的校验方法，帮助你快速验证下载的 ISO 文件完整性。下面我们就来看看 Rufus 的下载安装与使用步骤。 Rufus 使用步骤非常简单： 打开 Rufus 官方网站：https://rufus.ie/ 在页面中选择最新版本的 类型是便携版 下载到本地。 下载完成后，双击即可直接运行，无需安装，它有全中文的使用界面，非常友好。 ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:2:0","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"安装和初始化配置 ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:3:0","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"引导安装 当我们用刚才制作好的 U 盘引导服务器或虚拟机时，屏幕上出现的不是传统操作系统安装界面，而是 Veeam Software Appliance 的专用安装菜单。这张 ISO 里已经把操作系统和 Veeam 软件打包在一起，启动后就是“一体化”的安装体验。 主菜单清晰列出了两个主要组件： **Veeam Backup \u0026 Replication ** Veeam Backup Enterprise Manager **UEFI Firmware Settings ** 为了方便，还附带了一个 UEFI 设置选项，可以在不退出安装程序的情况下调整引导参数。 在 VBR 或 Enterprise Manager 的子菜单中，你会看到两个操作： Install – 全新安装，删除所有数据（推荐在新环境使用） Reinstall – 保留数据的重新安装 如果你选择 Install，系统会立刻弹出提示：“即将清空当前服务器挂载磁盘上的所有数据”。只要你点击 Yes 确认，之后就进入全自动安装流程 没有繁琐的分区、没有一堆选项，全程几乎无需操作，就像给电脑做一个 Ghost 还原一样简单。 安装完成后，右下角的 Reboot System 就会亮起，点击或者等待几秒后系统自动重启，即可进入 VBR。 这个 Appliance 安装完成之后，默认会包含两个常规的设备管理控制台，一个是酷炫纯文本的界面（TUI），另外一个是浏览器访问的 Web 界面（WebUI） ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:3:1","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"初始化配置 重启后进入系统，会直接进入 TUI，在这里需要首先做一些初始化配置，才能正常使用备份服务器。 在初始化配置向导的第一步，首先是 Veeam EULA 和一些第三方许可的确认界面，直接用键盘方向键操作或者 Tab 键操作即可，选中 Accept 进入下一步。 第二步是配置主机名，像我这里，配置了完整的 FQDN，并在我的 DNS Server 上做好了解析。 下一步是配置网络，我的环境中，没有 IPv6 的要求，我就只配置了 IPv4 的地址。 配置完成后，可以点击 Next 进入下一步。 再往下是时区和时间配置，这个对于备份系统来说非常重要，时间同步不仅用于登陆时的多因子验证，还要用于日常备份的各种操作，包括数据不可变。 然后是设置第一个管理员的密码，默认管理员用户名叫 veeamadmin，密码有非常严格的复杂度要求，为了 lab 环境使用方便，我一般会设置为： 123Q123q123!123 接下来会提示绑定多因子验证的设备，大家可以任选合适的手机上的 MFA 工具扫码绑定，我一般喜欢用微软的 Authenticator，这个支持备份数据，还是比国内的一些 App 要靠谱。 下一步是 Security Officer 选项，这个在复杂的生产环境是比较建议配置的，我的 Lab 我就直接勾选 Skip setting 了。 最后来到 Summary 界面，做一些配置检查后，点击 Finish 就可以完成初始化配置了。 配置完成后，就进入了日常待机的主画面。 接下去，我们就可以通过主画面的提示进一步进入 TUI 的高级配置中，进行一些主机配置的维护和调整，其中包括了主机配置、远程访问配置、修改密码、重启系统等等常规维护功能。 ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:3:2","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"使用 WebUI 进行高级配置 在 TUI 上提示了两个地址，一个是 Host Management console，另外一个是 Veeam Backup \u0026 Replication web UI。对于 Appliance 的进阶高级管理配置，可以通过 Host Management console 进入进行配置。进入的时候一样会提示输入密码和 MFA 的验证码。 以上，Veeam Backup \u0026 Replication 就安装完成了，至于 Veeam Backup Enterprise Manager，安装过程类似，就不在这里详细说明了，留给大家自己探索喽。 ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:3:3","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"小结 \u0026 下期预告 这一期，我带大家从头到尾走了一遍 Veeam Software Appliance 的 ISO 使用流程： 从官网下载镜像并校验完整性 → 使用 Rufus 制作启动 U 盘 → 引导服务器自动安装 → 在 TUI 界面完成最基础的初始化与管理。 你会发现整个过程几乎不需要复杂操作，只要准备好介质、跟着步骤点几下，任何人都能完成。 下一期，我们将正式走进 V13 版本的产品界面，深入体验它们的功能与新特性，看看全新版本到底有多强大。 ","date":"2025-09-05","objectID":"/2025/09/veeam-software-appliance-02/:4:0","tags":["VBR"],"title":"有手就能装！Veeam Software Appliance 一步一步带你部署","uri":"/2025/09/veeam-software-appliance-02/"},{"categories":[],"content":"前言：Veeam Software Appliance 发布背景 昨天 Veeam 官网悄悄上线了一个新产品：Veeam Software Appliance。对很多朋友来说，Veeam 过去一直都是 Windows 安装包 + 手动配置的传统模式，而这个 Software Appliance 明显走的是另一条路：安装和安全都做了预设，大大简化了上手流程。比如：它基于预加固的 Rocky Linux 平台，自带不可变存储、零信任访问控制和自动补丁，无需再单独采购 Windows 授权或自己做安全加固；用 ISO 或 OVA 就能直接部署，无论在虚拟机、物理机还是云上都可以跑。 ","date":"2025-09-04","objectID":"/2025/09/veeam-software-appliance-01/:1:0","tags":["VBR"],"title":"Veeam 重磅发布 Software Appliance：官网下载与文档结构大升级","uri":"/2025/09/veeam-software-appliance-01/"},{"categories":[],"content":"亮相新品：Veeam Software Appliance 概览 本次更新，Veeam 官方一次性放出“三件套”。如果大家平时用 Veeam 做备份，看到名字可能有点懵，下面我简单捋一捋： Veeam Software Appliance 这是这次的“主角”，也就是我们熟悉的 Veeam 备份软件本体，包含了备份服务器（Veeam Backup \u0026Replication）和企业管理器（Enterprise Manager）。不同的是，现在不用再在 Windows 上装一堆安装包了，而是直接提供了一个 ISO 或者 OVA 镜像，服务器用它引导后，就能进入系统安装界面，一次性把系统和软件都装好，省心又安全。 Veeam Infrastructure Appliance 这个可以理解成备份基础架构的“扩展包”。在 Veeam 环境里，支持分布式部署各种角色服务器，比如 Proxy、Tape Server、Gateway Server、Mount Server，还有最关键的数据存储库——Hardened Repository，现在通过这个 Appliance 可以用于安装这些角色。它和 Software Appliance 一样，都是基于 Rocky Linux 预先构建好的，拿来就能用，部署和维护成本都降下来了。 Veeam ONE v13 这个并不是 Software Appliance 版本，它和以前一样，是 Windows 下的安装包，这个算是常规升级版，负责监控和分析整个备份/恢复环境。可以从 V12 的 Veeam ONE 升级到 v13，同时能兼容旧版（V12 Windows 版 VBR）的监控，也能支持新版 Appliance 的监控。对于我们要同时管理老环境和新环境的小伙伴来说，这点特别重要，对于想提前尝鲜 V13 的，能实现平滑过渡。 需要注意的是，对于备份服务器来说，本次 Software Appliance 的 v13 版本仅支持全新安装，已有的 v12 版本暂时还不支持升级和迁移，如果是已经在使用 Veeam 朋友想升级的话，可能还需要等待一段时间，在下次更新时，Veeam 会推出平滑过渡的升级方案。 另外，Veeam Software Appliance 将不再支持社区版许可，因此就算想试用，都需要额外从官网下载测试许可导入才能让这个 Appliance 工作起来。 ","date":"2025-09-04","objectID":"/2025/09/veeam-software-appliance-01/:2:0","tags":["VBR"],"title":"Veeam 重磅发布 Software Appliance：官网下载与文档结构大升级","uri":"/2025/09/veeam-software-appliance-01/"},{"categories":[],"content":"官网全面焕新：下载与文档手册新体验 伴随新品发布，Veeam 官网也进行了一些调整。无论是产品下载入口、文档手册页面还是手册内部结构，这可能会对大家造成一定困扰。接下来我们来看看具体的一些变化吧。 ","date":"2025-09-04","objectID":"/2025/09/veeam-software-appliance-01/:3:0","tags":["VBR"],"title":"Veeam 重磅发布 Software Appliance：官网下载与文档结构大升级","uri":"/2025/09/veeam-software-appliance-01/"},{"categories":[],"content":"软件下载页 按照这次发布的内容，一共三个组件，下载位置有点不同。 Veeam Software Appliance 本体下载 在 Veeam 中文官网的右上角下载按钮，可以进入下载页，进入后找到 Veeam Data Platform 的下载，直达电梯 (https://www.veeam.com/cn/products/data-platform-trial-download.html?tab=extensions)，这时候可以看到下载选项中多了一个Pre-Hardened Software Appliance（Linux）标签卡，点击切换就能找到备份服务器本体下载，如下图： 这里可以找到这个 Appliance 的版本发布说明，也可以选择 ISO 或者 OVA 格式下载，在最右边还可以申请许可证密钥，如果没有购买正式许可，请务必在这里点击申请密钥申请测试许可，才能使用这个 Appliance。 Veeam Infrastructure Appliance 在上面这个页面下方，可以看到有个更多下载，切换到扩展程序及其他，可以看到有个 Veeam Infrastructure Appliance，点击前面的 + 号，可以打开这个组件的下载框进行下载。 VeeamONE v13 Veeam ONE 的下载页面藏的比较深，如果官网首页直接找的话，可能会找不到，这里给一个直达的电梯 (https://www.veeam.com/cn/products/free/monitoring-analytics-download.html)，虽然是社区版，但是产品安装包是同一个。熟悉 Veeam 网站的朋友也可以从 my.veeam.com 中进入找到 v13 的下载。 ","date":"2025-09-04","objectID":"/2025/09/veeam-software-appliance-01/:3:1","tags":["VBR"],"title":"Veeam 重磅发布 Software Appliance：官网下载与文档结构大升级","uri":"/2025/09/veeam-software-appliance-01/"},{"categories":[],"content":"V13 使用手册 除了软件下载之外，官网文档也有明显优化，Software Appliance 和 Veeam ONE 都推出了对应 v13 的新文档。文档结构也进行了重组，而不是以前大部分功能都写在 vSphere 备份的文档中，毕竟 Veeam 现在的功能已经不再是 VMware 专用备份工具啦。 文档入口： Veeam Software Appliance 使用手册 https://helpcenter.veeam.com/docs/vbr/userguide/overview.html?ver=13 Enterprise Manager 使用手册 https://helpcenter.veeam.com/docs/vbr/em/introduction.html?ver=13 Veeam Explorer 使用手册 https://helpcenter.veeam.com/docs/vbr/explorers/explorers_introduction.html?ver=13 Proxmox 备份使用手册 https://helpcenter.veeam.com/docs/vbproxmoxve/userguide/overview.html?ver=2 VeeamONE v13 使用手册 https://helpcenter.veeam.com/docs/one/userguide/about_one.html?ver=13 ","date":"2025-09-04","objectID":"/2025/09/veeam-software-appliance-01/:3:2","tags":["VBR"],"title":"Veeam 重磅发布 Software Appliance：官网下载与文档结构大升级","uri":"/2025/09/veeam-software-appliance-01/"},{"categories":[],"content":"系列文章预告与快速上手指南 本系列文章将在后续深入讲解 Veeam Software Appliance 的功能亮点、部署要点以及全面的使用介绍，帮助读者更高效地利用 Veeam 的最新资源。如果你也正在探索如何快速掌握新版 Veeam 体验，敬请关注接下来的更新 ","date":"2025-09-04","objectID":"/2025/09/veeam-software-appliance-01/:4:0","tags":["VBR"],"title":"Veeam 重磅发布 Software Appliance：官网下载与文档结构大升级","uri":"/2025/09/veeam-software-appliance-01/"},{"categories":[],"content":"Kasten 在安全方面提供全面的管理能力，其中很重要的一部分是用户的账号访问管理，使用 Kasten 的用户可以灵活的借助 OIDC 的协议完成身份认证。本文以 Azure EntraID 为例，通过为 Kasten 配置 Azure EntraID 的集成，实现 Kasten 控制台的多因子验证。 本配置方法由两部分组成，一部分在 Azure 中完成，另外一部分在 Kasten K10 中完成。 ","date":"2025-05-26","objectID":"/2025/05/kasten-and-azure-entraid-integration/:0:0","tags":["Kubernetes"],"title":"使用 Azure EntraID 为 Kasten 控制台提供多因子验证","uri":"/2025/05/kasten-and-azure-entraid-integration/"},{"categories":[],"content":"Azure 配置 ","date":"2025-05-26","objectID":"/2025/05/kasten-and-azure-entraid-integration/:1:0","tags":["Kubernetes"],"title":"使用 Azure EntraID 为 Kasten 控制台提供多因子验证","uri":"/2025/05/kasten-and-azure-entraid-integration/"},{"categories":[],"content":"第一步 Kasten 用户组创建 首先在 Azure EntraID 中，需要配置一个安全组，我们会将需要访问 Kasten 网页的用户添加到这个安全组中。 在 Azure EntraID 控制台中，我们首先找到 Group，然后 New Group 新建一个。Group type 选择安全组，Group Name 随意起，我这里设置成 Kasten Users，其他选项保持不变如下图： 点击 Create 创建后，回到 All groups 列表中可以看到创建好的组。 然后我们点击进入这个组，找到 Members，在这里通过 Add members 按钮，把需要访问的用户加进来，比如我这里已经把 Lei Wei 添加进来了。 ","date":"2025-05-26","objectID":"/2025/05/kasten-and-azure-entraid-integration/:1:1","tags":["Kubernetes"],"title":"使用 Azure EntraID 为 Kasten 控制台提供多因子验证","uri":"/2025/05/kasten-and-azure-entraid-integration/"},{"categories":[],"content":"第二步 应用注册 在 Azure EntraID 中需要创建一个 App，用来做 Kasten 身份认证的接口，在 Azure EntraID 中找到 App registrations，点击 New registration 就可以进行创建，如下图： 在 New registration 向导中，我们需要起个名字，比如叫 kasten-service，其他选项保持默认，注册即可。 注册完后，立刻进入了这个新创建的 kasten-service 应用属性页面，接着我们需要简单配置下这个应用，让这个应用能够给 kasten 使用。 找到 Manage 下面的 Authentication，在这里要配置下 Platform，我们点击 Add a platform，然后选择 Web Applications 中的 Web，如下图： 这时候，在接下去的 Configure Web 步骤中，设置下 Redirect URIs，这个需要将 kasten 的网页填上来，比如我的 kasten 的 webui 地址是 https://k10-lab-1-node01-71.suzhou.backupnext.cloud/k10，这时候，我需要在这个地址后加上/auth-svc/v0/oidc/redirect组成一个完整的 Redirect URI，如下： https://k10-lab-1-node01-71.suzhou.backupnext.cloud/k10/auth-svc/v0/oidc/redirect 另外，在这个步骤中，还需要勾选 ID tokens 复选框，如图： 点击 save 之后这步就完成了。 接下去，我们还需要一个这个 Application 的 secret，找到 Manage 下面的 Certificates \u0026 secrets，创建一个并记录下来备用。这里需要注意下过期时间，如果过期了，到时候是需要重新创建和更新的。 创建完成后，有复制按钮，复制出来备用。 下一步，我们还要在 Token configuration 中添加一个 group claim，使它能够访问安全组。同样是在 Manage 下，找到 Token configuration，点击 Add group claim，选中 Security groups 后点 add 添加。 ","date":"2025-05-26","objectID":"/2025/05/kasten-and-azure-entraid-integration/:1:2","tags":["Kubernetes"],"title":"使用 Azure EntraID 为 Kasten 控制台提供多因子验证","uri":"/2025/05/kasten-and-azure-entraid-integration/"},{"categories":[],"content":"第三步 收集配置信息用于 Kasten 好，大功告成，那么我们来收集一些信息，去用作 Kasten 的 helm value.yaml 配置。 首先我们来看下 yaml 模版： auth: oidcAuth: clientID: 3cae7658-5192-4122-b31a-1efcb9355a6f clientSecret: xxxxxxxxxxxxxxxxxxxxxxx enabled: true groupClaim: groups groupPrefix: kasten_azure_ prompt: select_account providerURL: https://login.microsoftonline.com/6d2374b4-aceb-42ac-966a-716a93f07db0/v2.0 redirectURL: https://k10-lab-1-node01-71.suzhou.backupnext.cloud scopes: openid email usernameClaim: sub usernamePrefix: kasten_azure_ 上面这个模版中，我们需要 3 个重要信息，分别是 clientID、clientSecret 和 providerURL。 这可以第二步设置的 App 首页中找到，打开 Overview，然后点击上面的 Endpoint，如下图显示的信息： 这里需要注意的是，providerURL 除了复制这个 URL 之外，还需要额外加上/v2.0这个路径。另外，clientSecret 就是第二步中我们记下的那个 Secret。 我们还需要找一下安全组的 ID，这个 ID 会在配置权限时用到。找到 Group 后，看到 Kasten User 的 Overview，找到上面的 Object ID，复制备用。 ","date":"2025-05-26","objectID":"/2025/05/kasten-and-azure-entraid-integration/:1:3","tags":["Kubernetes"],"title":"使用 Azure EntraID 为 Kasten 控制台提供多因子验证","uri":"/2025/05/kasten-and-azure-entraid-integration/"},{"categories":[],"content":"Kasten 配置 回到 Kasten 中，我们先导出一份已经在使用的 Kasten 的 helm yaml helm get values k10 -n kasten-io \u003e k10_values.yaml 编辑这个 k10_values.yaml，将 auth 下面的内容用我们修改好的信息替换后保存： auth: oidcAuth: clientID: 3cae7658-5192-4122-b31a-1efcb9355a6f clientSecret: xxxxxxxxxxxxxxxxxxxxxxx enabled: true groupClaim: groups groupPrefix: kasten_azure_ prompt: select_account providerURL: https://login.microsoftonline.com/6d2374b4-aceb-42ac-966a-716a93f07db0/v2.0 redirectURL: https://k10-lab-1-node01-71.suzhou.backupnext.cloud scopes: openid email usernameClaim: sub usernamePrefix: kasten_azure_ 然后更新下 kasten 的配置： helm upgrade k10 kasten/k10 -n kasten-io -f k10_values.yaml 更新后，等待几分钟，kasten 的 pod 会全部重启下。 重启完成后，再次登入 kasten 网页的时候，会发现网页直接跳转到 Azure EntraID 的认证了。输入 Azure EntraID 的账号并认证后，就能进入 kasten webui 了，但是此时会发现，进入之后没有任何的访问权限。这是因为我们还没为账号绑定 kasten 相关的权限。我们来创建下 kasten 的权限： 下面的命令中，会用到前面提到的安全组的 Object ID，在命令中的 group 信息，由上面 yaml 中的 groupPrefix 的内容和安全组的 ID 组合而成。我这里例子中，groupPrefix 是kasten_azure_而安全组的 id 记下来的是d228b7e7-c10c-488b-9b13-8714682dbb0c，因此我的命令如下： #创建clusterrolebinding kubectl create clusterrolebinding k10-admin \\ --clusterrole=k10-admin \\ --group=kasten_azure_d228b7e7-c10c-488b-9b13-8714682dbb0c #创建rolebinding kubectl create rolebinding k10-admin \\ --role=k10-ns-admin \\ --group=kasten_azure_d228b7e7-c10c-488b-9b13-8714682dbb0c \\ --namespace=kasten-io 创建完成后，再刷新网页，会发现访问就正常了。到此所有配置完成。 ","date":"2025-05-26","objectID":"/2025/05/kasten-and-azure-entraid-integration/:2:0","tags":["Kubernetes"],"title":"使用 Azure EntraID 为 Kasten 控制台提供多因子验证","uri":"/2025/05/kasten-and-azure-entraid-integration/"},{"categories":[],"content":"使用 Azure EntraID 认证 重新打开 Kasten 网页，会立刻重定向到 Azure EntraID 的认证界面。 输入账号密码后，会提示通过 Authenticator 进行多因子验证，需要手机同意授权。 完成之后即可进入控制台，在控制台右上角，可以看到当前用户信息，对应的是前缀 kasten_azure_，而后缀则是 Azure 中对应用户的 User ID。 ","date":"2025-05-26","objectID":"/2025/05/kasten-and-azure-entraid-integration/:3:0","tags":["Kubernetes"],"title":"使用 Azure EntraID 为 Kasten 控制台提供多因子验证","uri":"/2025/05/kasten-and-azure-entraid-integration/"},{"categories":[],"content":"总结 通过和 Azure EntraID 的集成，Kasten 能够快速获得安全可靠的多因子身份验证能力，进一步守护数据的安全。 ","date":"2025-05-26","objectID":"/2025/05/kasten-and-azure-entraid-integration/:4:0","tags":["Kubernetes"],"title":"使用 Azure EntraID 为 Kasten 控制台提供多因子验证","uri":"/2025/05/kasten-and-azure-entraid-integration/"},{"categories":[],"content":"系列目录 数据保护不只是备份，它关乎企业的安全的最后一道防线。Veeam 通过零信任设计理念，将安全性融入到产品的每一处细节。从备份的开始到恢复的最后一步，Veeam 不断打磨每一个功能，以满足现代安全需求。本系列汇聚了 VDP v12 版本后新增的安全小技巧，简单易用，却能为数据安全保驾护航。 第一篇：免账户和 SSH 服务管理 Linux 备份代理 第二篇：使用 gMSA 技术托管 Windows 账号 第三篇：四眼认证模式：双人控制管理备份系统操作 第四篇：启用多因子认证（MFA）：加强备份系统账户保护 第五篇：减少备份中涉及的网络端口 第六篇：使用 Syslog 将日志托管至 SIEM 系统 ","date":"2024-12-16","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-03/:1:0","tags":["Backup","Security"],"title":"VDP 安全技术系列（三） - 四眼认证模式：双人控制管理备份系统操作","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-03/"},{"categories":[],"content":"四眼认证模式，守护 Veeam 备份操作安全 在数字化时代，数据是企业的命脉，备份与恢复的安全性尤为关键。一个误操作或是一个恶意破坏，就可能导致业务中断或数据泄露。为此，**四眼认证模式（Four-Eyes Authorization）**逐渐成为组织保护备份流程的重要策略，通过双人审核机制，为关键任务构筑坚实的安全屏障。 四眼认证模式是一种双重授权策略，广泛应用于财务、法律和 IT 管理等领域，以避免单人操作引发的失误或恶意行为。在专业备份解决方案如Veeam Data Platform中引入这一机制，能有效减少超管权限滥用及人为配置错误所带来的风险，显著提升数据管理的安全性和透明度。 本文深入解析 VDP 四眼认证模式的适用场景、实现步骤和注意事项，帮助您打造更安全的备份环境。 ","date":"2024-12-16","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-03/:1:1","tags":["Backup","Security"],"title":"VDP 安全技术系列（三） - 四眼认证模式：双人控制管理备份系统操作","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-03/"},{"categories":[],"content":"四眼认证模式适用场景 在 Veeam B\u0026R 中，以下关键操作需通过四眼认证： 1. 删除备份操作 删除备份文件、快照或不可用备份记录。 2. 存储基础设施管理 删除备份存储库或存储资源。 3. 用户管理与身份验证 添加、更新或删除用户及用户组。 启用或修改多因素认证（MFA）。 调整自动注销设置。 4. Veeam Cloud Connect 相关操作 服务提供商：删除云存储库，删除导入的租户备份文件。 租户：删除服务提供商，删除备份文件。 另外，四眼认证并不能保护已被攻破的服务器，因此对于服务器的保护，建议结合加固基础设施和遵循最佳实践。 ","date":"2024-12-16","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-03/:1:2","tags":["Backup","Security"],"title":"VDP 安全技术系列（三） - 四眼认证模式：双人控制管理备份系统操作","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-03/"},{"categories":[],"content":"四眼认证模式工作流程 四眼认证在 VDP 中通过以下机制确保操作安全： 1. 操作请求的创建 备份管理员提交敏感操作时，系统会生成请求，需额外审批方可执行。 2. 请求审批的通知与展示 Veeam 控制台：请求显示在“Home”视图的“Pending Approvals”节点下。 邮件通知：已配置全局通知的管理员会收到审批提醒。 3. 审批与处理 如图，管理员或安全管理员审批界面： 备份管理员或安全管理员可批准或拒绝请求，支持批量处理。 请求创建者仅能取消其提交的请求，无法自行批准。 4. 超时自动拒绝 未在规定时间内处理的请求（默认 7 天）将自动被拒绝，避免悬而未决的风险。 ","date":"2024-12-16","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-03/:1:3","tags":["Backup","Security"],"title":"VDP 安全技术系列（三） - 四眼认证模式：双人控制管理备份系统操作","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-03/"},{"categories":[],"content":"前提条件与限制 前提条件 功能仅适用于Veeam Universal License或Enterprise Plus版本。 订阅许可证到期后，已创建请求仍可处理，但无法提交新请求。 限制条件 不支持的操作： 通过 PowerShell、REST API 或 Veeam Backup Enterprise Manager 执行删除操作。 在“Files”视图中编辑、删除或重命名文件/文件夹。 任务锁定限制： 被占用的对象（如运行中的备份任务）无法执行敏感操作，需解锁后重新提交请求。 不可变备份文件保护： 四眼认证一样无法直接删除不可变备份文件（Immutable Backups）。 ","date":"2024-12-16","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-03/:1:4","tags":["Backup","Security"],"title":"VDP 安全技术系列（三） - 四眼认证模式：双人控制管理备份系统操作","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-03/"},{"categories":[],"content":"如何配置四眼认证模式 1. 用户角色配置 确保至少两名用户具备以下角色之一： Veeam Backup Administrator Veeam Security Administrator 2. 启用四眼认证 打开Users and Roles \u003e Authorization设置。 勾选Require additional approval for sensitive operations选项。 设置审批请求有效期（1 至 30 天）。 3. 关闭四眼认证 关闭功能也需另一位管理员审批，确保设置变更的安全性。 ","date":"2024-12-16","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-03/:1:5","tags":["Backup","Security"],"title":"VDP 安全技术系列（三） - 四眼认证模式：双人控制管理备份系统操作","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-03/"},{"categories":[],"content":"操作日志：记录每一步授权 通过操作日志，管理员可追踪四眼认证相关活动： 进入History视图，点击Authorization Events节点。 查看日志内容，包括： 批准/拒绝记录。 四眼认证设置调整。 用户及用户组管理操作。 ","date":"2024-12-16","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-03/:1:6","tags":["Backup","Security"],"title":"VDP 安全技术系列（三） - 四眼认证模式：双人控制管理备份系统操作","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-03/"},{"categories":[],"content":"总结 四眼认证模式为备份操作增添了一道安全屏障，降低了单人误操作和权限滥用的风险。结合 Veeam 的其他安全功能，如权限管理、数据加密及不可变备份，企业可构建更健全的备份策略。 正在使用 Veeam 的朋友，赶紧启用四眼认证模式，保障您的数据安全，为企业发展保驾护航。 ","date":"2024-12-16","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-03/:1:7","tags":["Backup","Security"],"title":"VDP 安全技术系列（三） - 四眼认证模式：双人控制管理备份系统操作","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-03/"},{"categories":[],"content":"系列目录 数据保护不只是备份，它关乎企业的安全的最后一道防线。Veeam 通过零信任设计理念，将安全性融入到产品的每一处细节。从备份的开始到恢复的最后一步，Veeam 不断打磨每一个功能，以满足现代安全需求。本系列汇聚了 VDP v12 版本后新增的安全小技巧，简单易用，却能为数据安全保驾护航。 第一篇：免账户和 SSH 服务管理 Linux 备份代理 第二篇：使用 gMSA 技术托管 Windows 账号 第三篇：四眼认证模式：双人控制管理备份系统操作 第四篇：启用多因子认证（MFA）：加强备份系统账户保护 第五篇：减少备份中涉及的网络端口 第六篇：使用 Syslog 将日志托管至 SIEM 系统 上一篇，我们详细介绍了在 Linux 系统中如何通过免账户和 SSH 服务来管理备份代理。而在 Windows 系统中，情况有所不同，尤其是在 Veeam 备份平台的各种操作场景中，经常会涉及本地管理员账号的使用。例如，在执行虚拟机的 Guest Processing、Indexing 等任务时，以及在管理 Windows 代理或进行各种还原操作时。Veeam 通常会将这些账号储存在本地数据库中，这样做会带来一些潜在的安全风险，攻击者可能会通过破解 Veeam 本地数据库来窃取生成系统的高权限账号；并且还会带来管理上的复杂性，需要定期根据生产系统的需求同步修改存储在备份系统的账户密码，来确保安全性和合规性。 今天，我们就来介绍一种全新的账号使用方式——内置在 Windows 系统中的专用服务账号。Veeam 利用这种技术，可以在进行 Guest Processing 和 Indexing 过程中避免记录 Windows 系统的账户密码，从而进一步减少账号密码泄露的风险。 这个技术叫做 Group Managed Service Account (gMSA)。gMSA 其实是在 Windows 2012 版及以后的版本中推出的技术，尽管已经有 10 多年的历史了，但因其使用相对较少，因此关于它的教程和资料并不常见。 希望这篇文章能够帮助大家更好地理解和应用这一技术！ ","date":"2024-12-09","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-02/:1:0","tags":["Backup","Security"],"title":"VDP 安全技术系列（二） - 使用 gMSA 技术托管 Windows 账号","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-02/"},{"categories":[],"content":"技术背景 gMSA 是一种在 Windows 系统中用于管理和存储服务账户密码的技术，它可以提高安全性并简化管理。它有以下这些特点： 动态密码管理：gMSA 的密码是由 AD 管理的，并且会定期自动更改，任何人无法获取也不需要使用这个账号的密码。 减少密码风险：使用 gMSA 不需要管理员记住服务密码，系统会自动从 AD 中去调取需要的密码进行工作，并且动态自动更新进一步加强了它的安全性。 简化使用流程：在使用了 gMSA 后，备份系统上就不需要去定期手工更新和配置账号密码了，降低了复杂性。 gMSA 技术通过动态管理和自动更新密码的方式，在确保服务稳定性和安全性的前提下，极大地简化了服务账户的管理和维护。它特别适合那些对安全性有较高要求且需要长期运行的备份系统。 ","date":"2024-12-09","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-02/:1:1","tags":["Backup","Security"],"title":"VDP 安全技术系列（二） - 使用 gMSA 技术托管 Windows 账号","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-02/"},{"categories":[],"content":"适用环境 必须有 Windows 2012 以上的 AD 管理的环境，所有需要使用这个技术的虚拟机的操作系统必须是 Windows 2012 以上版本。 无法用于 Linux 操作系统，即使是将 Linux 系统加入到满足条件的 AD 域中。 必须使用 guest Interaction proxy 作为应用感知的处理系统，VIX 模式在这里不工作。 所有涉及到的相关系统都必须能够正常访问 AD 资源，能够从 AD 中去取得需要的账号和权限。 ","date":"2024-12-09","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-02/:1:2","tags":["Backup","Security"],"title":"VDP 安全技术系列（二） - 使用 gMSA 技术托管 Windows 账号","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-02/"},{"categories":[],"content":"环境准备和配置步骤 要使用这一技术，首先要对 AD 环境做一些准备工作。前面我们提到，必须在 Windows 2012 及以上版本中进行操作。进入 AD 的管理单元后，检查一个关键条件是否满足：默认的 Managed Service Accounts OU 必须正常存在。这个 OU 是系统内置的，默认情况下会存在于 AD 中。如下图： 如果这个 OU 不存在或被意外删除了，那么就无法使用 gMSA 技术。可能需要联系微软技术支 持来恢复这个默认的 OU，手工创建同名 OU 是无效的。 在检查完这个 OU 正常后，需要在域控制器上做一些配置，接下去要做的这些配置大部分要通过 Powershell 的命令来完成。因此需要首先确保 AD 上正确安装了 AD 的 Powershell 管理模块，这个可以通过 Windows 的功能和特性模块来确定安装情况。具体位置如下图： 打开 Powershell，首先要创建一个 root Key，用于自动管理 gMSA 的密码，用以下命令即可： Add-KdsRootKey -EffectiveImmediately 需要注意的是，这条命令打完后，虽然参数是立即生效，但是根据我的经验和网上的评论，是隔天生效的，因此如果是跟着我的步骤进行操作的，可以不用接着往下做了，明天回来才能继续进行。 在 AD 中创建一个安全组，在接下去的操作中，我们会把涉及到的相关的所有服务器都放入到这个安全组中，只有在这个组中的服务器，才会被授权使用 gMSA 账号。而不在这个安全组中的计算机，将无权访问 gMSA 账号，这一步骤非常重要。 这个安全组具体创建在哪个 OU 中没有关系，我的这个实验中，我就将它创建在 Users 的 OU 下，如图： 将 VBR 中涉及到的所有服务器，全都添加至这个 Security Group 的 Members 中。我的实验中，会用到两台服务器，一台是需要使用 gMSA 账号管理的备份目标 V100SQL，另外一台是用于做 guest Interaction proxy 的 Win001。如图在 Members 中我已经将他们添加好了： 需要额外注意的是，在添加 Members 的时候，默认情况下搜索对象时是搜索不到 Computer Name 的，必须在 Select object type 时，加上 Computers 的类型才能够搜索到并添加上。 创建 gMSA 账号，以上准备完成后，接着只需要用以下这个命令，即可完成 gMAS 账号的创建： $gMSAName = 'gmsa01' $gMSAGroupName = 'gMSAGroup' $gMSADNSHostName = 'gmsa01.v100lab.local' New-ADServiceAccount -Name $gMSAName -DNSHostName $gMSADNSHostName -PrincipalsAllowedToRetrieveManagedPassword $gMSAGroupName -Enabled $True 创建完成后，gMSA 账号就会出现在Managed Service Accounts这个OU下面： 这样，AD 上面的配置基本上就完成了，接下去的操作，我们需要到每一台要使用 gMSA 账号的 Windows 系统上进行配置了。在配置之前，我们需要刷新一下刚刚创建的 AD 对象信息，将它同步过来，一般可以通过执行以下命令完成： C:\\WINDOWS\\system32\\klist.exe -lh 0 -li 0x3e7 purge 也可以简单粗暴一点，直接重启对应的系统。像我在本次实验中，为了能正常配置，在第六步完成后，我就将我所有的 VM 重启了一遍。 接下来，我先来配置一下 Guest Interaction Proxy，这个配置相对简单一些，允许它进行账号的获取和使用即可，因为我们的 Guest Interaction Proxy 会通过这个账号去发起一些备份操作，因此它需要获得账号的使用权。按照步骤 5 的配置，实际上我们已经正常获得了使用权，此处我们只需要进行一个简单的验证，如果验证结果通过，我们也就无需做更多配置： PS C:\\Users\\Administrator.V100LAB\u003e Test-ADServiceAccount gmsa01$ True 用这个 Test 的命令，只需要保证输出为 True，如果这个输出不为 True 则说明账号没配置成功，需要往上回去检查 1-7 步骤，看看是哪里没有正确配置。 然后，来到目标服务器上，进行相关权限的配置。首先需要做的是将 gmsa 账号装入该目标服务器，命令如下： #测试账号 Test-ADServiceAccount gmsa01$ #安装账号 Install-ADServiceAccount \"gmsa01$\" 一切正常的话，会发现账号已经被安装上了。 配置 gMSA 的本地权限，和其他账号一样，用于 VBR 的备份，我们需要将 gMSA 账号添加到操作系统的本地管理员组，同时对于包含 SQL 的机器，我们需要同样将 gMSA 账号加入到 SQL Server 的 sysadmin 组中。 在添加 SQL 权限时，搜索账号需要特别注意勾选 Service Accounts 选项，否则是搜不到 gmsa 账号的。 以上添加完成后，gMSA 账号的配置就完成了，接下去可以回到 VBR 中配置和测试 gMSA 的账号了。 在 VBR 的备份作业中，开启应用感知选项，在右侧的 Add Credentials 中，可以找到Managed Service Account...点击后，会弹出一个仅需要输入用户名的对话框，这样的方式，我们只需要账号，无需密码，就可以将它用于应用感知。从而实现了 VBR 中免密配置应用感知。 点击 Test Now，测试下这个 gMSA，看看能否正常工作。 可以看到，在使用 gMSA 情况下，Test 是不会去测试 VIX 工作方式的，仅通过 RPC 方式进行验证。 ","date":"2024-12-09","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-02/:1:3","tags":["Backup","Security"],"title":"VDP 安全技术系列（二） - 使用 gMSA 技术托管 Windows 账号","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-02/"},{"categories":[],"content":"总结 以上就是 Windows 下，配置免密的备份账号的方法，例子中以 SQL Server 作为备份对象，如果其他应用程序，也需要配置相应的权限，否则应用感知就会失败。 ","date":"2024-12-09","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-02/:1:4","tags":["Backup","Security"],"title":"VDP 安全技术系列（二） - 使用 gMSA 技术托管 Windows 账号","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-02/"},{"categories":[],"content":"系列目录 数据保护不只是备份，它关乎企业的安全的最后一道防线。Veeam 通过零信任设计理念，将安全性融入到产品的每一处细节。从备份的开始到恢复的最后一步，Veeam 不断打磨每一个功能，以满足现代安全需求。本系列汇聚了 VDP v12 版本后新增的安全小技巧，简单易用，却能为数据安全保驾护航。 第一篇：免账户和 SSH 服务管理 Linux 备份代理 第二篇：使用 gMSA 技术托管 Windows 账号 第三篇：四眼认证模式：双人控制管理备份系统操作 第四篇：启用多因子认证（MFA）：加强备份系统账户保护 第五篇：减少备份中涉及的网络端口 第六篇：使用 Syslog 将日志托管至 SIEM 系统 在任何系统中，获取账号权限都是黑客攻击的起点，备份系统也不例外。账号存储和管理存在一定的安全风险，因此在设计和配置系统时，减少不必要的账号自动记忆和保存是保障安全的重要措施。在备份解决方案中，，Veeam Agent for Linux 引入了免账号管理功能，这能够大大增强了系统的安全性。通过这种方式，用户无需将账号信息存储在系统中，从而有效降低了潜在的安全漏洞和数据泄露的风险。这种免账号管理机制不仅提升了备份的安全防护等级，还简化了管理员的管理流程，对于特殊的系统还能避免使用 SSH 管理协议，使得整体系统更加安全可靠。 另外，对于堡垒机托管 root 密码的环境，这种部署方式也能适应不断变化的账号密码，避免来备份系统中修改存放的密码。 ","date":"2024-12-02","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-01/:1:0","tags":["Backup","Security"],"title":"VDP 安全技术系列（一） - 免账户和 SSH 服务管理 Linux 备份代理","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-01/"},{"categories":[],"content":"工作原理 在部署 Veeam Agent for Linux 前，管理员先到 Linux 机器上，预先安装 Veeam 的部署服务包和临时证书，有了这个服务包后，当 VBR 发起 Agent 推送/管理操作时，VBR 会检测到 Linux 系统上的这个组件，和这个组件建立连接后，检查必要的证书，如果是临时证书，那么 VBR 会下发正式证书替换当前的临时证书。在这之后，VBR 都会用这个有效证书和 Linux 机器通讯，管理和安装相关的 Agent 组件。这个过程完全不需要用到在备份服务器上输入 Linux 机器的管理员用户名和密码。 ","date":"2024-12-02","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-01/:1:1","tags":["Backup","Security"],"title":"VDP 安全技术系列（一） - 免账户和 SSH 服务管理 Linux 备份代理","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-01/"},{"categories":[],"content":"操作步骤 接下来，就跟着我一步一步来看下怎么使用这个功能。 首先需要从 VBR 上导出一下这个预安装的软件包和临时证书，导出需要用到以下 powershell 命令： Generate-VBRBackupServerDeployerKit -ExportPath \"C:\\Users\\Administrator\\Documents\" 打开 VBR 服务器左上角三条横线的汉堡图标，找到 Console 菜单下的 Powershell，输入以上命令，就能获取到这份 Deployer Kit。 到导出的目录下，可以看到以下文件： 其中，rpm 包是用于 redhat 系的安装包，而 deb 则是 debian 系的安装包。根据不同系统，需要拷贝 client-cert.pem、server-cert.p12 和一个 rpm 或 deb 软件包到目标的 Linux 的机器上。 运行命令安装 rpm 包： yum install veeamdeployment-12.2.0.334-1.x86_64.rpm 接着运行命令安装证书： /opt/veeam/deployment/veeamdeploymentsvc --install-server-certificate server-cert.p12 /opt/veeam/deployment/veeamdeploymentsvc --install-certificate client-cert.pem /opt/veeam/deployment/veeamdeploymentsvc --restart 回到 VBR 控制台，创建保护组，在保护组的创建向导中，添加 Linux 主机时，选择Connect using certificate-based authentication，添加完可以使用Test Now按钮测试可连接性。此时，使用certificate-base authentication模式时，VBR 将不再需要任何的 ssh 服务来部署 Veeam Agent for Linux。 一切正常后，就可以安装正常方式完成 Protection Group 的创建，推送 Agent 了。推送过程中，VBR 将会更新目标服务器上的临时证书，将它更新成正式的通讯证书，并安装 Transport service。 以上就是关于 Linux Agent 管理的安全小技巧，希望对您的 IT 系统的安全有帮助，下一期我将带大家来看看 Windows 系统该如何使用免密码的管理方式。 ","date":"2024-12-02","objectID":"/2024/12/vdp-v12-other-security-features-deep-dive-01/:1:2","tags":["Backup","Security"],"title":"VDP 安全技术系列（一） - 免账户和 SSH 服务管理 Linux 备份代理","uri":"/2024/12/vdp-v12-other-security-features-deep-dive-01/"},{"categories":["Linux Agent"],"content":"Linux 高度自由的开源系统让每个人都有自己使用它自己的使用方式，这让对于操作系统深度依赖的备份软件变的各种不适。细微的一些变化就会引起备份失败，因此备份软件通常都会有一个兼容列表，不在列表中的系统通常无法工作。 这类问题普遍存在于开源世界，虽然没办法一把解决这个问题，但是如果能解决大部分，那也是不错的，不是吗？ 在 Veeam Linux Agent 中，有一种非常特殊的工作模式，我把它称为万金油模式。它不需要加载 Veeamsnap 驱动程序，不需要使用 dkms 模块编译驱动程序，因此能够适配绝大多数环境，实现非标准环境的数据备份。 我们知道，Veeam 官方支持的 Linux 操作系统列表有限，国内常见的欧拉、龙晰、统信、麒麟等系统，按照常规的 Veeam Linux Agent 配置步骤来进行是肯定无法安装的，这时候手工安装 Veeam Linux Agent no-snap 的模式，就能解决这个问题，让这些系统也能够备份至 Veeam 的存储库中。 另外，如果稍稍加一些小条件，还能实现整机备份和 BMR 恢复。 本文以 OpenEuler 为例，来给大家详细说说整个过程以及其中的注意事项。 ","date":"2024-11-25","objectID":"/2024/11/veeam-agent-for-linux-nosnap/:0:0","tags":["备份"],"title":"使用无快照模块的 Veeam Agent for Linux 备份各种魔改 Linux","uri":"/2024/11/veeam-agent-for-linux-nosnap/"},{"categories":["Linux Agent"],"content":"去哪里找这个 Agent? 和其他的 Veeam Agent for Linux 一样，我们有两种方式可以获取到这个 Agent 安装包。 一种是在 VBR 的控制台上，我们只需创建一个类型为Computers with pre-installed backup agents的 Protection group。 在创建向导中，可以找到各种 Linux 版本的 Nosnap 的 Agent，本次实验我们用于 Red Hat 系魔改的 Euler 系统，所以我们选择Red Hat 9 x64 no-snap - 6.2.0.101即可。 在设置完 Export 路径后，就可以点击 Apply 生成 no-snap 的安装包，在 Export path 中，就能找到对应的这个 rpm 包。 另外，我们还能够在 Veeam 官方的软件 repository 中，直接下载到这个 nosnap 的包。 网址如下：https://repository.veeam.com/backup/linux/agent/rpm/el/9/x86_64/ 最新版本需要下载两个文件，一个是 veeam-nosnap-6.2.0.101-1.el9.x86_64.rpm，另外一个是 veeam-libs-6.2.0.101-1.x86_64.rpm。 ","date":"2024-11-25","objectID":"/2024/11/veeam-agent-for-linux-nosnap/:0:1","tags":["备份"],"title":"使用无快照模块的 Veeam Agent for Linux 备份各种魔改 Linux","uri":"/2024/11/veeam-agent-for-linux-nosnap/"},{"categories":["Linux Agent"],"content":"安装和配置 这个包安装非常简单，直接一个yum install ~/nosnap/veeam*命令即可。yum 会自动解析当前需要的依赖包，一般来说也没什么额外的依赖包需要，安装在几秒钟内顺利完成。 安装完成后，我们可以回到 VBR 控制台上，找一个合适的 Protection Group 或者新建一个 Protection Group，然后再将这台机器添加进来，这样 VBR 就能管理这台 OpenEuler 了。 为新的 Protection Group 起个名字： 以 IP 地址的方式添加目标计算机： 添加后，走完向导，VBR 会检测下目标服务器上已经安装的 Agent，发现已经安装后，就不会再去检测兼容性和安装条件了，直接使用已安装的配置。 这时候，VBR 控制台上正确的显示了当前的操作系统为 OpenEuler。 ","date":"2024-11-25","objectID":"/2024/11/veeam-agent-for-linux-nosnap/:0:2","tags":["备份"],"title":"使用无快照模块的 Veeam Agent for Linux 备份各种魔改 Linux","uri":"/2024/11/veeam-agent-for-linux-nosnap/"},{"categories":["Linux Agent"],"content":"备份模式 no-snap Linux agent 其实并不是完全没有 snap，这个 Agent 它其实有两种工作模式，一种是真的不拍快照，这样对于有些处于打开状态的文件，比如备份那一刻，某个文件正在编辑，那么这个文件可能就只能被跳过了；而另外一种则是不调用 Veeamsnap，使用 LVM 卷的 snapshot 替代 Veeamsnap 进行工作，这个模式几乎就和 Veeamsnap 非常相似了，不同之处在于，两者快照技术的不同，LVM snapshot 的所有前提条件都需要被正常满足才能让这个模式正常工作。 ","date":"2024-11-25","objectID":"/2024/11/veeam-agent-for-linux-nosnap/:0:3","tags":["备份"],"title":"使用无快照模块的 Veeam Agent for Linux 备份各种魔改 Linux","uri":"/2024/11/veeam-agent-for-linux-nosnap/"},{"categories":["Linux Agent"],"content":"LVM 快照前提条件 简单来说，一句话，有足够的 Free PE. 大家可以通过 vgdisplay 命令查到这个空间，如下图。 LVM 卷快照，会将快照的变化数据存放在这个区域，因此在做 LVM 分区规划的时候需要提前考虑这部分区域空间分配，至少要留出总磁盘容量的 10%~20%。 ","date":"2024-11-25","objectID":"/2024/11/veeam-agent-for-linux-nosnap/:0:4","tags":["备份"],"title":"使用无快照模块的 Veeam Agent for Linux 备份各种魔改 Linux","uri":"/2024/11/veeam-agent-for-linux-nosnap/"},{"categories":["Linux Agent"],"content":"备份和恢复 备份恢复没有什么特别的，Veeam Agent 能够自动感知到底层的配置，自动使用 LVM 卷的快照能力备份数据。而在恢复选项上，所有常规能使用的恢复手段，对于这个备份存档也都可用，包括 BMR 恢复。 使用 LVM 卷快照备份，我们可以在备份作业设置时，选择Entire Machine或者Volume level backup模式。 这样在备份作业进行时，能够正常调用快照进行备份。 备份完成后，正常的所有恢复选项都可以使用，包括 BMR、FLR、应用程序对象恢复、跨平台迁移等等、 如果需要进行裸机 BMR 恢复，就需要到 Veeam 官方的软件仓库中下载合适的 Recovery Media 来引导裸机服务器。下载地址为： https://repository.veeam.com/backup/linux/agent/veeam-recovery-media/x64/veeam-recovery-amd64-6.0.0.iso ","date":"2024-11-25","objectID":"/2024/11/veeam-agent-for-linux-nosnap/:0:5","tags":["备份"],"title":"使用无快照模块的 Veeam Agent for Linux 备份各种魔改 Linux","uri":"/2024/11/veeam-agent-for-linux-nosnap/"},{"categories":["Linux Agent"],"content":"BMR 恢复过程 我们用这个下载的 ISO 引导服务器后，目标服务器会立刻自动进入 Veeam 的引导界面，这个界面上，我们选择第一项Veeam recovery 6.1.0-23-amd64就行了。 选择后，系统会提示 SSH 连接，如果不方便控制台操作，可以选择 Start SSH now，这样 Veeam Recovery Media 也支持远程 SSH 控制进行恢复。 接下来，会有个使用前的惯例，接受许可协议。两个选项都选上X后选Continue继续。 这时候系统会进入 Veeam Recovery Media 的恢复主菜单，上面有卷恢复、文件恢复、设置网络、退回到 shell 以及重启关机这些菜单。 使用前，我们先配置下网络，这样我们一会儿就能通过网卡连接到 VBR 服务器上读取备份存档。网络配置也不复杂，常规的 IPv4 的 IP 地址即可，同时根据需要配置上 DNS 服务器。 配置完成 IP 后，直接点 restore Volume 就会弹出选择备份位置的窗口，这里我们选 VBR 备份服务器。 需要注意的是，为了更安全的恢复，我们需要从备份服务器上为相关的备份存档创建一个 Token。Token 创建后，需要妥善保存，默认可以使用 24 小时。 在备份服务器的连接界面上，输入 IP 地址和端口，选择 Recovery Token 并输入刚刚生成的 Token 后点击 Next 来连接。 如果自签名证书不信任的情况下，系统有可能会像我一样弹出一个警告，这搞关系不大，直接选 Accept 即可。 这时候，我们的还原点就会出现，选择这个还原点进行下一步。 这时候系统自动读取当前分区，如果分区大小相同的情况下，这时候，自动选择右边的相关设备进行 Mapping 即可。Mapping 完成后按 S 键就能开始进行自动还原了。 其他的恢复方法，还有即时虚拟机恢复、文件级恢复，导出成 VHD 和 VMDK 等等。 ","date":"2024-11-25","objectID":"/2024/11/veeam-agent-for-linux-nosnap/:0:6","tags":["备份"],"title":"使用无快照模块的 Veeam Agent for Linux 备份各种魔改 Linux","uri":"/2024/11/veeam-agent-for-linux-nosnap/"},{"categories":["Linux Agent"],"content":"注意事项 以上的 no-snap 的方式进行数据备份和恢复，Veeam 官方的系统支持列表依然非常重要，不在官方支持列表中的各种操作系统，虽然能够正常工作了，但是 Veeam 官方售后不会对这些操作系统进行售后支持，任何技术问题，可能需要我们聪明的 Linux 系统管理员自己搞定了。 ","date":"2024-11-25","objectID":"/2024/11/veeam-agent-for-linux-nosnap/:0:7","tags":["备份"],"title":"使用无快照模块的 Veeam Agent for Linux 备份各种魔改 Linux","uri":"/2024/11/veeam-agent-for-linux-nosnap/"},{"categories":["Repository"],"content":"上一期，我给大家介绍了国庆前 Veeam 发布的 Veeam Managed Hardened Repository 社区预览版，今天这一篇，我手把手带大家一步一步来安装和配置这个系统。 本次帖子中的部署，为了方便我使用了 VMware 平台上的虚拟机进行部署，大家如果有条件完全可以在物理硬件上进行部署，部署过程中如果发现任何问题，可以随时联系我进行反馈。 ","date":"2024-10-12","objectID":"/2024/10/veeam-hardened-repository-iso-2/:0:0","tags":["备份"],"title":"【社区预览版】Managed Hardened Repository ISO by Veeam（下）","uri":"/2024/10/veeam-hardened-repository-iso-2/"},{"categories":["Repository"],"content":"虚拟机配置 本次安装环境如下： vSphere 虚拟机 Guest OS 类型：Redhat Enterprise Linux 9 vCPU：2 个 RAM： 8G 2 个虚拟磁盘，一个 150G，一个 200GB 需要注意的是，不管是用虚拟机还是物理机进行这个系统的安装，必须启用 UEFI 中的安全引导 (secure boot) 功能，这是强制的必要条件，也是安全加固过程中的重要手段之一。 在 VMware 虚拟机的配置页面上，可以找到下图确认，默认情况下对于 Redhat 9，这个选项是启用状态。 ","date":"2024-10-12","objectID":"/2024/10/veeam-hardened-repository-iso-2/:0:1","tags":["备份"],"title":"【社区预览版】Managed Hardened Repository ISO by Veeam（下）","uri":"/2024/10/veeam-hardened-repository-iso-2/"},{"categories":["Repository"],"content":"安装系统 开机后从光驱引导，会进入“Install Hardened Repository”安装界面，需要注意的是，如果安装界面下图不同，提示 Rocky Linux 9 的安装界面，那么上一步的 Secure Boot 配置出现了问题。 接下去，ISO 进入简单的引导，就可以进入图形化安装界面。 安装界面非常简单，可以看到左上角的系统名称提示：Rocky Linux provided by Veeam，而右上角会有红色的 Pre-release/Testing 的提醒，不建议在生产环境中使用。 这个界面和绝大多数 Redhat 系的 Linux 安装界面非常相似，只是更加简洁，在这个界面上，需要做 4 个设置： Keyboard Installation Destination Time \u0026 Date Network \u0026 Host Name 这些设置基本上都非常简单，属于一看就懂的，也无需多解释。 Keyboard 键盘设置，只需要点进去确认下，我们国内大多数都是用 us 键盘布局。 Installation Destination 这部分可以点进去确认下，一般安装程序会自动识别现有磁盘，最小空间的用于安装系统，另外大的空间会用于 VBR 的 Hardened Repository 空间。点击 Return 可以回前一页。 Time \u0026 Date 这里需要设定下时区和 NTP Server。我把时区设置为 Asia/Shanghai，时间服务器加上了阿里云的 ntp.aliyun.com。 Network 在网络设置里，网卡会被自动识别出来，然后可以配置上 IP 地址和主机名，这里如果有多块网卡，可以设置网卡的 bonding。 这样设置之后，Begin Installation 按钮就会蓝色亮起，点它就能进入全自动的安装过程了。 安装非常快，大约几分钟，系统就装完，可以点击 Reboot System 进入安装完成后的 Hardened Repository 系统。 ","date":"2024-10-12","objectID":"/2024/10/veeam-hardened-repository-iso-2/:0:2","tags":["备份"],"title":"【社区预览版】Managed Hardened Repository ISO by Veeam（下）","uri":"/2024/10/veeam-hardened-repository-iso-2/"},{"categories":["Repository"],"content":"配置 Hardened Repository 系统重新引导后，会看到 Rocky Linux 的引导界面，这样系统就安装成功了，选第一项就能进入 Hardened Repository 系统。 进入系统后，会看到非常简洁的命令行欢迎界面，如下图，它会提示当前是 Veeam Hardened Repository 系统，它的 IP 地址是：10.10.1.83，以及一个登入提示。 输入 vhradmin 就能进行登入，默认密码是 vhradmin，但是需要注意的是，在第一次登入的时候，就会提示进行密码修改，这个密码修改会有严格的复杂性要求和时间要求，请在登入前提前准备好以下复杂性的避免： 至少一个数字 至少一个小写字母 至少一个特殊字符 15 个字符以上 4 个连续的字符不能属于同一类（比如密码中连续 4 个小写字母或者连续 4 个数字） 一天只能修改一次密码 密码修改完成后，就会进入首次配置界面，需要 Accept 一下 License Agreement。 点击 I Accept 之后，会进入 Configurator 的主菜单。 这个 Configurator 有一些基本配置，其中 Network settings、Time Settings 和 Change hostname 在安装阶段已经设置过了，在这个菜单中，还能进行调整。 除了这个之外，还有几项配置功能： Proxy Settings Change Password Reset time lock Start SSH Logout Reboot Shutdown 这些配置大部分没啥特别，一看名字就知道干啥用。有两个需要注意，Proxy Setting，可以帮助管理员设置无法直接上网的系统通过 Proxy 访问 repository.veeam.com 网站，完成 Hardened repository 系统的在线更新；而 Reset time lock 用于 Hardened repository 长期处于关机后，时间出现重大的改变的时候，进行系统时间的解锁。 Start SSH 这个 Configurator 的最重要的功能，就是 Start SSH 菜单，这是首次在 VBR 中配置注册需要打开的，否则 VBR 中目前就无法完成首次配置，在首次配置完成后，需要回来 Stop SSH。 点击 Start SSH 后，屏幕上会出现用于在 VBR 中配置需要的所有信息，包括用户名、密码、主机名、IP 地址、系统指纹等。 这时候，需要回到 VBR 中进行配置了，在配置结束前，保持这个屏幕不要点击 Continue 按钮。 在 VBR 中添加选择 Hardened Repository 类型，进入 Linux 主机的添加，在这里输入用户名密码，不需要勾选Use \"su\" if \"sudo\" fails 接下去只要一路 Next 就能完成这个 Linux 主机的添加。添加完成后，会返回 Repository 的添加向导。在 Repository 向导中，需要选择一下挂载的空间目录，如下图： 目录的路径是/mnt/veeam-repository01，这个路径下的文件系统已经被正确的格式化成了 XFS，能够支持 fast clone 功能。配置完成后，在 Repository 列表中，能够看到配置结果。 这时候，回到 Hardened Repository 的 Linux 控制台，如果时间超过了内置的 timeout 时间，该控制台会返回到最初始的登陆界面，我们需要重新登入然后 stop SSH 这样，Hardened Repository 系统就完全准备完了，可以进行接下去的备份和还原测试了。 ","date":"2024-10-12","objectID":"/2024/10/veeam-hardened-repository-iso-2/:0:3","tags":["备份"],"title":"【社区预览版】Managed Hardened Repository ISO by Veeam（下）","uri":"/2024/10/veeam-hardened-repository-iso-2/"},{"categories":["Repository"],"content":"自从 Veeam v11 起，Veeam 推出了加固的备份存储库，这个存储库已经在全球范围内被 Veeam 的客户广泛使用，很多客户使用自己的 Linux 系统构建了加固存储库，为 Veeam 提供安全可靠的数据存储，成功抵抗了各种勒索病毒的攻击。 在过去的几年里，为了能帮大家更方便的配置加固存储库，我曾经出过不少脚本和工具方便大家使用： 用了这个方法，您的备份数据再也不怕被勒索了 Veeam Hardened Linux Repository Configurator Ubuntu 系统用于 Veeam 加固存储库的进一步安全加固 在 9/30，Veeam R\u0026D 团队正式发布了 Hardened Repository 的另外一种部署方式，一个用于从“零”开始搭建系统的 Linux ISO，管理员可以用这个 Veeam 封装的 ISO 快速部署裸机服务器，安装 Hardened Repository 操作系统，安装完成后，该系统就已经部署了 Veeam Hardened Repository 的一系列最佳实践，管理员可以在 VBR 中进行后续的配置和管理。 ","date":"2024-10-03","objectID":"/2024/10/veeam-hardened-repository-iso/:0:0","tags":["备份"],"title":"【社区预览版】Managed Hardened Repository ISO by Veeam（上）","uri":"/2024/10/veeam-hardened-repository-iso/"},{"categories":["Repository"],"content":"功能说明 这是一个 Veeam 封装的 Linux 系统安装盘，Linux 系统使用的是 Rocky Linux，在这个系统安装完成后，对于底层系统会自动应用 DISA STIG 安全配置文件，禁用 SSH 并启用时间修改保护。该系统内置了 Hardened Repository Configurator 工具，该工具能够： 配置系统网络 设置 HTTP 代理 修改主机名 修改 vhradmin 这个 user 的密码 临时启用 SSH 升级 OS 和 Veeam 组件 重置时间更改保护 注销/重启/关机 10 分钟后自动注销。 ","date":"2024-10-03","objectID":"/2024/10/veeam-hardened-repository-iso/:0:1","tags":["备份"],"title":"【社区预览版】Managed Hardened Repository ISO by Veeam（上）","uri":"/2024/10/veeam-hardened-repository-iso/"},{"categories":["Repository"],"content":"系统需求 这个 Linux 系统可以安装在任何Redhat 官方兼容列表中所列出的物理硬件上，对于 CPU 和内存的需求，请遵循 Veeam 帮助文档中列出的最佳实践的要求，对于存储，必须准备至少两个物理卷，比如/dev/sda、/dev/sdb，而安装操作系统的卷最小的容量为 100GB，否则系统安装过程中就会出现报错。 该系统仅支持内置 Raid 卡或者磁盘控制器的存储系统，对于通过 iSCSI 或者 FC 挂载到服务器上的 LUN，无法正常工作。对于软 Raid 和假 Raid 系统，也无法支持。所有存储的配置必须在安装系统前完成，系统安装开始后，该系统安装程序会识别到相关磁盘并进行自动格式化。 系统安装过程中，安装程序会自动选择容量最小的磁盘安装操作系统，所以在磁盘选择配置的时候，请务必保证期望安装系统的磁盘小于数据盘。 ","date":"2024-10-03","objectID":"/2024/10/veeam-hardened-repository-iso/:0:2","tags":["备份"],"title":"【社区预览版】Managed Hardened Repository ISO by Veeam（上）","uri":"/2024/10/veeam-hardened-repository-iso/"},{"categories":["Repository"],"content":"操作系统安全设计逻辑 这个 Hardened Repository 安装盘设计了以下安全配置： 自动应用 DISA STIG 安全配置文件。这个包括密码复杂度要求、应用程序白名单、UEFI 安全启动等等。 安装完成后禁用所有网络服务侦听，包括禁用 SSH。 在这个系统上配置了两个用户，一个是 veeamsvc，另外一个是 vhradmin。 veeamsvc 用来运行 VBR 的所有服务，并且密码是通过 Hardened Repository Configurator 自动生成的，该用户具有 sudo 权限，在 VBR 中配置 Hardened Repository 会用到这个账号进行一次性配置。 vhradmin 账号没有任何的 sudo 权限，并且只能运行 Hardened Repository Configurator 这个程序，用于维护系统的基本配置。这个账号的默认密码为“vhradmin”，该密码会强制在第一次登陆时修改。 所有安全自动更新来自 repository.veeam.com 源，如需获取自动更新，需要开通这个网站的访问权限。 目前，这个加固存储库系统开始了社区预览版，版本号是 0.1.15，有兴趣的朋友可以到Veeam 社区论坛下载试用。因为是技术预览版，不建议在生产环境中商用，并且暂时也没有 Veeam 的技术支持。在未来，Veeam 计划会发布正式的完整产品版本，到那个版本，Veeam 官方的技术支持将会对这个 ISO 部署的 Linux 系统提供全面完整的技术支持。 还需要注意的是，这个预览阶段，产品也不支持升级到未来的正式版本，到时候正式版本还是需要完整重新安装。 这个社区技术预览版的所有技术支持，都可以直接在论坛下载贴中提问和回复，如果有需要，也可以公众号上留言联系我。 以上就是本期内容，在下一期我会为大家带来详细的安装说明。 ","date":"2024-10-03","objectID":"/2024/10/veeam-hardened-repository-iso/:0:3","tags":["备份"],"title":"【社区预览版】Managed Hardened Repository ISO by Veeam（上）","uri":"/2024/10/veeam-hardened-repository-iso/"},{"categories":[],"content":"在快速变化的数字化世界中，保持领先不仅是一种优势，更是一种必要。VMware Explore 2024 是一个汇集全球 IT 精英、展示最新技术成果、探讨未来创新趋势的平台。今年，这一盛会将在美丽的巴塞罗那举行，从 11 月 4 日到 11 月 7 日，为参会者提供一场充满灵感与启迪的技术盛宴。 无论是经验丰富的 IT 专业人士，还是刚刚踏入技术领域的新人，VMware Explore 都为所有人提供了宝贵的学习机会和行业洞见。与会者将有机会亲身体验最新的技术创新，聆听行业领袖的洞见，与来自世界各地的同行建立联系，汲取灵感，开拓思维。 今年的 VMware Explore 2024 Barcelona 站注定不同凡响。除了常规的主题演讲、技术展示和互动体验外，大会还准备了一系列丰富多彩的分会场和专题讨论，涵盖云计算、安全性、现代应用等前沿话题。每一个细节都精心设计，只为带来最丰富、最深刻的参会体验。 今年欧洲站的 VMware Explore 将会在巴塞罗那的会展中心举办，最近大会官方正式开放了欧洲站的注册，有兴趣的朋友可以到以下链接了解详情：官网注册 在官网公布的早鸟计划中，在 7 月 29 日前注册，还能立减 200 欧元。 ","date":"2024-07-04","objectID":"/2024/07/vmware-explore-barcelona/:0:0","tags":["VMware"],"title":"VMware Explore Barcelona 前瞻","uri":"/2024/07/vmware-explore-barcelona/"},{"categories":[],"content":"场馆 VMware Explore 2024 Barcelona 站将于 Fira Gran Via 举行，这座现代化的展览中心是欧洲最重要的会展场馆之一，以其先进的设施和便捷的交通而闻名。位于巴塞罗那的核心地带，Fira Gran Via 不仅为各种大型国际会议和展览提供了理想的场所，也为参会者带来了丰富多彩的城市体验。 先进的基础设施 Fira Gran Via 拥有 8 个展厅，总展览面积超过 240,000 平方米。其建筑设计由著名建筑师丰·米拉（Toyoo Itō）操刀，融合了现代感与功能性，每个展厅都配备了最先进的技术设施，确保活动能够顺利进行。从高效的空调系统到高速的网络连接，场馆的一切设施都旨在为参会者提供最佳的体验。 便利的交通 Fira Gran Via 地理位置优越，交通便利。无论是乘坐公共交通还是自驾，参会者都能轻松抵达。场馆紧邻巴塞罗那地铁 L9 号线，连接市中心和机场，方便参会者快速往返。除此之外，场馆周围还有多条巴士线路，确保参会者无论从城市的哪个角落出发，都能便捷到达。 丰富的配套服务 Fira Gran Via 不仅提供了顶尖的会议设施，还配备了丰富的配套服务，包括多家餐厅、咖啡馆和休息区，方便参会者在繁忙的会议日程中放松休息。场馆内设有现代化的商务中心，提供打印、复印、快递等服务，确保参会者在需要时能够得到全方位的支持。 ","date":"2024-07-04","objectID":"/2024/07/vmware-explore-barcelona/:0:1","tags":["VMware"],"title":"VMware Explore Barcelona 前瞻","uri":"/2024/07/vmware-explore-barcelona/"},{"categories":[],"content":"酒店 参加 VMware Explore 2024 Barcelona 站，除了精彩纷呈的活动安排，一个舒适便利的住宿环境也是必不可少的。为此，活动官方精心挑选了多个不同档次的会务酒店，从经济实惠的三星级酒店到豪华舒适的五星级酒店，满足不同参会者的需求。这些酒店包括国际连锁品牌和本地特色品牌，并且提供了极具竞争力的协议价，确保您在巴塞罗那的住宿既舒适又划算。酒店列表链接 三星级酒店 B Hotel：位于市中心，交通便利，提供简洁舒适的客房和免费 Wi-Fi，是经济型住宿的优选。 四星级酒店 Alexandra Hotel – Curio by Hilton：这家酒店提供高品质的服务和设施，如免费 Wi-Fi、会议室和餐厅，是商务旅客的理想选择。 Renaissance Barcelona Fira：提供现代化的客房、健身中心和屋顶游泳池，适合商务和休闲旅客。 五星级酒店 InterContinental Barcelona：这家五星级酒店提供奢华的客房、多个餐饮选择和一个水疗中心，是享受豪华生活的理想之选。 Meliá Barcelona Sarrià：位于市中心的这家豪华酒店提供豪华客房、屋顶泳池和全方位的水疗服务，满足您对奢华住宿的所有期望。 ","date":"2024-07-04","objectID":"/2024/07/vmware-explore-barcelona/:0:2","tags":["VMware"],"title":"VMware Explore Barcelona 前瞻","uri":"/2024/07/vmware-explore-barcelona/"},{"categories":[],"content":"往届回顾与今年展望 往届回顾 VMware Explore 作为 IT 界备受瞩目的年度盛会，历年来都吸引了成千上万的专业人士、行业领袖和技术爱好者。从其前身 VMworld 开始，这一活动一直是技术创新、知识共享和行业交流的重要平台。 VMware Explore 2023 举办地：VMware Explore 2023 在美国拉斯维加斯和巴塞罗那两地举办，吸引了来自全球的与会者。 技术展示：展示了最新的云计算、虚拟化和网络安全技术，众多行业领先企业在展会上发布了创新产品和解决方案。 演讲亮点：行业领袖们的主题演讲引人入胜，包括对未来技术趋势的预测和成功案例分享。 互动体验：动手实验室和技术工作坊大受欢迎，参会者亲身体验了最新技术，深入了解了产品功能。 VMware Explore 2022 举办地：VMware Explore 2022 在旧金山举行。 创新展示：重点展示了云原生应用和边缘计算，多个突破性技术发布令人印象深刻。 社区互动：丰富的社交活动和主题派对，为参会者提供了绝佳的交流和网络机会。 每一届 VMware Explore 都在推动技术的前沿发展，通过多样的演讲、展示和互动环节，激发了无数与会者的创新灵感和职业热情。 今年展望 VMware Explore 2024 Barcelona 今年的 VMware Explore 2024 将在充满活力和魅力的巴塞罗那举行，预计将再次成为行业焦点。以下是今年活动的一些展望： 重量级演讲嘉宾：今年将有更多的行业领袖和技术专家登台分享他们的洞见和经验，深入探讨云计算、网络安全、虚拟化等前沿话题。 最新技术展示：VMware Explore 2024 将展示最新的技术进展和创新解决方案，包括云计算、边缘计算、人工智能和机器学习等领域的突破。 丰富的分会场：多个分会场将涵盖从技术架构到实际应用的广泛话题，满足不同背景和兴趣的参会者需求。 互动体验升级：今年的互动环节将更加丰富，包括更多的动手实验室、技术工作坊和一对一专家咨询，帮助参会者深入了解技术细节。 社交与网络机会：一系列精心安排的社交活动和主题派对，将为参会者提供更多的交流和合作机会，打造一个真正的行业社区。 ","date":"2024-07-04","objectID":"/2024/07/vmware-explore-barcelona/:0:3","tags":["VMware"],"title":"VMware Explore Barcelona 前瞻","uri":"/2024/07/vmware-explore-barcelona/"},{"categories":[],"content":"更多资料 官网： 注册链接 住宿：酒店链接 博客：官网帖子 ","date":"2024-07-04","objectID":"/2024/07/vmware-explore-barcelona/:1:0","tags":["VMware"],"title":"VMware Explore Barcelona 前瞻","uri":"/2024/07/vmware-explore-barcelona/"},{"categories":[],"content":"在 VDP v12.1 中，不仅在备份过程中和备份结束后，加入了安全扫描功能，在管理上，对于监控和合规性方面都有全新的能力提升。为了更好的帮助管理员提升备份系统的安全性，VBR 对于自身的安全合规方面，加入了全自动的安全合规检测能力 Security \u0026 Compliance Analyzer；同时在高级版中，推出了全新的 Threat Center 仪表盘。 ","date":"2024-05-06","objectID":"/2024/05/vdp-v12-1-security-feature-deep-dive-03/:0:0","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（三）- 全面威胁监控","uri":"/2024/05/vdp-v12-1-security-feature-deep-dive-03/"},{"categories":[],"content":"Security \u0026 Compliance Analyzer 这个组件在 v12 中就已经有了，当时的名称是 Best Practices Analyzer，但是第一个版本中功能不算太完善，检测能力稍显薄弱。在新版本中，Best Practices Analyzer 改名为 Security \u0026 Compliance Analyzer，并且能力大大加强了。 在 v12.1 中 Security \u0026 Compliance Analyzer 包含 31 项安全检测，分别检查 VBR 所在的操作系统以及备份基础架构的安全最佳实践。 使用方法 Security \u0026 Compliance Analyzer 使用非常简单，在 VBR 控制台的 Home 界面中，上方的工具栏按钮点击即可进入。 进入后，Security \u0026 Compliance Analyzer 就开始自动扫描当前的环境，几分钟后扫描就会完成，在右边的状态栏分别显示每一项检测的结果。绿色的✅为检查通过，符合安全最佳实践；而红色的❌表示该项最佳实践检测失败，当前环境需要优化；另外还会有一种黄色的⚠️状态，表示当前环境无法检测。 关于这 31 项检测内容，可以参考官网手册，了解详细。 除了打开界面检测外，这个 Security \u0026 Compliance Analyzer 还支持定时计划任务扫描检测当前环境，系统自动在每天的某个时间运行所有检测，检测完成后，发送通知到指定的管理员邮箱。 这样做能确保环境中所有的安全措施是持续被管理和监控的，避免随意修改和破坏系统配置。 检测后的处理 在这个检测中提示的一些安全问题，可以通过相关的操作系统安全加固手段完成备份系统的安全加固，为了便于管理员更方便的处理，Veeam 特别收集了这些加固的操作方法，并且制作成了一键加固的脚本，管理员可以参考并根据实际需求修改这个脚本进行系统加固。这个脚本可以到这个知识库链接中找到：KB4525。 当然，安全和方便永远都是相对的，如果有些选项管理员认为必须保留，那么 Veeam 也提供了 Suppress 按钮，用于排除检测。 ","date":"2024-05-06","objectID":"/2024/05/vdp-v12-1-security-feature-deep-dive-03/:0:1","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（三）- 全面威胁监控","uri":"/2024/05/vdp-v12-1-security-feature-deep-dive-03/"},{"categories":[],"content":"Threat Center 威胁检测中台 在 VDP 高级版中（此功能需要激活高级版许可，并正确安装和配置了 VeeamONE 组件），加入了全新的集成了 Veeam ONE 的仪表盘面板。备份和安全管理员无需切换控制台至 Veeam ONE Dashboard 就可以立刻查看到当前备份系统中安全相关的重要信息。 在 VBR 的控制台中，导航栏多了一个栏目Analytics，在这个视图下面，内置了 4 个仪表盘，分别是 Threat Center、Overview、Backup Heatmap 和 Jobs Calendar，这些仪表盘都是来自 Veeam ONE Dashboard，管理员也可以直接通过 Veeam ONE Dashboard 找到这些仪表盘。 在目前发布的第一个版本中，VBR 内嵌的这个 Threat Center 还有一些些小问题，上面的内容暂时不支持自定义配置，如果对于显示内容有一定要求的，可以进入 Veeam ONE Dashboard 的 Threat Center 页面，在这里可以自由定制相关内容。 Threat Center 展示内容 Threat Center 由 4 部分组成，左上角是一个 Data Platform 的打分表，Veeam ONE 根据收集到的数据从平台安全合规性、数据可恢复性的健康度、数据保护状态以及备份不可变状态这几个维度出发对整个平台以百分比的形式进行得分计算，分数过低，会给出黄色和红色的状态。 右上角是一个恶意攻击检测侦测地图，根据 Repository 所在位置，Threat Center 通过世界地图展示出潜在的恶意攻击行为发生的地理位置。 左下角是 RPO 异常分析表，这个表会将所有需要保护的 workload，根据设定的 RPO，帮我们找出那些 RPO 没有达到预期的业务系统。 在右下角，是 SLA 合规性状态，假如有任何备份作业出现失败的情况下，在这个红绿的 Heatmap 中就会有异常的红色区块显示，那么在过去的一段时间，曾经出现的问题在这个区域会被醒目的罗列出来。 Threat Center 配置方法 在 Veeam ONE Dashboard 中，可以配置 Threat Center 所显示的内容和数据采集的范围。在上面提到的这四个部分，是仪表盘的 4 个小组件，在这 4 个小组件的右上角，都有一个配置的按钮，可以打开相关的配置向导。 Data Platform 打分表配置 Scorecard 得分有 4 部分组成，因此这里小组件的向导中，有对应 4 个不同的得分的相关配置，包括了采集数据的对象和类型等。管理员可以根据自己关心的内容调整 Scorecard 的计分范围。 恶意攻击检测侦测地图配置 这个小组件的配置包含两部分，一部分是侦测的时间范围和显示方式，另外一部分是关于地理位置的配置。在这里，地理位置是内置在 Veeam ONE 中的离线地名数据库，管理员可以使用已经内置的英文地名，也可以通过 Custom 按钮设置自定义的地名以及地理经纬度坐标。在为每一个 Repository 设定完位置之后，该小组件就能够在地图上醒目的显示受感染的数据中心了。 RPO 异常分析配置 这个设置支持基础架构对象的选择、RPO 的时间范围和前 N 工作负载的排序，管理员能够根据自己实际关心的数据进行内容展示。 SLA 合规性状态配置 这个设置支持集成架构对象的选择、作业类型的选择、统计时间范围和目标 SLA 值，管理员可以根据实际啥情况设定最关心的数据。 由于 Veeam ONE 是个多用户系统，以上这些配置仅对当前登录用户生效，因此，不同的用户需要根据实际情况做相应设置。 ","date":"2024-05-06","objectID":"/2024/05/vdp-v12-1-security-feature-deep-dive-03/:0:2","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（三）- 全面威胁监控","uri":"/2024/05/vdp-v12-1-security-feature-deep-dive-03/"},{"categories":[],"content":"接着昨天的，来说说第二大重磅更新功能，YARA Scan 和 Antivirus Scan。 VBR 除了能对备份数据流进行在线扫描之外，现在还支持对备份下来的备份数据进行二次扫描。v12.1 中具备两大扫描引擎，一个是使用 Mount Server 上的杀毒软件作为扫描引擎，另外一个是使用 YARA 作为扫描引擎。 ","date":"2024-04-29","objectID":"/2024/04/vdp-v12-1-security-feature-deep-dive-02/:0:0","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（二）- 恶意软件扫描","uri":"/2024/04/vdp-v12-1-security-feature-deep-dive-02/"},{"categories":[],"content":"YARA 工具 YARA(全称：Yet Another Recursive Acronym)。官网链接：https://yara.readthedocs.io/en/latest/，Github 仓库链接：https://github.com/virustotal/yara。 YARA 通常是用来帮助安全专家和研究人员识别和分类恶意软件，它主要用于恶意软件的研究和检测。它能够扫描文本或者二进制模式的代码。 YARA 工具一般包含两部分，其中一部分是 YARA 扫描引擎本身，它可以安装在各种平台上。另外一部分是 YARA 规则，这个是使用者根据实际需求进行编写的匹配规则。在 YARA 使用时，简单逻辑是，YARA 引擎调用 YARA 规则扫描对应的需要扫描的内容，输出扫描结果。 在 VDP v12.1 中，加入了 YARA 工具，备份和安全管理员，可以直接在 VBR 控制台调用编写好的 YARA 规则，对备份存档进行扫描。完全不需要自己去手工搭建 YARA 运行环境。 YARA 规则 关于 YARA 规则，其实语法非常简单，可以参考官网的说明 https://yara.readthedocs.io/en/stable/writingrules.html，在 Github 上能找到相关的规则模版 https://github.com/Yara-Rules/rules。 在 VBR 上，内置了 3 段经典的 YARA 规则模版，可以作为编写的参考。 当然现在也不用那么麻烦，各种 GPT 可以帮我们轻松写一段 YARA 规则，比如： YARA 扫描工作原理 将以上 Chat GPT 帮我生成的内容存入到一个.yar 或者.yara 结尾的文件中，然后放到C:\\Program Files\\Veeam\\Backup and Replication\\Backup\\YaraRules 目录下，VBR 就能自动识别到这些规则。 启动扫描后，VBR 会将备份存档挂载到 Mount Server 上，然后利用 Mount Server 上的 YARA 引擎加载选择的 YARA 规则进行扫描。 当然，这个扫描因为是文本和二进制扫描，它不仅局限于恶意代码的扫描，实际上它能够扫描任何我们想查找的关键信息。 ","date":"2024-04-29","objectID":"/2024/04/vdp-v12-1-security-feature-deep-dive-02/:0:1","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（二）- 恶意软件扫描","uri":"/2024/04/vdp-v12-1-security-feature-deep-dive-02/"},{"categories":[],"content":"杀毒软件扫描 在 VBR v10 开始就在 Secure Restore 功能中内置了杀毒软件的扫描，VBR 会调用在 Mount Server 上的杀毒软件对备份存档进行扫描。v12.1 中，这个功能被集成到了 Scan Backup 中，并且内置支持的杀毒软件也更加丰富了。 杀毒软件配置 在 v12.1 中内置了 Symantec Protection Engine、ESET、Windows Defender、Kaspersky Security、Bitdefender Endpoint Security Tools、Trellix (以前鼎鼎大名的 McAfee) 这 6 款杀毒引擎。 除了这 6 款软件之外，如果需要使用其他的杀毒软件，Veeam 也支持通过 AntivirusInfos.xml 配置其他的杀毒软件，只需要修改 Mount Server 上%ProgramFiles%\\Common Files\\Veeam\\Backup and Replication\\Mount Service这个目录下的 xml 文件，通过 CLI 命令行调用对应杀毒软件即可。更详细的 xml 配置方法，可以查看官网的详细 xml 语法属性说明 https://helpcenter.veeam.com/docs/backup/vsphere/av_scan_xml.html?ver=120。 ","date":"2024-04-29","objectID":"/2024/04/vdp-v12-1-security-feature-deep-dive-02/:0:2","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（二）- 恶意软件扫描","uri":"/2024/04/vdp-v12-1-security-feature-deep-dive-02/"},{"categories":[],"content":"配置方法 在 VBR 上，有多种方式启动扫描。 选中受支持的备份存档，右键点击或者选择工具栏上的Scan Backup按钮，激活杀毒引擎扫描或者 YARA 扫描对话框。 启动 Scan Backup 后，会打开扫描对话框，这时候，可以用这两个引擎按照 3 中不同的扫描方式对整条备份链进行安全扫描。 在各种整机或者磁盘恢复的 Secure Restore 步骤中，勾选杀毒引擎扫描或者 YARA 扫描选项。 在 Surebackup 作业中，勾选杀毒引擎扫描或者 YARA 扫描选项。 查看扫描结果 如果扫描结果匹配到了需要查找的内容，VBR 就会标记扫描到的备份存档为 Infected 状态，表示有恶意软件被发现。 完整的扫描存档会记录在 VBR 的这个目录下：C:\\ProgramData\\Veeam\\Backup\\FLRSessions\\Windows\\FLR__\u003cmachinename\u003e_\\Antivirus 和前面介绍的在线恶意攻击分析一样，在 VBR 的 History 中也会记录到详细的扫描状态，可以在 History 中查找扫描的结果。 以上这些就是 VDP v12.1 中新增的一些备份存档扫描检查方法，能够帮助管理员在发生问题后避免二次感染，确保恢复出来的数据是干净的系统存档。 ","date":"2024-04-29","objectID":"/2024/04/vdp-v12-1-security-feature-deep-dive-02/:0:3","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（二）- 恶意软件扫描","uri":"/2024/04/vdp-v12-1-security-feature-deep-dive-02/"},{"categories":[],"content":"去年年底，Veeam 发布了 v12.1 的重要更新，其中包含了大量安全方面的新功能，从今天开始，我将会深入每一个具体功能，来为大家介绍它们的原理和使用方法。 本次第一篇，先来说说勒索攻击侦测部分，在这个版本中，加入的这个功能模块叫 Malware Detection，从功能分类上来说，由两大类组成。其中一个叫 Inline Entropy Scan，另外一个叫 Index Scan。 ","date":"2024-04-28","objectID":"/2024/04/vdp-v12-1-security-feature-deep-dive-01/:0:0","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（一）- 勒索攻击侦测","uri":"/2024/04/vdp-v12-1-security-feature-deep-dive-01/"},{"categories":[],"content":"Inline Entropy Scan 首先来看下 Inline Entropy Scan。默认情况下，Inline Entropy Scan 是处于被禁用状态，管理员需要手工打开该选项进行激活。而激活后，它是一个全局选项，所有支持的备份源都会在备份时进行 Inline Entropy Scan。 Inline Scan 会根据 Veeam 多年的数据保护经验训练的数据分析大模型在备份过程中对备份数据进行实时扫描，当源数据中发现有以下几种状况时，系统就会发出警告，通知侦测到异常状况： 发现大量数据正在被加密，这个数据量有个 5 档敏感度设定，当灵敏度调高时，就算比较少的数据被加密，系统都会发出警告。 当勒索攻击创建了相关文本内容后，系统会发出警告，这主要包括类似于 V3 版本的洋葱地址，勒索通知等。 工作原理 这个扫描会在备份作业运行的时候进行，VBR 会对每一个备份过程中接收到的数据块进行分析，VBR Server 上会加入一个全新的服务 Veeam Data Analyzer Service 来管理这个分析。 这个数据分析会发生在 Backup Proxy 或者 Agent 端，在分析数据开始后，Proxy 上会存放一个临时的 RIDX 文件，这个文件会包含扫描到的磁盘源数据和勒索数据，比如加密的数据、文件类型、洋葱地址、勒索通知等。 备份完成后，这个数据会被发送到 VBR 上的 VBRCatalog 文件夹中。 VBR 将收到的 RIDX 文件和存放在 VBRCatalog 文件夹中的历史存档将进行比较，确定是否有恶意攻击发生，如果侦测到异常，就会发出事件通知，将备份存档标记为 Suspicious。 启用方法和排除方法 在 VBR 控制台的左上角，打开 VBR 的全局设置菜单，可以找到 v12.1 新增的 Malware Detection 选项，打开这个设置选项就可以看到如下图的配置复选框和滑块。默认情况下，复选框是没有被启用的，要打开扫描，可以勾上复选框。滑块是设置扫描灵敏度的，默认被置于 Normal 级别，可以根据实际情况调整灵敏度。 如果有些特殊机器，不希望进行扫描，可以通过全局排除选项进行排除。和上面的启用方法一样，在 VBR 控制台的左上角，打开 VBR 的 Global Exclusion，可以找到 v12.1 全新的 Malware Exclusion 选项。 在这里可以添加需要排除的虚拟机，也可以添加需要排除的 Veeam Agent。 ","date":"2024-04-28","objectID":"/2024/04/vdp-v12-1-security-feature-deep-dive-01/:0:1","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（一）- 勒索攻击侦测","uri":"/2024/04/vdp-v12-1-security-feature-deep-dive-01/"},{"categories":[],"content":"Index Scan 除了上面的 Inline 方式进行扫描之外，VBR 还能够利用文件系统的 Index 记录功能来进行恶意文件分析。这个分析借助了 VBR 的 Guest Processing 中 Index guest files 的功能，默认情况下全局选项是打开的，但是它需要配合每一个备份作业中 Guest Processing 选项来一起工作，如果备份作业的 Guest Processing 步骤中的 Index guest files 复选框没有启用，那么 Index Scan 对于该备份作业也不会生效。 Index Scan 的扫描会针对以下几种异常状况： Index Scan 在工作时，会调用 VBR 中 SuspiciousFiles.xml 文件中已知的可疑文件扩展名进行匹配，发现已知的可疑文件后，系统会发出警告。 如果有超过 200 个文件被重命名，并且重命名后都带有同样的扩展名，系统会发出警告。 如果有包含特殊扩展名的 25 个文件以上或者 50% 的文件被删除，系统会发出警告。 工作原理 这个扫描会在备份作业运行的时候进行，因为是 Guest Processing 服务，因此它会在每一台虚拟机或者物理机上抓取文件的索引信息，传输到 VBR 的 VBRCatalog 目录中，并由 VBR 的 Veeam Data Analyzer Service 来分析这个数据。 在工作时，SuspiciousFiles.xml 相当于是这个扫描的病毒库，VBR 在安装后，内置了出厂的库，备份管理员可以通过在线或者离线的方式来更新这个文件。 启用方法和排除方法 全局的启用选项和前面的 Inline Scan 一样，在 VBR 控制台的左上角，打开 VBR 的全局设置菜单，找到 Malware detection 选项，第二部分就是这个 Index Scan 的功能。默认情况下，这个复选框是选上的。在这个复选框下面，还有一个复选框是在线更新 SuspiciousFiles.xml 文件的，如果 VBR 能连接互联网，那么这个文件可以定期被自动更新。如果需要手工更新这个文件，可以参考 https://www.veeam.com/kb4514。 在全局启用后，每个备份任务中，需要额外启用 Index 功能，因此如果不想扫描，只需要在备份任务中不启用 Index 即可。 ","date":"2024-04-28","objectID":"/2024/04/vdp-v12-1-security-feature-deep-dive-01/:0:2","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（一）- 勒索攻击侦测","uri":"/2024/04/vdp-v12-1-security-feature-deep-dive-01/"},{"categories":[],"content":"恶意事件管理 以上两种扫描，如果触发了告警之后，在 Inventory 界面的 Malware Detection 中会出现黑体加粗的恶意攻击警告，对应的虚拟机或者物理机会在这里列出来。以上两种扫描的结果会被标记成 Suspicious 状态。 在 History 中，也会有一大类新的事件，会列出每次备份中各种事件扫描到的内容。每个事件选择后，上方的工具栏或者右键菜单，都有事件详情的选项，可以打开详情查看具体发生了什么恶意事件。 在详情中，会记录更加详细的事件记录的具体日志文件。 以上就是 VBR v12.1 中，在线勒索攻击的侦测方法，希望大家在启用功能后，永远别扫描到有数据被攻击。 ","date":"2024-04-28","objectID":"/2024/04/vdp-v12-1-security-feature-deep-dive-01/:0:3","tags":["Backup","Security"],"title":"VDP v12.1 安全功能深度分析系列（一）- 勒索攻击侦测","uri":"/2024/04/vdp-v12-1-security-feature-deep-dive-01/"},{"categories":[],"content":"之前分享过两篇关于使用K10即时恢复Kubernetes上应用的方法，这个功能对于Kubernetes环境还是有一些要求的。当时给大家详细分享了手工部署的过程，今天我为大家带来一个一键部署的脚本，只要有VMware基础环境，能够正常连接Github/k8s.io网络，那么这个脚本会非常方便，启动脚本后只需要等待10分钟左右，你就可以直接使用这个单节点的k3s环境了。 脚本仓库地址： https://github.com/Coku2015/k3s_vsphere ","date":"2024-02-21","objectID":"/2024/02/automate-deploy-k3s-with-vsphere-csi/:0:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"一键部署脚本：K3S+vSphere CSI","uri":"/2024/02/automate-deploy-k3s-with-vsphere-csi/"},{"categories":[],"content":"前提条件 在使用这个脚本之前，需要提前准备一下能够用于自动化部署的镜像和虚拟机自定义规范，脚本会自动调用这个镜像和规范来部署k3s环境。 ","date":"2024-02-21","objectID":"/2024/02/automate-deploy-k3s-with-vsphere-csi/:1:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"一键部署脚本：K3S+vSphere CSI","uri":"/2024/02/automate-deploy-k3s-with-vsphere-csi/"},{"categories":[],"content":"虚拟机镜像 我推荐使用Ubuntu 20.04LTS作为运行k3s的环境，虚拟机模版镜像的制作也推荐基于这个版本。 模版虚拟机，我一般硬件配置比较低1vCPU，2GB内存和50GB硬盘就足够了。 虚拟机模版的安装可以有多种方法，最简单直接的是用iso进行一个最小化的安装，在安装结束后，为了能够进行后续的全自动远程配置，需要在这个模版中做一些调整，首先是启用密钥对认证远程登录： # 在你的Linux机器上创建远程连接的密钥对 $ ssh-keygen # 创建完成后，你会得到id_rsa和id_rsa.pub两个文件，分别是私钥和公钥。 # 用下面这个命令远程复制到模版机器上，假设ubuntu的用户名为ubuntu $ ssh-copy-id ubuntu@ubuntu_template_vm # 试试拷贝完成后的效果, 正常还是会提示输入密码。 $ ssh ubuntu@ubuntu_template_vm 接下去，ssh远程进入这台Ubuntu后sudo -i到root直接运行以下命令，进行进一步调整： # 修改ssh密钥对登录免密码 $ sed -i 's/#\\?PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config # 重启ssh服务 $ systemctl restart sshd # 加入sudo免密码(如果username不是ubuntu，请修改下面的命令) $ echo 'ubuntu ALL=(ALL) NOPASSWD:ALL' \u003e\u003e /etc/sudoers # 修复 VMware 自定义配置问题，详情可以参考VMware KB56409 $ sed -i '/^\\[Unit\\]/a After=dbus.service' /lib/systemd/system/open-vm-tools.service $ awk 'NR==11 {$0=\"#D /tmp 1777 root root -\"} 1' /usr/lib/tmpfiles.d/tmp.conf | tee /usr/lib/tmpfiles.d/tmp.conf # 禁用 Cloud Init $ touch /etc/cloud/cloud-init.disabled # 更新系统 $ apt cleaan $ apt update -y $ apt upgrade -y # 删除machine-id，避免模版部署后同ID冲突 $ rm /etc/machine-id $ touch /etc/machine-id 好了，这样配置完成后，退出ssh，然后再试下ssh至这台模版机器，看看是否还需要密码验证，并且sudo -i试试提权是否需要密码，如果都不要，那么恭喜你，模版制作完成了。接下去只需要将这台虚拟机关机，转换成模版即可。 ","date":"2024-02-21","objectID":"/2024/02/automate-deploy-k3s-with-vsphere-csi/:1:1","tags":["VMware","Kubernetes","Instant Recovery"],"title":"一键部署脚本：K3S+vSphere CSI","uri":"/2024/02/automate-deploy-k3s-with-vsphere-csi/"},{"categories":[],"content":"虚拟机自定义规范 除了制作模版之外，我们还需要配置一个虚拟机自定义规范。 在vSphere Client的快捷方式中，找到虚拟机自定义规范按钮，点击进入。 点击新建按钮后，弹出一个新建向导。 设置一个名称，选择Linux操作系统。这个名称会在后续的脚本中使用到 设置计算机名称，我们选择使用虚拟机名称，表示和虚拟机同名，然后在下方域名中随便填入个合适的域名，这步不能省略，必须填上任意文字。 选择时区，我选择我所在的亚洲 - 上海。 自定义脚本这里不用配置，直接点下一步。 设置网络，需要选择手动选择自定义设置，然后选择下方的网卡1，再点击编辑，进行下一步调整。 打开网络设置界面，在IPV4里，左边选择当使用规范时，提示用户输入IPv4地址，右边填入你环境中的子网掩码和网关。IPv6默认不做配置，点击确定保存配置。 设置DNS，配上环境中的能上互联网的默认DNS服务器地址。 点击完成保存设置。 这样自定义规范机配置好了，可以在后续的脚本中直接调用第一步设置的名称使用了。 ","date":"2024-02-21","objectID":"/2024/02/automate-deploy-k3s-with-vsphere-csi/:1:2","tags":["VMware","Kubernetes","Instant Recovery"],"title":"一键部署脚本：K3S+vSphere CSI","uri":"/2024/02/automate-deploy-k3s-with-vsphere-csi/"},{"categories":[],"content":"脚本使用说明 ","date":"2024-02-21","objectID":"/2024/02/automate-deploy-k3s-with-vsphere-csi/:2:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"一键部署脚本：K3S+vSphere CSI","uri":"/2024/02/automate-deploy-k3s-with-vsphere-csi/"},{"categories":[],"content":"脚本使用环境拓扑介绍： 在Linux控制机上，使用git clone下载脚本仓库。 $ git clone https://github.com/Coku2015/k3s_vsphere.git 下载后进入脚本目录： $ cd k3s_vsphere 用vi编辑器打开脚本，找到脚本开头部分，修改其中的环境变量参数。 ####################### Environment Variables Section ###################### ### Modify the following environment variables to match your environment ### MY_SSH_USER=\"ubuntu\" MY_VSPHERE_SERVER=\"172.16.0.100\" MY_VSPHERE_USERNAME=\"administrator@vsphere.local\" MY_VSPHERE_PASSWORD=\"VMware123!\" MY_DATACENTER=\"MyDatacenter\" MY_VM_TEMPLATE=\"Ubuntu20.04LTS\" MY_DATASTORE=\"localdatastore\" ####################### Environment Section End ########################### 其中第一个MY_SSH_USER是Ubuntu模版的用户名，其他信息都是比较常规的vSphere访问信息，根据实际情况填写即可。 填写完成后，保存退出，然后就能执行脚本啦，对了，还需要注意，脚本运行需要root权限安装相关软件。 执行命令运行脚本： $ bash deploy_k3s_with_vspherecsi.sh 这时候会提示输入一些本次自动部署的配置，一共三个，第一个为部署的虚拟机名称，只需要输入一个前缀，脚本会自动为虚拟机名称加上4个随机数字作为唯一标识；第二个为虚拟机的IP地址，根据自己环境的空闲IP地址情况按实际情况输入即可；第三个为k3s的版本，可以到k3s官网查询相关需要的版本，理论上任何stable版本都能支持: +----------------------------------------------------------------------+ | K3S with vSphere CSI automation script | +----------------------------------------------------------------------+ | This script is used to create a single node k3s cluster on vSphere. | +----------------------------------------------------------------------+ | Intro: https://blog.backupnext.cloud | | Bug Report: Lei.wei@veeam.com | +----------------------------------------------------------------------+ Please enter the VM name: (Default VM name will be ‘k3s-cluster-\u003c4 random number\u003e’): Please enter the IP address for the VM: (Default IP address will be ‘192.168.1.\u003crandom number\u003e’):10.10.1.103 Please enter the k3s version: (Default version will be ‘v1.28.6+k3s2’):v1.27.10+k3s2 输入完成后，脚本就开始自动部署了，大约10分钟左右，你就能像我一样获得一个直接可以使用的k3s测试环境了。 ","date":"2024-02-21","objectID":"/2024/02/automate-deploy-k3s-with-vsphere-csi/:2:1","tags":["VMware","Kubernetes","Instant Recovery"],"title":"一键部署脚本：K3S+vSphere CSI","uri":"/2024/02/automate-deploy-k3s-with-vsphere-csi/"},{"categories":["Repository"],"content":"Veeam v12版本发布后，官方手册给出了基于Ubuntu20.04系统构建Veeam加固存储库后进一步系统安全加固的方法，并且提供了全自动配置的脚本，因此在使用我的Configurator构建完Ubuntu存储库后，可以用这个自动化配置脚本进行更安全的加固。 由于官方脚本包含了一些美国军方的合规配置，并不适合中国用户使用，我将Veeam官方的脚本进行了一些修改，并进行了重新发布，以适合中国用户使用。 脚本下载地址： https://github.com/Coku2015/veeam-hardened-repository 系统要求: 必须以root用户身份运行 必须在一台干净安装的Ubuntu 20.04系统上运行 仅支持 Veeam Backup \u0026 Replication v12 以上版本 使用说明: 通过 SSH 连接到 Ubuntu 20.04 服务器上 复制脚本内容到该服务器上 使用以下命令运行脚本: sudo bash veeam.harden.sh \u003e output.txt 2\u003e\u00261 注意: 如果你需要更详细的输出，只需运行以下的命令: sudo bash veeam.harden.sh ","date":"2024-02-02","objectID":"/2024/02/veeam-hardened-ubuntu/:0:0","tags":["备份"],"title":"Ubuntu系统用于Veeam加固存储库的进一步安全加固","uri":"/2024/02/veeam-hardened-ubuntu/"},{"categories":["Repository"],"content":"脚本加固内容说明 UBTU-20-010005 - Ubuntu 操作系统必须允许用户直接对所有连接类型发起会话锁定。 UBTU-20-010007 - Ubuntu 操作系统必须强制执行 24 小时/1 天作为最短密码生命周期。新用户的密码必须有 24 小时/1 天的最短密码有效期限制。 UBTU-20-010008 - Ubuntu 操作系统必须强制执行 60 天最长密码生存期限制。新用户的密码必须有 60 天的最长密码有效期限制。 UBTU-20-010013 - 在不活动超时后，Ubuntu 操作系统必须自动终止用户会话。 UBTU-20-010014 - Ubuntu 操作系统必须要求用户在权限升级或更改角色时重新进行身份验证。 UBTU-20-010016 - Ubuntu 操作系统默认文件系统权限必须定义为所有经过身份验证的用户只能读取和修改自己的文件。 UBTU-20-010035 - Ubuntu 操作系统必须使用强身份验证器来建立非本地维护和诊断会话。 UBTU-20-010036 - Ubuntu 操作系统在一段时间不活动后必须立即终止与 SSH 流量关联的所有网络连接。 UBTU-20-010037 - Ubuntu 操作系统必须在会话结束时或 10 分钟不活动后立即终止与 SSH 流量关联的所有网络连接。 UBTU-20-010038 - 在授予任何本地或远程系统连接之前，Ubuntu 操作系统必须显示标准强制性 DoD 通知和同意横幅。 UBTU-20-010043 - Ubuntu 操作系统必须将 SSH 守护程序配置为使用采用 FIPS 140-2 批准的加密哈希的消息身份验证代码 (MAC)，以防止未经授权的信息泄露和/或检测传输过程中信息的更改。 UBTU-20-010047 - Ubuntu 操作系统不得允许通过 SSH 进行无人值守或自动登录。 UBTU-20-010048 - 必须配置 Ubuntu 操作系统以禁用远程 X 连接，除非是为了满足记录和验证的任务要求。 UBTU-20-010049 - Ubuntu 操作系统 SSH 守护程序必须阻止远程主机连接到代理显示。 UBTU-20-010050 - Ubuntu 操作系统必须通过要求至少使用一个大写字符来强制密码复杂性。 UBTU-20-010051 - Ubuntu 操作系统必须通过要求至少使用一个小写字符来强制密码复杂性。 UBTU-20-010052 - Ubuntu 操作系统必须通过要求至少使用一个数字字符来强制密码复杂性。 UBTU-20-010053 - Ubuntu 操作系统在更改密码时必须要求更改至少 8 个字符。 UBTU-20-010054 - Ubuntu 操作系统必须强制要求密码长度至少为 15 个字符。 UBTU-20-010055 - Ubuntu 操作系统必须通过要求至少使用一个特殊字符来强制密码复杂性。 UBTU-20-010056 - Ubuntu 操作系统必须禁止使用字典单词作为密码。 UBTU-20-010057 - 必须配置 Ubuntu 操作系统，以便在更改密码或建立新密码时必须使用 pwquality。 UBTU-20-010070 - Ubuntu 操作系统必须禁止密码重复使用至少五代。 UBTU-20-010072 - Ubuntu 操作系统必须自动锁定帐户，直到管理员在尝试登录 3 次失败后释放锁定的帐户。 UBTU-20-010074 - 必须配置 Ubuntu 操作系统，以便每 30 天或更短时间运行一次以检查文件完整性的脚本是默认脚本。 UBTU-20-010075 - Ubuntu 操作系统必须在登录尝试失败后的登录提示之间强制执行至少 4 秒的延迟。 UBTU-20-010100 - Ubuntu 操作系统必须为影响 /etc/passwd 的所有帐户创建、修改、禁用和终止事件生成审核记录。 UBTU-20-010101 - Ubuntu 操作系统必须为影响 /etc/group 的所有帐户创建、修改、禁用和终止事件生成审核记录。 UBTU-20-010102 - Ubuntu 操作系统必须为影响 /etc/shadow 的所有帐户创建、修改、禁用和终止事件生成审核记录。 UBTU-20-010103 - Ubuntu 操作系统必须为影响 /etc/gshadow 的所有帐户创建、修改、禁用和终止事件生成审核记录。 UBTU-20-010104 - Ubuntu 操作系统必须为影响 /etc/opasswd 的所有帐户创建、修改、禁用和终止事件生成审核记录。 UBTU-20-010118 - Ubuntu 操作系统必须在审核失败时默认关闭（除非可用性是首要问题）。 UBTU-20-010122 - 必须配置 Ubuntu 操作系统，以便未经授权的用户无法读取或写入审核日志文件。 UBTU-20-010123 - Ubuntu 操作系统必须配置为仅允许授权用户拥有审核日志文件。 UBTU-20-010124 - Ubuntu 操作系统必须仅允许授权组拥有审核日志文件。 UBTU-20-010128 - 必须配置 Ubuntu 操作系统，以便未经授权的用户无法对审核日志目录进行写访问。 UBTU-20-010133 - 必须配置 Ubuntu 操作系统，以便未经授权的用户无法写入审计配置文件。 UBTU-20-010134 - Ubuntu 操作系统必须仅允许授权帐户拥有审核配置文件。 UBTU-20-010135 - Ubuntu 操作系统必须仅允许授权组拥有审核配置文件。 UBTU-20-010136 - Ubuntu 操作系统必须为成功/不成功使用 su 命令生成审核记录。 UBTU-20-010137 - Ubuntu 操作系统必须为成功/不成功使用 chfn 命令生成审核记录。 UBTU-20-010138 - Ubuntu 操作系统必须为成功/不成功使用 mount 命令生成审核记录。 UBTU-20-010139 - Ubuntu 操作系统必须为成功/不成功使用 umount 命令生成审核记录。 UBTU-20-010140 - Ubuntu 操作系统必须为 ssh-agent 命令的成功/不成功使用生成审核记录。 UBTU-20-010141 - Ubuntu 操作系统必须为成功/不成功使用 ssh-keysign 命令生成审核记录。 UBTU-20-010142 - Ubuntu 操作系统必须为 setxattr、fsetxattr、lsetxattr、removexattr、fremovexattr 和 lremovexattr 系统调用的任何使用生成审核记录。 UBTU-20-010148 - Ubuntu 操作系统必须为 chown、fchown、fchownat 和 lchown 系统调用的成功/不成功使用生成审核记录。 UBTU-20-010152 - Ubuntu 操作系统必须为 chmod、fchmod 和 fchmodat 系统调用的成功/不成功使用生成审核记录。 UBTU-20-010155 - Ubuntu 操作系统必须为 creat、open、openat、open_by_handle_at、truncate 和 ftruncate 系统调用的成功/不成功使用生成审核记录。 UBTU-20-010161 - Ubuntu 操作系统必须为 sudo 命令的成功/不成功使用生成审核记录。 UBTU-20-010162 - Ubuntu 操作系统必须为成功/不成功使用 sudoedit 命令生成审核记录。 UBTU-20-010163 - Ubuntu 操作系统必须为成功/不成功使用 chsh 命令生成审核记录。 UBTU-20-010164 - Ubuntu 操作系统必须为成功/不成功使用 newgrp 命令生成审核记录。 UBTU-20-010165 - Ubuntu 操作系统必须为 chcon 命令的成功/不成功使用生成审核记录。 UBTU-20-010166 - Ubuntu 操作系统必须为成功/不成功使用 apparmor_parser 命令生成审核记录。 UBTU-20-010167 - Ubuntu 操作系统必须为成功/不成功使用 setfacl 命令生成审核记录。 UBTU-20-010168 - Ubuntu 操作系统必须为 chacl 命令的成功/不成功使用生成审核记录。 UBTU-20-010169 - Ubuntu操作系统必须为tallylog文件的使用和修改生成审核记录。 UBTU-20-010170 - Ubuntu操作系统必须为faillog文件的使用和修改生成审核记录。 UBTU-20-010171 - Ubuntu操作系统必须生成lastlog文件的使用和修改的审计记录。 UBTU-20-010172 - Ubuntu 操作系统必须为成功/不成功使用 passwd 命令生成审核记录。 UBTU-20-010173 - Ubuntu 操作系统必须为成功/不成功使用 unix_update 命令生成审核记录。 UBTU-20-010174 - Ubuntu 操作系统必须为成功/不成功使用 gpasswd 命令生成审核记录。 UBTU-20-010175 - Ubuntu 操作系统必须为成功/不成功使用 chage 命令生成审核记录。 UBTU-20-010176 - Ubuntu 操作系统必须为成功/不成功使用 usermod 命令","date":"2024-02-02","objectID":"/2024/02/veeam-hardened-ubuntu/:1:0","tags":["备份"],"title":"Ubuntu系统用于Veeam加固存储库的进一步安全加固","uri":"/2024/02/veeam-hardened-ubuntu/"},{"categories":[],"content":"在Veeam数据保护平台中，对各种应用程序支持非常完善，从镜像级备份的自动应用感知到特殊的应用Plugins备份，Veeam几乎覆盖了市场上所有的主流数据的支持。然而大家经常有疑问，MySQL的备份为什么在Veeam数据保护平台中找不到身影？今天我就来说说这是怎么一回事，对于MySQL，使用Veeam应该如何做备份和恢复。 ","date":"2023-12-11","objectID":"/2023/12/mysql-backup-and-restore/:0:0","tags":["MySQL","VBR","Backup"],"title":"VBR备份和恢复MySQL最佳实践","uri":"/2023/12/mysql-backup-and-restore/"},{"categories":[],"content":"MySQL数据存储引擎 说MySQL备份之前，得先来讲一下MySQL的数据存储引擎，因为不同的引擎直接决定了MySQL数据备份和恢复的能力。在MySQL中，默认情况下InnoDB是最常用的存储引擎，Create Table命令如果不接Engine参数情况下创建的表默认都会使用InnoDB引擎，并且Oracle官方也推荐除非有特殊需求，在通常使用MySQL时都使用InnoDB这个引擎。当然除了这个引擎之外，特殊情况下，MySQL也支持其他引擎，比如MyISAM、MEMORY、CSV、BLACKHOLE等引擎，关于更多的存储引擎信息，可以查看官方文档。 InnoDB引擎的自我恢复能力非常强，目前市面上针对MySQL在线物理热备份的解决方案都是针对InnoDB引擎的恢复特性来设计的，Veeam也同样利用了这个特点来实现MySQL的数据备份。 使用InnoDB引擎的数据库在出现服务器非正常关机后，恢复数据库只需要简单的启动MySQL服务，这时候InnoDB会自动检查数据库的Redo log和undo log，进入crash recovery流程，关于这个流程的详情可以参考官网InnoDB Recovery说明。这个特性对于Veeam的快照备份，无论是无代理的虚拟机快照还是Linux Agent的Veeamsnap快照来说，都非常适用，我们知道快照状态属于crash consisitent状态，这时候从这个状态启动的MySQL Server自然能非常顺利的进入自我crash recovery流程，然后完成服务启动，无需任何人工干预。 这个过程在系统恢复后，可以通过/var/log/mysql/error.log文件查询到以下信息： [System] [MY-013576] [InnoDB] InnoDB initialization has started. [System] [MY-013577] [InnoDB] InnoDB initialization has ended. [System] [MY-010229] [Server] Starting XA crash recovery... [System] [MY-010232] [Server] XA crash recovery finished. [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.0.35-0ubuntu0.20.04.1' socket: '/var/run/mysqld/mysqld.sock' port: 3306 (Ubuntu). 对于MyISAM引擎来说，因为其存储格式，也能够支持到通过物理备份的方式进行备份。唯一一点差异是，MyISAM引擎的一致性处理并不像InnoDB那么宽松，因此在物理备份复制文件之前，需要进行一个锁表的操作，来确保数据库的一致性。 ","date":"2023-12-11","objectID":"/2023/12/mysql-backup-and-restore/:1:0","tags":["MySQL","VBR","Backup"],"title":"VBR备份和恢复MySQL最佳实践","uri":"/2023/12/mysql-backup-and-restore/"},{"categories":[],"content":"Veeam数据保护平台 MySQL的备份 因此，在Veeam软件中，备份MySQL数据库也需要进行分开讨论： InnoDB引擎 - 整个备份过程可以直接以整机的方式进行，正常执行磁盘或者文件系统的快照，在快照后将快照点的所有文件备份出来后，数据库就同时完成了备份，不需要任何额外的设置和步骤。 MyISAM引擎 - 通常会建议加入FLUSH TABLES tbl_list WITH READ LOCK;命令来执行锁表操作，在锁表后MyISAM的表文件*.MYD, *.MYI, *.SDI只需要被按照文件方式备份即可。在使用无代理虚拟机快照的时候，通常会加入pre-freeze和post-unfreeze 脚本来处理锁表和解锁操作，而在使用Veeam Agent备份时，则只需要开启应用感知，那么Veeam Agent就能自动判断当前MySQL的存储引擎，自动为MyISAM引擎的表执行以上锁表和解锁操作。 数据库管理员可能这时候会疑惑，那么增量备份怎么办？备份数据有压缩吗？其实这些完全不用担心，Veeam的Change Block Tracking技术和重删压缩技术在整机镜像备份中应用的非常好，备份管理员能够轻松完成数据的重删压缩处理。 Veeam CDP技术在MySQL实时同步中的应用 如果您的MySQL运行在VMware vSphere中，那么恭喜您，VeeamCDP技术可以无缝应用到MySQL的实时同步复制的容灾场景中了，这时候完全不需要担心使用InnoDB引擎的MySQL的一致性，所有操作全部交给基础架构管理员托管给Veeam和VMware来完成。而在使用了Veeam B\u0026R 12.1后，甚至还能通过文件级恢复回滚到MySQL每2秒的任意一个状态，并且对于MySQL的容灾演练来说，SureReplica技术也能在CDP副本上发挥全自动演练的作用，确保数据的可恢复性。 MySQL的数据恢复 通过Veeam进行备份后，MySQL的数据恢复也非常方便，可以使用的手段会非常的多。 整机故障 - 即时虚拟机恢复 数据盘故障 - 即时磁盘恢复 DB故障 - 即时磁盘恢复、磁盘发布、文件级恢复 数据逻辑错误 - 结合数据实验室和文件级恢复等多种手段 ","date":"2023-12-11","objectID":"/2023/12/mysql-backup-and-restore/:2:0","tags":["MySQL","VBR","Backup"],"title":"VBR备份和恢复MySQL最佳实践","uri":"/2023/12/mysql-backup-and-restore/"},{"categories":[],"content":"VBR中MySQL备份恢复实战 接下来我通过一个实际的例子来具体看看MySQL数据库是怎么备份和恢复的。 环境说明 虚拟化平台: VMware vSphere 7.0 OS: Ubuntu 20.04 MySQL: 8.0.35 VBR: v12.1 数据备份 - InnoDB 为了模拟在数据不断写入过程中的数据库热备份，我准备了一个Python脚本来每一秒插入一行时间数据。这个table非常简单，如下： mysql\u003e SELECT * from time LIMIT 5; +----+------------+----------+ | id | date | time | +----+------------+----------+ | 5 | 2023-12-13 | 14:06:26 | | 6 | 2023-12-13 | 14:07:04 | | 7 | 2023-12-13 | 14:17:14 | | 8 | 2023-12-13 | 14:17:15 | | 9 | 2023-12-13 | 14:17:16 | +----+------------+----------+ 5 rows in set (0.00 sec) Python脚本如下： #!/usr/bin/python3 import MySQLdb import time while True: db = MySQLdb.connect(\"localhost\", \"lei\", \"P@ssw0rd\", \"leitestdb\") curs=db.cursor() try: curs.execute (\"\"\"INSERT INTO time values(0, CURRENT_DATE(), NOW())\"\"\") db.commit() except: db.rollback() db.close() time.sleep(1) VBR中的备份任务没什么特别的，一个普通的VMware虚拟机备份作业，不需要开启应用感知，直接进行备份。 数据恢复一 ：整机故障 出现了系统级的故障后，通过VBR可以执行整机的即时恢复，不仅服务器能够恢复，数据库也能完美恢复。在VBR控制台中启动即时虚拟机恢复后，MySQL能在2分钟内恢复上线。 我们来看看恢复后的数据库，数据库成功通过InnoDB的自我恢复模式使用crash recovery恢复。 lei@MySQL-01:~$ sudo cat /var/log/mysql/error.log [sudo] password for lei: 2023-12-15T03:35:54.523723Z 0 [System] [MY-010116] [Server] /usr/sbin/mysqld (mysqld 8.0.35-0ubuntu0.20.04.1) starting as process 936 2023-12-15T03:35:54.603505Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started. 2023-12-15T03:35:55.634428Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended. 2023-12-15T03:35:55.892988Z 0 [System] [MY-010229] [Server] Starting XA crash recovery... 2023-12-15T03:35:55.901965Z 0 [System] [MY-010232] [Server] XA crash recovery finished. 2023-12-15T03:35:55.971499Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed. 2023-12-15T03:35:55.971547Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel. 2023-12-15T03:35:56.039984Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Bind-address: '127.0.0.1' port: 33060, socket: /var/run/mysqld/mysqlx.sock 2023-12-15T03:35:56.040153Z 0 [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.0.35-0ubuntu0.20.04.1' socket: '/var/run/mysqld/mysqld.sock' port: 3306 (Ubuntu). 我们再来看看备份的数据点位于哪个时间点： mysql\u003e select * from time order by id desc LIMIT 10; +-----+------------+----------+ | id | date | time | +-----+------------+----------+ | 361 | 2023-12-14 | 10:20:00 | | 360 | 2023-12-14 | 10:19:59 | | 359 | 2023-12-14 | 10:19:58 | | 358 | 2023-12-14 | 10:19:57 | | 357 | 2023-12-14 | 10:19:56 | | 356 | 2023-12-14 | 10:19:55 | | 355 | 2023-12-14 | 10:19:54 | | 354 | 2023-12-14 | 10:19:53 | | 353 | 2023-12-14 | 10:19:52 | | 352 | 2023-12-14 | 10:19:51 | +-----+------------+----------+ 10 rows in set (0.00 sec) 可以看到，备份数据的最后一条记录在2023-12-14的10:20:00写入，而前面备份时的虚拟机快照完成时间正好是10:20:21。 数据恢复二：MySQL数据整库恢复 这个场景多数出现于主机环境正常，而数据库出现了问题，这时候在Veeam中恢复的操作方法选择也非常多样。我们先来看看从备份管理员角度最舒服的操作方式：Veeam文件级恢复。 找到VBR控制台的MySQL存档，在右键菜单中，选择Restore guest files-\u003e Linux and other...，就能打开MySQL的文件级还原向导。 打开后，在图形化恢复界面中，可以快速找到/var/lib/mysql的数据目录，看到其中的详细每一个文件。 选择文件或者目录后，把/var/lib/mysql整个目录还原回源机或者新服务器，即可完成数据还原。完成数据还原后，在MySQL服务器上，检查下目录的权限，如果owner和group不正确，就通过以下命令调整一下权限，然后启动mysql即可。 $ chown -R mysql:mysql /var/lib/mysql 数据恢复三：单表恢复 单表恢复在MySQL中会比较复杂一点，但是利用Veeam的强大功能，我们可以轻松实现。具体原理，还是基于MySQL 官网的InnoDB引擎的恢复说明 首先，我们需要用数据实验室生成一份要恢复表的metadata，关于数据实验室的配置，可以参考我之前的帖子。 在数据实验室中，MySQL机器能够正常被启动，我们通过ssh连接进入机器，然后执行mysql命令来生成metadata： mysql\u003e use leitestdb; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql\u003e FLUSH TABLES time FOR EXPORT; Query OK, 0 rows affected (0.00 sec) 这时候，需要注意的是，暂时还不能退出mysql控制台，我们需要先将生成的time.cfg文件拷贝出来，存放备用。因为退出mysql控制台后，这个文件就被自动删除了。 接着，我们开始正式恢复单表数据。 要恢复MySQL的单个表，首先我们需要在数据库里把表结构创建一下，比如我的这张表如下： mysql\u003e CREATE TABLE `time` ( `id` int(11) NOT NULL AUTO_INCREMENT, `date` date DEFAULT NULL, `time` time DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARS","date":"2023-12-11","objectID":"/2023/12/mysql-backup-and-restore/:3:0","tags":["MySQL","VBR","Backup"],"title":"VBR备份和恢复MySQL最佳实践","uri":"/2023/12/mysql-backup-and-restore/"},{"categories":[],"content":"总结 使用Veeam进行MySQL备份时，如果您的环境只有InnoDB引擎，那么这时候您完全不需要考虑任何备份过程的特殊处理操作，直接用镜像级的快照备份就能完美处理各种MySQL的备份和恢复场景；而当您的环境中有MyISAM引擎时，可以有两种选择，一种是使用Veeam Agent的方式由Veeam Agent来做锁表和解锁操作，另外一种您可以通过虚拟机备份应用感知中的脚本功能，在快照前后来手工加入锁表和解锁操作；而当您的环境中有其他类型的存储引擎时，我建议您最好通过暂停数据库的脚本通过冷备份的方式来进行，这样虽然会带来分钟级的短暂停机但是能确保数据的一致性。 以上就是Veeam备份恢复MySQL的最佳实践，欢迎关注我的博客，了解更多Veeam的备份技术。 ","date":"2023-12-11","objectID":"/2023/12/mysql-backup-and-restore/:4:0","tags":["MySQL","VBR","Backup"],"title":"VBR备份和恢复MySQL最佳实践","uri":"/2023/12/mysql-backup-and-restore/"},{"categories":[],"content":"就在昨天，Veeam正式GA了今年下半年度的数据保护平台全线产品的重要更新。几乎所有的产品都更新了一个版本，如果是Veeam深度用户，进入我的Veeam主页https://my.veeam.com，会看到满满的一屏所有产品全是New的状态，这些都是在本周全新上架可供下载的新版本。 本次产品更新最重要的部分当然是VDP旗舰平台的v12.1更新了，距离上次大版本v12更新一年不到的时间，Veeam研发团队为我们送上了新增功能仅次于大版本更新的v12.1，其中最耀眼的是今年超级火热的AI大模型技术，在备份、恢复、容灾甚至是日常操作中都集成了AI/ML技术，来提升备份系统的能力，可以说这个更新让您的数据保护平台更聪明了。 ","date":"2023-12-07","objectID":"/2023/12/vdp23h2-update/:0:0","tags":["VDP","VBR","Backup"],"title":"Veeam全线产品2023年下半年度重磅更新","uri":"/2023/12/vdp23h2-update/"},{"categories":[],"content":"主要功能更新 ","date":"2023-12-07","objectID":"/2023/12/vdp23h2-update/:1:0","tags":["VDP","VBR","Backup"],"title":"Veeam全线产品2023年下半年度重磅更新","uri":"/2023/12/vdp23h2-update/"},{"categories":[],"content":"网络安全的探测和发现 在线流式恶意软件探测 - 在备份数据传输过程中，对数据流进行内容分析，并且可以和已知的历史数据流状态进行对比分析，判断出数据块从未加密到被加密的状态变化，利用内置在产品中的Veeam训练的AI模型，来区分恶意加密行为，探测恶意攻击信号。 可疑文件系统行为探测 - 和流式分析不同，在数据备份完成后，对于备份下来的文件系统，通过Index的索引技术，快速扫描分析已知恶意软件的扩展名、勒索通告单，以及恶意软件标志物。这个分析技术一样可以进行历史备份数据的比较，通过不同时间的数据活动进行进一步分析，实现可疑行为的判断。这个技术Veeam内置了类似杀毒软件厂商的病毒库定义，并且支持在线和离线更新病毒库。 早期威胁探测 - 开放了一个全新的Incident API，和第三方的EDR工具集成，这个包括现在主流的NDR、MDR、XDR等等，一旦在其他系统上发现攻击信号，这些第三方系统就能拉响警报，通知备份系统进行“关门打狗”。 ","date":"2023-12-07","objectID":"/2023/12/vdp23h2-update/:1:1","tags":["VDP","VBR","Backup"],"title":"Veeam全线产品2023年下半年度重磅更新","uri":"/2023/12/vdp23h2-update/"},{"categories":[],"content":"加强从勒索事件恢复响应能力 YARA引擎扫描 - 除了可以用杀毒软件扫描备份存档外，这次更新还加入了业界流行的YARA引擎，这个能让扫描恶意软件变的更加的方便和有效率。同时这个引擎的扫描也更智能了，提供了3种不同的扫描模式。 避免二次感染 - 根据不同事件的勒索行为追踪，Veeam内置了恶意感染的重要爬虫标记，在图形化界面中能够清晰的看到哪些存档是有感染风险的，哪些是安全的。在恢复时，可以快速选中干净的还原点，避免二次感染。 事件转发能力 - 集成了Syslog标准服务能力，可以将大多数的事件全部转发给Syslog系统，进行进一步响应和分析。 ","date":"2023-12-07","objectID":"/2023/12/vdp23h2-update/:1:2","tags":["VDP","VBR","Backup"],"title":"Veeam全线产品2023年下半年度重磅更新","uri":"/2023/12/vdp23h2-update/"},{"categories":[],"content":"确保安全和合规性 四眼授权 - 两人四眼，也叫A-B角双人授权，这是IT中的传统安全流程，在备份系统中，Veeam也引入了这样的安全管理方式，对于重要的操作，需要A-B角色共同授权才能完成。 KMS密钥管理系统集成 - 消除人工密码管理的不安全性，通过密钥管理系统来进行数据的加密解密，Veeam通过标准的KMIP 1.4协议支持业界主流的KMS密钥管理系统对备份数据进行加密，避免备份数据泄露风险。 备份系统安全合规监控 - 加入了超过20项的安全自查，这部分是v12的能力增强，备份系统会自查安全性，并且将安全报告定期发送给客户，确保整个安全架构符合要求，没有被破坏。 Veeam威胁中台 - 全新的中台面板展示，将3-2-1-1-0的最佳实践直接直观的展示在控制台上，每天上班看一眼，就能知道现在数据安不安全。 ","date":"2023-12-07","objectID":"/2023/12/vdp23h2-update/:1:3","tags":["VDP","VBR","Backup"],"title":"Veeam全线产品2023年下半年度重磅更新","uri":"/2023/12/vdp23h2-update/"},{"categories":[],"content":"其他主要更新 对象存储备份 - 非结构化数据备份新成员，特别是云原生应用、图床、智能视频监控系统、静态网站托管等等各种对象存储使用的场景，现在Veeam平台能够将这些数据都实现备份和恢复了。 CDP能力增强 - 性能和功能都大大提升了，实验室数据显示，单个VBR支持7000台左右的VM秒级实时复制，实现连续数据保护毫无压力。并且v12.1的CDP还支持文件级恢复、应用对象恢复、全自动数据实验室恢复验证等Veeam广受好评的常规功能，更重要的是v12.1中加入的流式恶意软件探测系统在这里也能工作，发现IO异常后能以秒级的精度还原到历史时间点，大大减少数据丢失。 Veeam AI助手 - 内置大模型GPT，这个大模型是基于Veeam的官网操作手册训练的，专治各种不明白，拿到软件不会用，第一件事情就是打开助手问问题。 ","date":"2023-12-07","objectID":"/2023/12/vdp23h2-update/:1:4","tags":["VDP","VBR","Backup"],"title":"Veeam全线产品2023年下半年度重磅更新","uri":"/2023/12/vdp23h2-update/"},{"categories":[],"content":"其他更新 说说我最喜欢的几个小更新吧。 即时磁盘发布 - 其实这个是之前的数据集成API，目前已经变成图形化界面中可以直接操作的即时磁盘恢复了，这样任何Veeam的磁盘镜像存档都可以直接挂载给任何的Windows和Linux机器了，挂载完成后，可以进行数据恢复、数据挖掘、数据分析等等操作。 数据实验室Lite版 - 专为安全扫描和YARA扫描提供的轻量级数据实验室，没有虚拟化环境都能用。 即时PostgreSQL数据库恢复 - Veeam Explorer for PostgreSQL 的第二个版本，把这个Veeam的看家本领给补上。 Linux Agent 部署器 - 部署小工具，可以不需要在VBR上输入密码就集中管理Linux Agent。 Veeam Plugin 新增DB2支持 - 同时支持Linux和AIX的DB2，对单节点、HADR架构、IBM PowerHA、TSA和Pacemaker等复杂架构都能支持。 Veeam Explorer 新增SAP HANA支持 - SAP HANA全图形化操作来了，备份和恢复都可以在VBR控制台轻松进行了。 Enterprise Manager 中文版支持 - 日常使用的控制台，Enterprise Manager，完全中文版本，可管理、可备份、可恢复，甚至可以做自助服务，能做的不能做的在这里都有。 ","date":"2023-12-07","objectID":"/2023/12/vdp23h2-update/:2:0","tags":["VDP","VBR","Backup"],"title":"Veeam全线产品2023年下半年度重磅更新","uri":"/2023/12/vdp23h2-update/"},{"categories":[],"content":"支持平台更新 完整全功能支持VMware vSphere 8.0 U2 完整全功能支持VMware Cloud Director 10.5 完整功能支持Microsoft Windows 11 23H2版本 Linux 部分，完全支持Debian 12.1、12.2，Fedora 39，RHEL 8.9、9.2和9.3，Ubuntu 23.10 macOS 14 Sonoma 支持 其他更新还有很多，我就不一一在这里全部列举了，有兴趣的朋友可以去官网看详细的What’s New手册，也可以直接下载试用版动手试一试​。 ","date":"2023-12-07","objectID":"/2023/12/vdp23h2-update/:3:0","tags":["VDP","VBR","Backup"],"title":"Veeam全线产品2023年下半年度重磅更新","uri":"/2023/12/vdp23h2-update/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 本系列的最后一篇，我想通过一个实例来带大家一步一步做一做，用VRO实现K10的全自动容器灾备。 ","date":"2023-11-10","objectID":"/2023/11/vro-v6-guide-10/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（十） -  使用 VRO 搭配 K10 实现全自动容器灾备","uri":"/2023/11/vro-v6-guide-10/"},{"categories":[],"content":"基础实验环境配置 vSphere 7.0 ","date":"2023-11-10","objectID":"/2023/11/vro-v6-guide-10/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（十） -  使用 VRO 搭配 K10 实现全自动容器灾备","uri":"/2023/11/vro-v6-guide-10/"},{"categories":[],"content":"上一期我们把基础 Kubernetes 环境搭建好了，这期我们来详细说说备份和恢复。 ","date":"2023-11-05","objectID":"/2023/11/kubernetes-pvc-instant-recovery-02/:0:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（下）- 备份与恢复","uri":"/2023/11/kubernetes-pvc-instant-recovery-02/"},{"categories":[],"content":"K10 安装和配置 首先是 K10 安装，没啥特别之处，用官网标准的安装手册去进行 Helm 安装即可，唯一需要注意的是，支持即时恢复的 K10 需要 6.0.8 以上的版本，而VBR需要用到v12版本以上。我这里放一下我用的K10安装参数，供大家参考： # 更新 Helm 仓库 helm repo update \u0026\u0026 helm fetch kasten/k10 # 创建 Namespace kubectl create ns kasten-io # 安装 K10 helm install k10 kasten/k10 --namespace=kasten-io \\ --set global.airgapped.repository=ccr.ccs.tencentyun.com/kasten \\ --set metering.mode=airgap \\ --set auth.tokenAuth.enabled=true \\ --set externalGateway.create=true 安装完成之后可以通过 Loadbalancer 进入 K10 主页进行下一步配置。访问 K10 网页我配置了 token 认证，因为是 1.25 版本了，因此需要按照以下步骤获取 token： # 创建临时 token kubectl --namespace kasten-io create token k10-k10-token --duration=24h # 用这个 token 为 k10-k10 账号创建 secret desired_token_secret_name=k10-k10-token kubectl apply --namespace=kasten-io --filename=- \u003c\u003cEOF apiVersion: v1 kind: Secret type: kubernetes.io/service-account-token metadata: name: ${desired_token_secret_name} annotations: kubernetes.io/service-account.name: \"k10-k10\" EOF kubectl get secret ${desired_token_secret_name} --namespace kasten-io -ojsonpath=\"{.data.token}\" | base64 --decode 在我的这个 Demo 中，K10 会调用 vSphere 的虚拟磁盘快照来进行数据备份的操作，同时会用到 VBR 的 Repository 作为存储库。 进入 K10 主页后，在右侧的 Profile 中找到 Location，我们需要为 K10 配置一个 S3 的对象存储和一个 VBR 的 Repository，其中 S3 对错存储用于存储 Metadata 和 YAML 配置，而 VBR 的 repository 用于 vmdk 数据备份存储，也就是 pvc 的备份。 在 Profile 下面，还有个 Infrastructure，使用 New Profile 按钮新增一个 vCenter 的连接，配置信息非常简单，和任何设备添加 vCenter 几乎没区别，IP 地址、用户名、密码，3 要素。 ","date":"2023-11-05","objectID":"/2023/11/kubernetes-pvc-instant-recovery-02/:1:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（下）- 备份与恢复","uri":"/2023/11/kubernetes-pvc-instant-recovery-02/"},{"categories":[],"content":"备份配置 接下来，就可以进行备份策略的配置了。在使用了 vSphere CSI 后备份策略稍有不同，在 Snapshot Retention 上，可以看到 K10 自动感知到这是 VMware CSI，给出了 VMware 平台中 Snapshot 保留的最佳实践，并提示 K10 不需要保留 local snapshot，因此我将 Snapshot 设置为 0。 在 Export Location Profile 中，可以选择 Wasabi S3 对象存储作为第一级备份 Export 目标，在这里其实 S3 并不存放 vmdk 数据，仅仅是存放应用的 metadata 和 yaml 配置，此处 VBR 的 Location Profile 处于不可选状态。 在这个Enable Backups via Snapshot Exports之后，会有个新增的选项Export snapshot data in block mode，勾选这个选项后，可以选择 Veeam Backup Location Profile。 其他配置没有什么特别，这样配置后的 Policy 如下： 备份自动运行后，可以从 Dashboard 进入查看到详细的备份 Action 详情，其中 VBR 的导出部分由 Kanister 完成： 而在 VBR 中，可以看到 K10 的 Policy 和 K10 的备份存档也已经出现： 关于 VBR 中 K10 的操作，可以参考 Veeam 官方的手册。 ","date":"2023-11-05","objectID":"/2023/11/kubernetes-pvc-instant-recovery-02/:2:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（下）- 备份与恢复","uri":"/2023/11/kubernetes-pvc-instant-recovery-02/"},{"categories":[],"content":"即时恢复 好了接下来到了我们今天的重头戏了，使用 K10 进行容器的即时恢复。 这个即时恢复是在 K10 的控制台中操作，在 K10 的图形化界面中，找到备份下来的存档，点击 restore 按钮，可以看到之前备份下来的还原点。和其他的容器还原一样，选择还原点之后会弹出还原设置窗口。K10 能够自动感知到 vSphere CSI 的支持，在还原选项中能够看到 Enable Instant Recovery 选项。我们只需要选中这个选项，在后面的还原中 K10 就会自动去使用这个能力了。 我们做一些基本配置，比如修改下 namespace 的名字来新建一个应用，然后点击还原，即时还原任务就会开始。 稍等片刻后，我们可以看到容器已经被恢复了，这时候来到 VBR 上，能够看到一个新的 FCD 的即时还原任务已经启动完成。数据还是通过 Veeam 经典的 vPower 技术挂载到 vSphere 上。 使用下 kubectl get pv,pvc 来看下目前的数据卷状态，对于 Kubernetes 来说，毫无感知，无缝恢复。 这时候查看 vSphere 上容器卷的情况，会发现经典的 vPower 技术挂载的 NFS 卷已经被使用在容器的 PV 和 PVC 上了 接下去我们一样还需要通过 Migrate to Production 功能，借助 Storage vMotion 或者 Veeam Quick Migration 功能，将虚拟磁盘文件迁移至虚拟化平台。 系统会自动用 storage vMotion 或者是 quick migration 全自动完成数据的迁移，整个迁移过程 k8s 应用在线正常运行，完全无感知。 迁移完成后，可以在 vSphere Client 中看到容器卷已经运行在 vSAN 上了。 好了，以上这个就是容器的即时恢复，喜欢的朋友赶紧动手试玩下吧，同时也不要忘了一键三连，关注、点赞、在看！ ","date":"2023-11-05","objectID":"/2023/11/kubernetes-pvc-instant-recovery-02/:3:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（下）- 备份与恢复","uri":"/2023/11/kubernetes-pvc-instant-recovery-02/"},{"categories":[],"content":"还记不记得去年我曾经介绍过 VMware 的 FCD 磁盘，并且通过 VBR 的 Instant Disk Recovery 试玩过 K8S 上的即时数据恢复？今年这个功能终于在最新的 K10 中联合 VBR 正式推出了，今天就跟我一起通过一个 Demo 来看看它是如何工作的吧。我的这个 Demo 会分成两部分，第一部分会先带大家来搭建一个可以使用 vSphere Cloud Native Storage 的 K3S 集群，然后第二部分我们再来看 K10 的备份和恢复。 ","date":"2023-11-02","objectID":"/2023/11/kubernetes-pvc-instant-recovery-01/:0:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（上）- 基础环境搭建","uri":"/2023/11/kubernetes-pvc-instant-recovery-01/"},{"categories":[],"content":"vSphere CSI 的安装和配置 使用 Instant Recovery 功能离不开 vSphere，第一个前提要求是 Kubernetes 的 Storage Class 必须使用 vSphere Cloud Native Storage(CNS)。 关于 vSphere CSI 的详细配置，可以参考 VMware 官网链接 ","date":"2023-11-02","objectID":"/2023/11/kubernetes-pvc-instant-recovery-01/:1:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（上）- 基础环境搭建","uri":"/2023/11/kubernetes-pvc-instant-recovery-01/"},{"categories":[],"content":"k3s 节点/集群安装配置 本次 Demo 实验环境是部署在我家 HomeLab 中一台 NUC11 猎豹峡谷上，这台 NUC 配置了 64G 内存和 1 块 NVME 的 SSD 硬盘，上面运行的是 vSphere 7u3。 在这个环境中，我的 Kubernetes 使用了轻量级的 K3S 1.25s1 版本，安装在一台 Ubuntu 20.04 上，配置成单节点启动实验环境。默认部署的 K3S 会禁用大多数 Cloud Provider，因此我需要调整一下 K3S 的安装参数，然后额外安装 VMware Cloud Manager。 # 安装命令 curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=\"v1.25.8+k3s1\" INSTALL_K3S_EXEC=\"server --disable-cloud-controller --disable=servicelb --disable=traefik --disable-network-policy --disable=local-storage\" sh -s - 安装完成后，先别急着启动，实际上我们还缺一些参数，需要配置到/etc/systemd/system/k3s.service文件中。用 VI 编辑器打开 k3s.service 文件，在 [Service] 这节中找到 ExecStart，额外加上 2 行启动参数--kubelet-arg=cloud-provider=external和--kubelet-arg=provider-id=vsphere://$master_node_id。加上后，k3s.service 文件的最后一部分如下： ExecStart=/usr/local/bin/k3s \\ server \\ '--disable-cloud-controller' \\ '--disable=servicelb' \\ '--disable=traefik' \\ '--disable-network-policy' \\ '--disable=local-storage' \\ '--kubelet-arg=cloud-provider=external' \\ '--kubelet-arg=provider-id=vsphere://$master_node_id' \\ 修改完后，可以用重新 reload 下 k3s service，然后重启下即可。 sudo systemctl daemon-reload sudo service k3s restart 接下去就可以通过 k3s 提供的 config 文件正常访问 cluster 了。 export KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl get pods --all-namespaces ","date":"2023-11-02","objectID":"/2023/11/kubernetes-pvc-instant-recovery-01/:1:1","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（上）- 基础环境搭建","uri":"/2023/11/kubernetes-pvc-instant-recovery-01/"},{"categories":[],"content":"vSphere CSI 安装 接下来我们需要把 vSphere datastore 挂载给 k3s 使用，这里需要准备一些配置文件，一共有 4 个，其中 1 个是 conf 文件，3 个是 yaml 文件。分别如下： vsphere-cloud-controller-manager.yaml csi-vsphere.conf vsphere-csi-driver.yaml storageclass.yaml vsphere-cloud-controller-manager.yaml 文件 这个文件可以从 Kubernetes 官方的 github 仓库中获取模板，不同 k8s 版本的模板不一样，我用 1.25 的版本，就下载了 1.25 的对应文件： curl -O https://ghproxy/https://raw.githubusercontent.com/kubernetes/cloud-provider-vsphere/master/releases/v1.25/vsphere-cloud-controller-manager.yaml 这个文件下载后不能直接使用，需要修改里面的 vCenter 地址和权限信息。 其中第一部分需要修改的是 Secret 中的 stringData，这里需要根据模板的样例填入 vCenter 的 ip、用户名和密码。然后第二部分需要修改的是 ConfigMap 中 data 下面的 vsphere.conf 中的内容，这里可以看到还是 vCenter 内的一些信息。 另外，如果无法访问 gcr.io 的话，还需要修改 DaemonSet 中的容器镜像地址，在我的腾讯个人镜像库里，已经放了 1.25.2 的镜像，地址如下：ccr.ccs.tencentyun.com/vsphere-csi/manager:v1.25.2 修改完后，这个文件可以放一边备用。 csi-vsphere.conf 文件 这个文件用于 vmware-system-csi 这个 namespace 下面创建 secret 用户，模板也可以从 VMware 官网 找到，以下是我修改后，在我的 demo 中用的内容： [Global] [VirtualCenter \"\u003cipaddress or fqdn\u003e\"] insecure-flag = \"true\" user = \"\u003caccount\u003e\" password = \"\u003cpassword\u003e\" port = \"443\" datacenters = \"\u003cdatacenter name\u003e\" vsphere-csi-driver.yaml 文件 这个文件也可以从 VMware 的 Github 仓库中直接获取，下载后里面的内容不需要修改，可以直接使用。 curl -O https://ghproxy/https://raw.githubusercontent.com/kubernetes-sigs/vsphere-csi-driver/v3.0.0/manifests/vanilla/vsphere-csi-driver.yaml 但是如果和我一样无法访问 gcr.io 的话，还是要修改下这个文件中用到的镜像的地址，可以用我的腾讯个人镜像库里面的这些： ccr.ccs.tencentyun.com/vsphere-csi/csi-attacher:v4.2.0 ccr.ccs.tencentyun.com/vsphere-csi/csi-resizer:v1.7.0 ccr.ccs.tencentyun.com/vsphere-csi/driver:v3.0.0 ccr.ccs.tencentyun.com/vsphere-csi/livenessprobe:v2.9.0 ccr.ccs.tencentyun.com/vsphere-csi/syncer:v3.0.0 ccr.ccs.tencentyun.com/vsphere-csi/csi-provisioner:v3.4.0 ccr.ccs.tencentyun.com/vsphere-csi/csi-snapshotter:v6.2.1 ccr.ccs.tencentyun.com/vsphere-csi/csi-node-driver-registrar:v2.7.0 storageclass.yaml 文件 最后，需要准备 storageclass 的 yaml 文件，这个模板也可以在 VMware 官网 找到，在我的 demo 中，我对文件进行了一些修改。 kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: standard annotations: storageclass.kubernetes.io/is-default-class: \"true\" provisioner: csi.vsphere.vmware.com parameters: datastoreurl: ds:///vmfs/volumes/578a0d70-0be672b6-a3f7-34e6d7803208/ 这个模板只有 2 个内容需要修改，其中 metadata 下的 name 字段，可以根据自己需要随意命名，另外一个是 datastoreurl，这个 url 需要去 vCenter 中，找到对应的 datastore，在摘要界面中寻找这个信息，如图。 CSI 安装 好了，准备完上述文件后，就可以开始安装了，整个安装过程相对来说比较简单，命令如下： #安装 ccm kubectl apply -f vsphere-cloud-controller-manager.yaml #创建 csi 管理 namespace kubectl create namespace vmware-system-csi #禁止调度 kubectl taint nodes $nodeid node-role.kubernetes.io/control-plane=:NoSchedule #确认上一条命令执行情况 kubectl describe nodes | egrep \"Taints:|Name:\" #创建连 vc 用的用户名密码的 secret kubectl create secret generic vsphere-config-secret --from-file=/home/lei/csi-vsphere.conf --namespace=vmware-system-csi #创建并启动 csi 驱动 kubectl apply -f vsphere-csi-driver-ccr-ccs.yaml #确定 pod 全部启动后，重新启用容器调度 kubectl taint nodes $nodeid node-role.kubernetes.io/control-plane=:NoSchedule- #创建存储类 kubectl apply -f storageclass.yaml 安装完成后，如果没有任何报错，可以看到 CSI 的相关容器都正常启动了。接下去部署个应用使用这个 Storage Class 试试，demo 用的 yaml 如下。 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: demo-pvc labels: app: demo pvc: demo spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: demo-app labels: app: demo spec: replicas: 1 selector: matchLabels: app: demo template: metadata: labels: app: demo spec: containers: - name: demo-container image: alpine:3.7 resources: requests: memory: 256Mi cpu: 100m command: [\"tail\"] args: [\"-f\", \"/dev/null\"] volumeMounts: - name: data mountPath: /data volumes: - name: data persistentVolumeClaim: claimName: demo-pvc 部署一下看看。 # 创建 namespace kubectl create ns demo # 部署应用 kubectl apply -f demo.yaml 部署完后，在 vCenter 中能看到对应的 vmdk，这样的状态，VMware CSI 就正确配置完成了。 ","date":"2023-11-02","objectID":"/2023/11/kubernetes-pvc-instant-recovery-01/:1:2","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（上）- 基础环境搭建","uri":"/2023/11/kubernetes-pvc-instant-recovery-01/"},{"categories":[],"content":"配置 Loadbalance 在我的 Demo 中，我还多配置了一个本地的 Loadbalance，用来为我的应用分配 IP 地址，在这里我选用了 MetalLB。安装也非常简单，在我的环境中，我使用了 0.13.9 的版本，从官网下载 yaml 文件，然后修改下镜像库即可。 curl -O https://ghproxy/https://raw.githubusercontent.com/metallb/metallb/v0.13.9/config/manifests/metallb-native.yaml 修改的镜像也有我的腾讯镜像库版本： ccr.ccs.tencentyun.com/vsphere-csi/metallb-controller:v0.13.9 ccr.ccs.tencentyun.com/vsphere-csi/metallb-speaker:v0.13.9 除了这个 LB 标准应用的 yaml 之外，我们还要一个 ip 地址配置的 metallb-config.yaml，模板官网 也有，我这里稍作修改： apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: first-pool namespace: metallb-system spec: addresses: - 10.10.1.230-10.10.1.240 --- apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: l2-config namespace: metallb-system spec: ipAddressPools: - first-pool 使用 kubectl apply 命令进行部署： # 部署 metallb kubectl apply -f metallb-native.yaml # 配置 metallb kubectl apply -f metallb-config.yaml 这样配置完成后，应用程序就可以直接使用了，对于 K10 来说，只需要简单的指定 externalGateway 参数为 true，metallb 就能够自动为 K10 分配访问地址了，非常方便。 好了，基础环境搭建就这些，我们下期详细介绍 K10 的备份与即时恢复。 ","date":"2023-11-02","objectID":"/2023/11/kubernetes-pvc-instant-recovery-01/:2:0","tags":["VMware","Kubernetes","Instant Recovery"],"title":"极速恢复：Kubernetes 容器即时恢复技术详解（上）- 基础环境搭建","uri":"/2023/11/kubernetes-pvc-instant-recovery-01/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 本系列的最后一篇，我来介绍一下 VAO 的文档系统。 VAO 能够全自动的为管理员生成灾备需要的系统文档，文档的内容为 VAO 系统自动根据 Orchestration Plan 的设置和执行自动生成。VAO 文档系统的强大在于所有的内容系统根据配置和运行会全自动生成，因此管理员只需要专心关注自己的灾备即可，这些后续的基础保障，繁琐的文档制定，全部交给 VAO 来完成。 VAO 生成的每个文档会包含两部分，第一部分是灾备管理员定义的 Report Template；第二部分是系统根据 Report Type 生成的动态内容。无论什么类型的文档，在文档的开头部分都会使用 Report Template 中所定义的内容，而第二部分则根据 Report Type 不同自动填充相关内容。 我们先来看个实际的例子，了解一下什么是 Report Template 中的内容，什么是根据 Report Type 自动生成的，如下图： 左边是一个 VAO 最终生成的 Readiness Check 的 Report，右边是我们在编辑器中打开的 Report Template。可以看到红色框所示的内容就是来自于 Report Template 的，而图中左边文档的后半部分内容则是根据这个 Report Type，自动产生的内容。 ","date":"2023-10-31","objectID":"/2023/10/vro-v6-guide-09/:1:0","tags":["VAO"],"title":"VAO 基础入门（九） -  文档模板解析","uri":"/2023/10/vro-v6-guide-09/"},{"categories":[],"content":"Report Type 先来说说这个 Report Type，也许聪明的你，在前几篇介绍 Orchestration Plan 的时候已经有看到，在每个 Plan 的右键菜单或者工具栏上有一些 Report 可以生成，它们分别是： Report 类型 作用 Plan Definition Report 记录灾备计划设置详情 Readiness Check Report 灾备计划可用性检测报告，包含恢复目标位置和灾备中心的可用性检测 Datalab test Reort 数据实验室测试报告 Excution Report 灾备执行情况报告 这些 Report 就是 VAO 能够生成的所有 Report 文档，这些文档都会有一个 VAO 已经内置设计好的内容，能够和灾备管理员定义的 Report Template 组合起来，最终形成一份完整可以阅读的 Report。 这部分 VAO 已经内置的内容，我们无法做任何的更改，系统都会根据实际的报告类型、当前灾备计划的设定、灾备计划的运行和执行来自动生成这个内容，因此我们也不需要对这里的内容做更改设定。 所以，此部分的内容目前只包含英语版本，我们没有任何方法去修改其中相关信息，当然如果我们的 Plan 中如果包含中文的信息，VAO 还是能够正确的传递给 Report，生成相关内容。 ","date":"2023-10-31","objectID":"/2023/10/vro-v6-guide-09/:2:0","tags":["VAO"],"title":"VAO 基础入门（九） -  文档模板解析","uri":"/2023/10/vro-v6-guide-09/"},{"categories":[],"content":"Report Template Report Template 的内容是管理员可以根据自己需求进行定制每个文档的前半部分，在 VAO 出厂软件中，已经内置了 8 国语言的默认模版，需要注意的是，这些默认模版都是无法编辑的，但是是可以直接被 Report 系统调用在 Orchestration Plan 中使用的。如果需要编辑这些模版，或者创建自己的模版，需要首先从这些模版 Clone 一份自己的拷贝，然后在这个基础上进行修改。 修改这些文档需要用 Word，要求是 Word 2010 SP2 以上版本，也就是说，需要在当前打开 VAO 网页的电脑上，同时安装了 Word 2010 SP2 以上版本，才能正常的进行编辑。点击 VAO 界面中的 Edit 按钮后，系统会自动从网页浏览器切换至 Microsoft Word 中进行编辑。 和普通的 Word 编辑完全不一样的是，这个模板的编辑是个动态文档的编辑，可以加入很多 VAO 中的变量，让 VAO 系统在生成 Report 的时候自动填充。 ","date":"2023-10-31","objectID":"/2023/10/vro-v6-guide-09/:3:0","tags":["VAO"],"title":"VAO 基础入门（九） -  文档模板解析","uri":"/2023/10/vro-v6-guide-09/"},{"categories":[],"content":"如何使用 Word 编辑动态文档 首先需要选择一个内置的 Template 作为我们要编辑的对象，点击 Clone 按钮启动创建自己的 Template。比如我这里选择Veeam Default Template（ZH）。 在 Clone Template 对话框中，选择分配给自己名下的哪个 Scope，然后为这个 Template 起个响亮的名字，填写一段描述，就能完成模板创建。 创建完成后，在 Template 清单中就能看的这个模板，并且上面的工具栏按钮也可以对这个模板进行操作了，可以点击 Edit 进行内容编辑。在这里 VAO 并不提供内置的文档编辑器，这个 Edit 按钮会直接调用当前浏览器所在的计算机打开 Word 进行编辑，要求管理员必须已经正确安装了 Microsoft Word。 点击 Edit 之后，会切换到 Word 程序，需要注意的是，Word 不会立即打开文档，而是需要一个访问的权限，这里需要的权限必须是当前在浏览器中登入 VAO 的用户，否则这个 Word 将打不开该文档模板。 打开文档后，即可正常进行 Word 的编辑了。这个文档并不是全文档都可以编辑，您会发现很多区域被黄色的荧光标注了，这部分内容才是允许编辑的区域，在这里可以任意的加上需要的文字和图片内容。所以，可以看到，这个文档的标题、页眉和页脚是不可被修改的，而其他部分，都是可修改的。 因为这是个动态文档，所以在这里我们可以调用很多很多 VAO 的变量内容来取得数据，VAO 系统已经给我们做了一些示例，在 Clone 出来的这个文档中，仔细观察这些文字，会发现有一些文字内容被 [] 包围，这部分内容就是这个文档中动态的变量内容。这个编辑和我们正常的 Word 编辑稍微有些不同，我们来看看如何进行操作。 要编辑这个变量数据，首先我们可以按正常方式输入一段文字内容，为了区分和普通文字的不同，建议也和 VAO 默认文档一样，加上 []，比如：[Hi，我是变量]，在上方工具栏，找到开发工具，打开设计模式。 在打开设计模式后，会发现这个文档变得好奇怪，之前藏起来的很多内容显现出来了，这时候别被这些多出来的内容吓到，他们实际上并不存在，关掉设计模式后他们会自动藏回去，这只是我们的变量设置结果而已。 接下去，我们对[Hi, 我是变量]进行设置，选中这段文字，然后需要点击设计模式左边的第一个Aa按钮，就能将这段文字变成和模板中一样的变量了，然后再点击设计模式下方的属性，可以打开变量设定的对话框，它是使用 Word 的内容控件来实现的，设定这个内容控件的属性即可完成。 这个变量设置非常简单，只需要输入一个标题和一个标记，一般来说，这两个设置成一样的就行了，标题跟着标记的内容来填写。VAO 内置了以下可用的所有标记，所有标记都是以“~”开头，选择需要的标记填入到上面的这个属性框中点确定即可。 变量名 作用说明 ~Created Report 生成时间 ~TimeZone Report 生成时区 ~PlanType VAO 计划类型 ~PlanName VAO 计划名称 ~PlanDescription VAO 计划描述 ~PlanContactName 灾备计划联系人姓名 ~PlanContactEmail 灾备计划联系人邮箱 ~PlanContactTel 灾备计划联系人电话 ~Site 站点名称 ~SiteScopeName 站点范围名称 ~SiteDescription 站点描述 ~SiteContactName 站点联系人姓名 ~SiteContactEmail 站点联系人邮箱 ~SiteContactTel 站点联系人电话 ~ServerName 服务器名称 ~VmsInPlan 在该计划中的虚拟机 ~GroupsInPlan 在该计划中的虚拟机组 ~ReportType Report 类型 ~TargetRTO 该计划的目标期望 RTO ~TargetRPO 该计划的目标期望 RPO 在根据需要写完这个文档之后，只需要按照正常保存或者关闭这个文件就可以将文档提交至 VAO 服务器了，千万记得不要使用另存为，另存为之后，就不会更新至 VAO 服务器，这个编辑也就白搭了。 Report Template 编辑完成后，就可以回到 VAO 网页 UI 中查看修改结果了，管理员也可以根据不同的 Scope 的设置，为不同的 Orchestration Plan 选择并使用这个新创建的 Report Template。 以上就是 VAO 的所有内容，希望对大家了解 VAO 有帮助，感谢关注和阅读！ ","date":"2023-10-31","objectID":"/2023/10/vro-v6-guide-09/:4:0","tags":["VAO"],"title":"VAO 基础入门（九） -  文档模板解析","uri":"/2023/10/vro-v6-guide-09/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 上一篇，我介绍了 Plan Step 的基本配置和使用，今天我来详细分解下在 Plan Step 中的自定义脚本，我会通过一个脚本使用例子，来带大家使用一下自定义脚本。 ","date":"2023-06-16","objectID":"/2023/06/vro-v6-guide-08/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（八） -  Plan Step · 下篇","uri":"/2023/06/vro-v6-guide-08/"},{"categories":[],"content":"创建和设置 配置自定义的脚本需要使用隶属于 Administrators 组的账户登入 VRO 平台。进入 Administration 控制台后，可以在 Configuration 下面找到 Plan Steps，在这里可以管理所有的 Plan Steps，当然除了创建自定义的 Steps 之外，也可以在这里对内置的那些 Steps 进行一些个性化的配置。 点击 Add 按钮即可进入添加向导，过程也非常简单，为它起个响亮的名字，比如：远程的骚操作测试，点击 Next 进入下一步。 在 Script 步骤中，找到 File 栏，点击 Browse 从当前的客户端上去选择制作好的 powershell 脚本，上传的脚本会在 Preview 中显示详细内容。点击 Next 进入下一步。 在 Step Visibility 步骤，如果不希望所有的灾备管理员都看到这个骚脚本的话，可以不勾上这个界面的复选框。 最后还是老样子，Summary 总结一下，点 Finish 就创建完成了。 但是，这只是创建完成，别想着就马上拿去用，这里特别敲黑板强调一下，自定义脚本可以有两种不同执行位置，一种是在灾备的机器上执行，另外一种是在 VBR 上执行。这个必须手工在创建完 Plan Step 之后点击这个 Step 名称，找到 Edit 进行修改，这时候会发现，除了前面的创建向导的步骤之外，还会多出一个叫 Step Parameters 的步骤，在这里可以进行更多的详细配置，也包括修改默认执行位置。 默认值是在 VBR 上执行。比如我今天要做的这个测试就是需要调整一下，更改成 In-Guest OS。 需要注意的是，这个 Step 的设置是全局的，也就是说，如果将这个 Step 提供给所有的 Scope 使用，那么这项配置内容是所有的 Scope 共享的，不能做计划任务中做更改。因此管理员如果有必要，需要做这个 Plan Steps 的管理页面中根据实际需求逐个定义。 ","date":"2023-06-16","objectID":"/2023/06/vro-v6-guide-08/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（八） -  Plan Step · 下篇","uri":"/2023/06/vro-v6-guide-08/"},{"categories":[],"content":"Hello！My Script 那么接下来，让我们来配置一个 Script 跑一把吧。来个简单的，内容如下： ########### #Lei Wei - 02/28/20 # # 这个脚本是骚操作的代表，请仔细往后看 # # v1.0 $S = Get-Date; Add-Content c:\\VRO_log.txt \"$S - Recording date \" 如果一切正常，在 VRO 中将会看到如下信息： ","date":"2023-06-16","objectID":"/2023/06/vro-v6-guide-08/:3:0","tags":["VAO","VRO"],"title":"VRO 基础入门（八） -  Plan Step · 下篇","uri":"/2023/06/vro-v6-guide-08/"},{"categories":[],"content":"让我们变得更复杂一点 好在这个脚本实在太简单了，几乎不可能会出现报错，那么如果复杂一点，脚本成功或者报错，VRO 能否捕获这些错误让我们的管理员能够更方便的知道系统发生了什么问题呢？请看以下代码： ########### #Lei Wei - 02/27/20 # # 这个脚本是骚操作的代表，请仔细往后看 # # v1.1 try { $S = Get-Date; Add-Content c:\\VRO_log.txt \"$S - Recording date. \" Write-Host \"准确计时，骚操作成功\" } Catch { Write-Error \" 不知道哪里坏了，失败了！\" Write-Error $_.Exception.Message } 在更换成这个 Powershell 执行之后，可以看到如下 VRO 界面中的执行成功记录，除了记录成功失败，还将我设置中脚本中的信息同时传递到了 VRO 界面之中。 ","date":"2023-06-16","objectID":"/2023/06/vro-v6-guide-08/:4:0","tags":["VAO","VRO"],"title":"VRO 基础入门（八） -  Plan Step · 下篇","uri":"/2023/06/vro-v6-guide-08/"},{"categories":[],"content":"更多参数传递 VRO 所使用的脚本还可以更复杂，比如说，可以通过 VRO 传递一些参数给脚本。我们来继续修改上面的脚本，如下： ########### #Lei Wei - 02/27/20 # # 这个脚本是骚操作的代表，请仔细往后看 # # v1.2 Param( [Parameter(Mandatory=$true)] [string]$planName, [string]$text ) try { $S = Get-Date; Add-Content c:\\VRO_log.txt \"$S - Recording date. \" Write-Host \"准确计时，骚操作成功\" Write-Host \"准确计时，骚操作成功，$planName，$text !\" } Catch { Write-Error \" 不知道哪里坏了，失败了！\" Write-Error $_.Exception.Message } 这个脚本中，我们配置了两个参数，$planName 和$text，如果要在 VRO 中正确使用参数，并将相关参数传递给脚本，那么就需要我们为这个 Plan Step 加上额外的参数，这个可以通过 Plan Step 中右边的 Add 按钮来完成。 需要注意的是，我们 Add 的参数，它的名称必须和脚本中的参数名称保持一致，才能够被正确的传递，如下图，我们设置了 planName 和 text。 这里 planName 的 default 值设置为$plan_name$，这个内容是 VRO 中系统自带的一些变量，在我们的传递参数中，可以直接使用。具体列表在点击 Edit 按钮时会直接弹出供我们选择。 而$text，我们直接输入 Default Value，而不是使用 VRO 内置的系统变量，输入的内容为：完成参数传递。 最后让我们来看看这个脚本骚操作在 Orchestration Plan 中执行结果吧，我们的 Step Details 和 Report 中会出现什么： 感觉怎么样，是不是觉得 VRO 很棒？赶紧动手试一试吧。 ","date":"2023-06-16","objectID":"/2023/06/vro-v6-guide-08/:5:0","tags":["VAO","VRO"],"title":"VRO 基础入门（八） -  Plan Step · 下篇","uri":"/2023/06/vro-v6-guide-08/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 在之前的帖子中，我们详细讨论了 Orchestration Plan 的创建过程。在每个 Orchestration Plan 中除了基础的这些创建步骤之外，这个系统重最重要的是它的自动化流程，这个自动化流程是通过 Powershell 脚本来实现。在 VRO 中，这些 Powershell 的自动化脚本被封装在 Plan Step 中，由 VRO 的 Orchestration Plan 来调度执行和传递参数。 每个 Orchestration Plan 创建时，会带入默认的几个 Plan Steps，这几个基本上就是我们每次灾备都会涉及的开机关机等操作。管理员可以编辑 Orchestration Plan，在其中加入一些额外的 Steps。 ","date":"2023-06-14","objectID":"/2023/06/vro-v6-guide-07/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（七） -  Plan Step · 上篇","uri":"/2023/06/vro-v6-guide-07/"},{"categories":[],"content":"Orchestration Plan 的详细管理和使用方法 在 VRO 的主界面中，找到左边的 Orchestration Plans，点击它后进入 Orchestration Plans 仪表盘，选择一条我们要编辑的 Plan，点击 Plan 名字，即可进入该 Plan 内。 在 Plan Details 中，可以看到从左到右的 5 个按钮分别是 Run、Halt、Check、Undo 和 Edit，其中包含了三大经典按键：Run 是执行键，Halt 是暂停键，Undo 是取消键。除了这 3 个之外，Check 是 Plan 检查就绪状态的按键，如果就绪状态 failed，那么这个计划在执行时很大可能就会失败；Edit 是今天要详细介绍的，我们用来加入自动化流程的主要按键。点击 Edit 之后，能进入 Plan 的编辑界面。 在 Plan Edit 界面中，整个布局呈从左到右的顺序排列，在最左边的框中是计划的分组，点击左边的框中的内容后往右依次会展示这个对象下的包含的对象和可用操作。 在最左边的框中有 Pre-Plan Steps 和 Post-Plan Steps 这两个默认的分组和用户定义分组，其中位于两个默认组中间的用户定义分组是有比较多的调整内容的部分，可以通过 Add 或 Properties 打开设置向导，进行一些配置，这些配置和之前提到的创建 Orchestration Plan 中的部分内容基本相同，换句话说就是在创建完 Plan 后，还需要调整创建过程中的部分参数，可以来这里调整。 而对于 Pre-Plan steps 和 Post Plan steps 这两个 Group 来说，这两个 Step 并不包含任何的实际机器，因此使用者无法调整这两个 Plan 的任何属性。然而 VRO 能够让我们往这两个 Plan Steps 的 Group 中添加一些 steps，这就能够让我们能够在 VRO 的正式执行 Plan 之前或者之后执行一些自定义流程了。点击 Pre-Plan Step 后，右边的框会出现具体 Steps 的选项，默认情况下，里面没有任何记录，可以通过 Add 按钮来添加，如下图。 在这里可以添加的 VRO 系统内置的 Step 有： Generate Event - 生成一个 Windows 事件，记录在 Windows event viewer 中。 Send Email - 发送电子邮件。 Veeam Job Actions - 操作 VBR 上的备份或者复制作业，可以进行 Enable、Disable、Start、Stop 这 4 个操作。 VM Power Actions - 操作 VC 上的虚拟机开关机，这对于灾备中心切换前关闭不重要的机器释放资源用于切换会非常有用。 其他任何用户定义的 Powershell 脚本。 对于用户定义分组，里面包含的是实际要做 restore 或者 failover 的机器，这时候，当我选择某个机器时，VRO 就会让我定义这台机器执行 restore 或者 failover 时我需要加入的 Step，对于已经添加的 Step，也可以修改执行先后顺序和定义详细参数。 在这里出厂内置的 Step 有以下这些，我做了个简单的分类： 应用验证类：12 个（AD、Exchange、Sharepoint、SQL 和 IIS） 虚拟机验证类：2 个（心跳和 ping 包） 事件通知类：2 个（Windows Event 和邮件） 资源操作类：3 个（虚拟机开关机、Windows 服务启动、源虚拟机关机） ","date":"2023-06-14","objectID":"/2023/06/vro-v6-guide-07/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（七） -  Plan Step · 上篇","uri":"/2023/06/vro-v6-guide-07/"},{"categories":[],"content":"Plan Step 通用参数 在每个 Plan Step 中，都会包含一个最基础的Common Parameter，这是对于这个 Plan Step 执行的基本控制条件，包含以下内容： During Failback \u0026 Undo : 决定在 Failback 和 Undo Failover 操作时是否执行脚本 During Lab Test : 决定在 Datalab 测试中是否使用脚本 Critical step : 定义这个 Step 对于整个 Plan 是否重要，如果是，则失败后立刻停止计划 Timeout : 定义整个 Step 执行超时时间 Retries : 定义失败重试次数 这些参数可以在每个 Orchestration Plan 中为每个 step 单独调整。 ","date":"2023-06-14","objectID":"/2023/06/vro-v6-guide-07/:3:0","tags":["VAO","VRO"],"title":"VRO 基础入门（七） -  Plan Step · 上篇","uri":"/2023/06/vro-v6-guide-07/"},{"categories":[],"content":"自定义脚本 VRO 还提供了自定义脚本功能，管理员可以在 VBR 服务器或者恢复后的系统上直接调用使用 Powershell 脚本，完成各种骚操作。 举个例子，数据中心某应用架构如下： 典型的三层架构，Oracle 数据库在 AIX 小机上，中间件和应用服务器跑在 VMware vSphere 上面。灾备系统设计之初，Oracle 数据库通过 OGG 做了复制，实现了数据级同步。 这样的架构，通常 Veeam 使用 VBR 的时候会建议用户对虚拟化平台也做一个保护，确保在主数据中心出现故障的时候能够应用系统和数据库都切换至灾备中心。而在使用了 Veeam 的解决方案后，通常我们的用户都会发现，VBR 不仅能够很好的完成虚拟化平台的灾备复制任务，同时他的灾备演练能力也极其强大，系统会真实的被恢复出来并且提供恢复后的演练访问，真枪实弹的完成整个演习过程，并且还是全自动的。 但是，管理员很快会发现，很尴尬的一点是，应用系统没有数据库的数据支持，就算恢复了，也没办法正常工作，这样的测试还是无法最终等效于实际灾备场景。 ","date":"2023-06-14","objectID":"/2023/06/vro-v6-guide-07/:4:0","tags":["VAO","VRO"],"title":"VRO 基础入门（七） -  Plan Step · 上篇","uri":"/2023/06/vro-v6-guide-07/"},{"categories":[],"content":"VRO 来帮忙 这事情借助 VRO，可以完美的解决。整个过程会是这样： 启动应用系统的 Failover / Restore Plan，可以在真正的恢复过程前的 Step 中，加入 Powershell 脚本，和灾备站点的 AIX 进行通讯。 AIX 上脚本执行后，新的 LPAR 部署出来。 再来一个脚本，将一个虚拟网卡 attach 到新部署出来的 LPAR 上，并让这个网卡和我们在虚拟化环境中创建出来的沙盒隔离网络相连，隔离网络无法直接路由访问到生产，所以是相对隔离的环境。 第三个脚本搞起，让最新的一份 Oracle 数据库运行在这个新的 LPAR 上。 一切准备结束，启动虚拟化灾备平台中的应用和中间件副本，这样在这个隔离环境中，起来的应用和中间件就可以访问 AIX 数据库了。 到这里还没完工，系统都跑起来了，让这套系统别停下，飞一会儿吧，可以在上面做一系列测试、开发等等操作。 经过一段漫长的测试，系统使用完毕，灾备管理员被通知可以回收了。灾备管理员操作 VRO，让系统进入下一步流程。 vSphere 上的虚拟机被 Undo Failover 到演练之前的状态，这个非常简单，和 VBR 上几乎没差别。 一个新的脚本被触发，通知 AIX，请删除这个 LPAR 和他上面的数据库，确保测试的数据不会被复制回生产中。 以上这个过程，是不是很不错？这样的过程不仅可以是加入和 AIX 的配合，同样各种系统不管是 HPUX 还是 Oracle Exadata 都可以搞一搞。对了，还有公有云，一起加入到这个灾备 Party 中吧，有了 VRO，这都不是事。 所以，有了自定义脚本和计划任务的调度，VRO 神通广大，几乎能做任何由 Powershell 可以实现的事情。在下一篇，我会来详细介绍如何玩转这个自定义脚本。 ","date":"2023-06-14","objectID":"/2023/06/vro-v6-guide-07/:5:0","tags":["VAO","VRO"],"title":"VRO 基础入门（七） -  Plan Step · 上篇","uri":"/2023/06/vro-v6-guide-07/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 Veeam 的产品怎么可以少了数据实验室（Datalab)，在 VRO 中，加强版的 Datalab 会比 VBR 中的功能更强大。今天我们就来说说这个加强版的数据实验室。 VRO 的数据实验室目前支持以下几种 Plan： Replica Plan Restore Plan（vSphere 和 Agent） Storage Plan 在数据实验室中，这几种 Plan 都会启动整个恢复流程，只是这个流程启动后，完全不影响生产系统。VRO 正确的选择数据实验室的网络和所有指定的恢复步骤完成所有的灾备测试。 和 VBR 中的 Virtual Lab 不一样的是，在 VRO 中 Datalab 可以独立启动，启动后的 Datalab 实际上是为我们开启了一套隔离网络，这套隔离网络的基础网络服务由 Datalab 的 Proxy 提供，而基础依赖应用则由 Lab Group 来提供。 在 VRO 中启动 Datalab 只需要打开 VRO 控制台，找到左边的 Datalabs 选择它，然后在中间内容显示区域会看到已分配的 Datalab，选中后，可以点击上方 Run 按钮来启动这个 Datalab。 Datalab 启动后可以把它理解为数据实验室的路由器被启动了，这时候任何放入这个网络的机器就能正常使用这个数据实验室网络了。 ","date":"2023-06-07","objectID":"/2023/06/vro-v6-guide-06/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（六）-  数据实验室","uri":"/2023/06/vro-v6-guide-06/"},{"categories":[],"content":"Datalab 测试 在 Orchestration Plan 的 Verity 按钮下，可以找到 Run Datalab test 的按钮，点击这个按钮后，会启动一个 DataLab test 的向导，通过这个向导中选择一些合适的选项，可以对于整个灾备计划做一次近乎真实的演练，整个演练过程甚至会 100%模拟实际的 Plan 执行，包括了其中所有设置的自定义脚本，只是在分配网络的时候会选择 Datalab 的隔离网络。因此管理员能从这样的演练过程中清楚的掌握实际灾备环境中恢复的状况以及需要的恢复时间。 3 种类型的 Plan 在执行 Datalab test 时，步骤上几乎没有太大差别，今天我就仅以 Restore Plan 为例子来说明整个过程。 打开 Datalab Test 向导后，我们首先需要选择 Test Method。这里 Quick Test 和 Full Restore Test 的区别是即时恢复和完整恢复的差异，在做 Datalab Test 时，一般我们会选择 Quick Test，而在长期使用测试环境时，可以选择 Full Restore Test。 在 Datalab 步骤中，我们看到在前面开启 Datalab 后，这里 Datalab 已经处于 running 状态了，我们可以选中它，然后点击下一步。 在 Recovery Location 步骤中，我这里选择在原位置还原，因为是 Datalab 测试，所以 Datalab 会自动为我的测试机器重命名。点击下一步。 在 Power Options 步骤中，可以选择测试完立刻关机，也可以选择测试完继续运行一段时间，这时候用这种方式，我们可以开启数据实验室用于各种实验环境的搭建。 在 Ransomware Scan 步骤中，借助 VBR 的 secure Restore 能力，VRO 能够全自动的寻找所有还原点中没有被勒索病毒污染的还原点实现干净还原。 在 Summary 中，还是国际惯例，总结下前面的选项，点击 Finish 就可以启动数据实验室测试。 在数据实验室启动后，点击 Plan 名字就能进入数据实验室的详细验证步骤查看，如下图。 ","date":"2023-06-07","objectID":"/2023/06/vro-v6-guide-06/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（六）-  数据实验室","uri":"/2023/06/vro-v6-guide-06/"},{"categories":[],"content":"日常计划任务测试 除了可以手工执行 Datalab test 之外，VRO 也可以全自动按计划任务执行 Datalabs Test。在 VRO 的仪表盘中，找到 Lab Calendar 部分，在这里可以看到 Create Schedule 按钮，就是用来设置全自动的 Datalab test 计划任务。 点击 Create Schedule 按钮后，会启动 Create Test Schedule 向导 在 Scope 步骤中先选择下 Scope，设置下权限，点击下一步。 在 Schedule Info 步骤中，设置计划任务的名称和描述，比如我这里设置了 Daily Verification。点击下一步。 在 Choose Plans 步骤中，选择需要验证的 Plan，然后点击 Add 添加。在这个步骤中，可以多选多个 Plan，这样这些 Plan 就都能够按照这个计划任务的设定进行测试。 在 Datalab 步骤中，选择一个 Datalab，点击下一步。 在 Recurrence and Start 步骤中，设定计划任务，比如我这里设置每周一三五运行测试计划，点击下一步。 在 Restore Options 步骤中，选择恢复模式，推荐日常测试选择 Quick Test，点击下一步。 在 Power Options 步骤中，选择默认的选项 Test then power off immediately，点击下一步。 在 Ransomware Scan 步骤中，可以选择病毒扫描，这里我们保持默认不勾选，点击下一步。 在 Summary 步骤中，可以查看以上设置，并且可以通过 copy to clipboard 来复制这里的信息。点击 Finish 按钮就可以结束向导完成设置。 回到 VRO 仪表盘 Lab Calendar 界面，我们可以看到日历表中已经出现了每天的验证计划。 如果再次点击其中一个计划任务的名字，我们可以重新编辑这个计划任务，并且还能删除和禁用这个计划任务。 以上就是 VRO 中数据实验室的具体设置和使用方法。 更多内容欢迎关注本人公众号， ","date":"2023-06-07","objectID":"/2023/06/vro-v6-guide-06/:3:0","tags":["VAO","VRO"],"title":"VRO 基础入门（六）-  数据实验室","uri":"/2023/06/vro-v6-guide-06/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 通过之前的配置，我们的 VRO 就可以开始正常使用了，我们可以用 Administrator 或者 Plan Authors 角色的用户登入到 VRO 控制台。在控制台中，可以访问 VRO 定制的仪表盘，包括灾备的执行计划（Plan）、灾备的状态检查（Readiness Check）、灾备测试情况（Datalab Testing）以及灾备的 SLA（RPO 和 RTO 情况）。 在主控制台中，管理员还能查看基础架构清单，根据各个角色定义的内容，分别能够从 Inventory 中查看到自己所管理的机器（Group）以及自己的灾备环境（Recovery Location）。 接下去，我来介绍下 VRO 的最主要的能力和具体的使用方法 - Orchestration Plan。 ","date":"2023-06-01","objectID":"/2023/06/vro-v6-guide-05/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（六） -  成功灾备计划的第一步","uri":"/2023/06/vro-v6-guide-05/"},{"categories":[],"content":"创建 Orchestration Plan 的方法 我们在最开始的简介中有提到过，Orchestration Plan 有五大类，所有自动化的操作过程都将会通过这个 Plan 加入到灾备中去。在这里，我建议首先第一步，尽可能的不要加入太复杂的自动化脚本，而是用系统自带的 Plan Steps，用最少的流程来认识这些 Plan，等到熟悉了系统的工作机制后，再来逐步逐步添加适合的自定义脚本。 操作步骤： 创建 Orchestration Plan，进入左边的 Orchestration Plans，在右边内容显示区域，会看到顶部的一排 4 个按钮，其中在 Manage 按钮所在的下拉菜单中，可以找到 New 的按钮。通过这个按钮可以启动 Orchestration Plan 的创建向导。 打开向导后，首先需要设定 Plan Info，此处的内容一般来说按照实际的情况填写，这些都会在 Report 中被使用到。 在向导的 Scope 步骤中，需要选取使用哪个 Scope 来创建这个 Orchestration Plan，就像基础组件中提到，每个 Scope 中包含了灾备的一系列元素，而 Orchestration Plan 则是把这些元素组合起来，形成一个可执行的计划，Scope 的选择决定了哪些用户可以访问这个 Plan。今天的例子中，我们选择 Admin 这个 Scope。 在向导的 Plan Type 步骤中，就可以选择 5 大分类的其中一种，今天的例子中，我们选择 Restore 进入下一步，其余的一些选项在后面的向导中会略有不同，留给大家自行探索。 在向导的 Recovery Location 步骤中，选择一个 DR 的 Location，我们将会把我们备份的机器恢复至 DR 站点的 ESXi 中。关于 Recovery Location 的设定，可以参考上一期的内容。 在向导的 VM Group 步骤中，当前 Scope 下能看到的所有可用 VM Groups 都会列在 Available Group 中，通过 Add 按钮将需要的 Group 添加至右边的 Plan Groups 窗格中。也可以通过 View VMs 来详细查看当前选定的 VM Groups 中所包含的 VM。 在 VM Recovery Options 步骤中，需要设置四个内容： If any VM recovery fails then：如果 Plan 中有多台 VM 需要恢复，假如其中有一台 VM 恢复失败，此选项决定了后续的 Plan 如何操作，可以继续执行计划恢复其他 VM 或者是直接停止计划。 Recover the VMs in each Group: 按顺序恢复还是同时恢复。如果选择 In parallel 是同时进行，如果是选择 In Sequence 则是按顺序执行。 Recover simultaneously max of VMs：选择合适的数量，默认是 10 个，一般来说，管理员需要根据自己的计算资源情况，合理选择，最好执行一些测试后最后决定这里的数量。 Restore VM Tags：这个复选框下有个⚠️，一般来说恢复至新位置成为一个新 VM 则大多是不会选择这个恢复 Tags，避免和生产的 VM 混起来。 在 VM Steps 步骤中，可以选择很多恢复过程中的可以用到的 Steps，默认情况下，系统自动会选上 Restore VM 和 Check VM Heartbeat 这两个 Step。我建议刚开始熟悉 VRO 的管理员逐项逐项的添加各种 Step，以测试每一种操作的功能，确定了某个需要的 Step 之后，再将其设计到自己的最终 Plan 之中。在这个步骤中，管理员可以加入各种各样的自定义 Powershell 脚本，借助这样的扩展，管理员可以灵活的控制和管理各种各样的系统。 在 Protect VM Groups 步骤中，可以加入自动化的保护恢复出来的灾备资源设置，这步操作对于全自动运行的灾备系统非常重要，确保了对灾备恢复后的下一步保护。今天的例子中，我们暂时保持这个选项默认，不做选择，进入下一步。 在 RPO 和 RTO 步骤中，管理员可以设定期望的 SLA，VRO 系统会全自动的去监控备份系统和灾备系统，确保管理员期望的 RPO 和 RTO。当出现任何不符合预期的状况，VRO 将会通过告警通知提醒管理员进行进一步处理。在个步骤我们也保持默认数值，1 小时的 RTO,24 小时的 RPO。 在 Report Template 中，管理员可以为整个 Plan 的动态文档设定相关的 Template，系统已经内置了多国语言版本的文档 Template，管理员也可以通过 Microsoft Word 来自定义这个 Template，我们将会在后续的介绍中详细说明 Template 的创建和编辑方法。在这个步骤中，我们选择中文的默认模板。 在 Report Scheduling 步骤中，可以设定 Plan Report 的创建时间，也不做修改保持默认。 以上就是所有设定步骤，在 Summary 中查看详细设置后点击 Finish 就能完成创建。创建完成后，这个 Plan 将会出现在 Orchestration Plan 的页面中。 ","date":"2023-06-01","objectID":"/2023/06/vro-v6-guide-05/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（六） -  成功灾备计划的第一步","uri":"/2023/06/vro-v6-guide-05/"},{"categories":[],"content":"管理 Orchestration Plan 对于创建好的 Plan，管理员可以对它做以下操作： Launch ：Run、Halt、Undo 和 Schedule Manage：Enable、Disable、New、Edit、Reset、Delete 和 Properties Verity：Datalab test 和 Readiness check Report 操作 一般来说，新创建的 Orchestration Plan 是处于 Disable 状态，也就是前面的图标是灰色的，需要点击 Manage-\u003eEnable 选项来激活它才能正常工作。 做了恢复或者故障切换操作之后，管理员需要通过 Manage-\u003eReset 按钮来重制这个 Plan 使其能继续工作，或者管理员还可以删除之前已经完成的 Plan，重新定义新的 Plan。 以上就是今天的内容，Orchestration Plan 的基本创建方法，今天的例子中只是简单介绍了 Restore Plan 的方法，剩下的其他四种 Plan 留给大家自己探索。 ","date":"2023-06-01","objectID":"/2023/06/vro-v6-guide-05/:3:0","tags":["VAO","VRO"],"title":"VRO 基础入门（六） -  成功灾备计划的第一步","uri":"/2023/06/vro-v6-guide-05/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 ","date":"2023-05-30","objectID":"/2023/05/vro-v6-guide-04/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（四） -  基本组件 · 下篇","uri":"/2023/05/vro-v6-guide-04/"},{"categories":[],"content":"资源分组 - Compute Resource/Storage Resource/VM Group 在详细介绍 Scope 的那些操作权限之前，今天我想先来说说资源的分组方法，因为这些特殊的分组方法将会在后面的这些操作权限中用到。这个分组方法分别对 VM、Host 以及 Storage 有效，VRO 中要用到的这些分组都会从内嵌的 VeeamONE 中读取，因此实际上就是在 Veeam ONE 中完成这些分组。大致上这里的具体操作方法可以分为两大类： 第一类可以通过 Veeam ONE Business View 原生的分组方法来进行分组。 第二类可以通过 vSphere Tags 将 ESXi 或者 Cluster、Datastore 进行分组，分组完成后 VRO 就能读取到这些信息。 不管有没有使用 vSphere Tags，我更推荐使用 Veeam ONE Business View 上的 Categorization 来完成资源分组的设定，下面我以 Compute Resources 分组为例来介绍这个分组的方法。 操作方法如下： 通过 Veeam ONE Monitor Client 打开 VRO 内嵌的 Veeam ONE 控制台，找到 Business View 视图中的 Hosts 分类，右键点击，在弹出的右键菜单中找到 Add Category… 菜单。 在弹出的 Add Category 向导的第一步 Name and Object type，填入分类的名称，比如我在这里填了 DR Compute，Type 保持 Host 不变，点击下一步。 在向导第二步 Categorization Method 中，选择第二项 Multiple conditions，点击下一步。（当然这一步也可以选择其他，今天的这个例子中，我就不详细展开介绍这些分类方法了）。 在向导第三步 Grouping Criteria 中，点击右边的 Add… 来添加新的分组，这一步非常非常重要，在这里添加的分组将会出现在 VRO 的 Recovery Location 设定向导的 Compute Resources 中。 点击 Add 后，会出现一个新的向导来添加分组。先为这个分组起个名称。比如我这里设置了“Compute Resource Group 1”，点击下一步。 在分组向导的第二步 Grouping Conditions 中会有一个默认的 Condition 出现，我们需要选中它，然后点击右边的 Remove 按钮，我们今天的例子中，会通过手工选取的方式来分组。删除这个 Condition 后，点击下一步。 在分组向导的第三步 Notification 中，保持默认选项，不做任何更改，这里的 Notification 设定在 VRO 中用不到，不需要设置。点击 Save 完成就行了。 回到 Add Category 向导的第三步 Grouping Criteria 步骤中，重复以上 4-7 步来添加多个分组，或者使用 Clone 按钮来进行分组克隆，克隆后修改名称即可。最后点击 Save 保存分类设定。 在完成分类设定后，在 Business View 的 Hosts 下面，会看到刚刚设定的 Category 和 Group，这时候因为我们会使用手工的方法进行分类，所以在 Group 下面暂时还没出现对应的 Host。我们选中 Business View 里的 Hosts，在右边的内容显示区中，找到并切换到标签卡 Hosts。 在 Hosts 列表中，找到要分组的主机，右键点击主机，在右键菜单中选择 Manual Categorization。 在弹出的 Edit Categorization 对话框中，在左边选择 Not Mapped 分类，然后在右边选择 Group 名字，点击 Ok。这样分组就完成了，可以在 VRO 中使用了。 对于 VM Group 和 Storage Resources 的设定，一样可以通过上面的方法完成。 ","date":"2023-05-30","objectID":"/2023/05/vro-v6-guide-04/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（四） -  基本组件 · 下篇","uri":"/2023/05/vro-v6-guide-04/"},{"categories":[],"content":"Scope Inclusions 接下来说说 Scope Inclusions，也就是 VRO 灾备系统的权限管理中，有哪些具体的操作可以做。在之前的版本中，这个模块叫做 Plan Components，v6 改名成了 Scope Inclusions，其实内容基本相同。 以下这些组件，需要针对每个 Scope 进行设置，上一篇中已经介绍了具体设置位置，接下来我们来看看这些对象都有些什么以及他们的设置方法。 ","date":"2023-05-30","objectID":"/2023/05/vro-v6-guide-04/:3:0","tags":["VAO","VRO"],"title":"VRO 基础入门（四） -  基本组件 · 下篇","uri":"/2023/05/vro-v6-guide-04/"},{"categories":[],"content":"Groups Groups 定义了在每个 Scope 下面，能管理哪些机器。但是和 VBR 中选机器不一样的是，在 Groups 中虚拟机或者物理机并不是以它原有的结构和名称来呈现，在 VRO 的 Groups 中自动列出了以下几类对象： Veeam 备份作业保护的虚拟机或者物理机 - 这类以 [作业名称 - VBR 主机名] 这个方式出现在清单中。 Veeam Replication 或者 CDP 保护的虚拟机 - 这类以 [作业名称 - VBR 主机名] 这个方式出现在清单中。 vSphere Datastore 所包含的虚拟机 - 这类以 [Datastore] 方式出现在清单中。 Veeam agent 保护组 - 这类以 [保护组名称 - VBR 主机名] 这个方式出现在清单中。 vCenter Server 标签 - 这类以 [类别名 - 标签名] 这个方式出现在清单中。 除了自动分类之外，管理员还能够通过内嵌的 Veeam ONE 的 Business View 进行手工分类，这时候分类就更加灵活了，甚至是配置上复杂的正则表达式来实现复杂的筛选和分组。 这些分类里，Agent 作业和 Agent 保护组中都会出现 Agent 的对应的 Windows 或者 Linux 机器，会有重复的机器出现；而虚拟机部分备份作业、Datastore 或者 vCenter 标签也会有重复的虚拟机出现。实际在设定 Orchestration Plan 时，不同类型的分类可以混合在一个 Plan 中，重复的机器不会被计算两次，Orchestration Plan 能够自动从 Repository 中提取合适的 Restore Point 或者 Replica 进行还原。 这样的对象选择方式，虽然有点烧脑，但是却能够给管理员提供极大的分组自由度，选择非常多。 ","date":"2023-05-30","objectID":"/2023/05/vro-v6-guide-04/:3:1","tags":["VAO","VRO"],"title":"VRO 基础入门（四） -  基本组件 · 下篇","uri":"/2023/05/vro-v6-guide-04/"},{"categories":[],"content":"Recovery Locations Recovery Locations 是我们的 Orchestration Plan 恢复时所要使用的物理计算资源，它包括了 Compute、Storage、Network 三大核心资源。转换成 vSphere 上，分别有如下的对应关系： VRO Recovery Locations 名称 vSphere 资源 Compute ESXi、Cluster Storage Datastore Network 虚拟交换机上的端口组名称 在 VRO 中，我们并不能直接选择某个 ESXi、Datastore 作为我们的 Recovery Location，只能通过 VRO 内嵌的 Veeam ONE 中的 Business View 引擎来获取的，这也就是本篇开头部分介绍的资源分组方法。我们首先要通过本篇开头的资源分组方法，将 Compute Resource 和 Storage Resource 按照一定规则进行分组，在这些分组设置完成后，才可以创建 Recovery Location 了。Recovery Locations 的设置需要进入 Administration 界面，找到右边的 Configuration 分类。 进入 Recovery Location 界面后，会看到 VRO 已经内置了一个默认的 Recovery Location，名字叫“Original VM Location”，这是还原到虚拟机的原始所在位置，对于这个默认的 Recovery Location，我们只能对他做编辑操作，并不能删除它，而编辑操作可调整的内容也非常少。 我们可以新建新的 Recovery Location 用于还原到一个新的位置。我们可以在这里创建多个 Recovery Location。通过 Add 按钮，我们可以打开添加向导： 这里的 Recovery Location 有三种类型，分别是 Storage、Restore 和 Cloud。我的这个例子里，我们就选择 Restore 这个场景，Storage 和 Cloud 这两个场景有兴趣的朋友可以看看官网手册详细了解。 在 Recovery Location Name 步骤中，填入合适的名称，点击下一步。 在 Recovery Option 步骤中，默认选中了可以用于 Agent 和 vSphere 的恢复，保持不变，点击下一步。 在 Compute Resources 步骤中，选择从 Veeam ONE 中读取过来的 Compute Resource 的分组，点击 Add。这里可以多选添加多个，并且可以通过 View Resource 按钮查看添加的集群或者主机。添加完成后点击下一步。 在 Storage Resources 步骤中，同样，选择合适 Storage 分组。添加完成后点击下一步。 在 Storage Options 步骤中，可以设定 vSphere Storage 使用的上限，确保不会耗尽 vSphere 的存储。同时在这个步骤中还能设置是否使用 DR site 的 backup copy 作为还原的数据源，如果是从 DR site 进行恢复，这个选项必选。 在 Agent Network 步骤中，可以为 Agent 恢复的机器选择网络的 Mapping 规则，从源网络对应至 vSphere 中合适的端口组，比如我在源网络中设置了所有来自 10.10.1.0/24 的机器，对应到 VLAN1 的端口组。 在 VM Network 步骤中，和上一步的设置一样，只是适用于虚拟化的环境，源端的选择是源端 vCenter 上的端口组。 在 Re-IP 步骤中可以为 Windows 机器设置修改 IP 的规则，这一步我的这个例子中就不添加了，恢复后不修改 IP 地址。 在 Data Sovereignty 步骤是设定恢复数据恢复的物理位置的，通过 VBR 的 Location 功能来实现数据恢复的合规性。这里也不勾选，保持默认。 最后 Summary 看下设置是否正确，就完成了 Recovery Location 的创建。 在 Configuration 下面创建完 Recovery Locations 之后，我们需要在 Scope Inclusions 中，为某个 Scope 选择所能用的 Recovery Locations，和 Groups 一样，切换到 Recovery Locations 标签卡后，勾选需要的 Recovery Locations 之后，点击 Include 即可。 ","date":"2023-05-30","objectID":"/2023/05/vro-v6-guide-04/:3:2","tags":["VAO","VRO"],"title":"VRO 基础入门（四） -  基本组件 · 下篇","uri":"/2023/05/vro-v6-guide-04/"},{"categories":[],"content":"Plan Steps Plan Steps 是所有我们在 Orchestration Plan 中可以用的操作，Veeam 系统内置了绝大多数恢复或者验证系统时要用的步骤。当然我们也可以额外再添加一些新的自定义脚本。添加新的自定义脚本需要通过管理员账号进入 Administration，找到 Configuration 下面的 Plan Steps，在这里进行新的 Step 的定义。关于自定义 Step，涉及到更多的脚本方面的内容，我计划在后面的详细 DR 实例中再进行详细介绍，这里就不展开了。 定义完成之后，还是需要回到 Scope Inclusions 中，为某个 Scope 选择所能使用的 Plan Step，在 Plan Steps 标签卡下，勾选需要的 Step 后，点击 Include，确保已经包含即可。 ","date":"2023-05-30","objectID":"/2023/05/vro-v6-guide-04/:4:0","tags":["VAO","VRO"],"title":"VRO 基础入门（四） -  基本组件 · 下篇","uri":"/2023/05/vro-v6-guide-04/"},{"categories":[],"content":"Credentials Credentials 是我们在灾备中需要用到的用户名密码，用于执行一些操作系统内的自动化脚本，这里 VRO 会从 VBR 中将所有已经设置的用户名密码继承过来，稍微有些不同的是，对于用户名密码，我们可以在这个标签卡下点击 Add 来新增。我们在这个标签卡下需要做的事情也很简单，只需将需要使用到的用户名密码在这里勾选点击 Include 即可。目前来说，这里的 Credentials 仅限 Windows 类型的用户名密码，但是这些 Simple 类型的用户名密码有时候也能作为参数传递给 Linux Server 用户用户名密码的验证，而更安全的 key pair 方式的登录认证暂时在这个密码箱里不受支持。 ","date":"2023-05-30","objectID":"/2023/05/vro-v6-guide-04/:5:0","tags":["VAO","VRO"],"title":"VRO 基础入门（四） -  基本组件 · 下篇","uri":"/2023/05/vro-v6-guide-04/"},{"categories":[],"content":"Template Jobs VRO 在做完灾备切换和灾备恢复后，能第一时间即刻对新恢复出来的系统进行数据保护，确保第一时间系统时处于被保护的状态，这一功能需要 VRO 有一个 VBR 备份作业的模板作为参考。在每一个 Scope 中，都可以设定需要使用的 Template Job。这个 Template Job 并不是在 VRO 中设定的，它是直接从 VBR 中进行获取，获取的规则也很简单，只要 VBR 的 Backup Job 中作业的 Description 中写入了* [VDRO Template] *字样就能被 VRO 正确获取。 以上就是 VRO 所有的基础组件，谢谢阅读并关注。 ","date":"2023-05-30","objectID":"/2023/05/vro-v6-guide-04/:6:0","tags":["VAO","VRO"],"title":"VRO 基础入门（四） -  基本组件 · 下篇","uri":"/2023/05/vro-v6-guide-04/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 作为一套灾备管理系统，权限管理是至关重要的，因此，我想先来说说 VRO 中的角色权限管理。在 VRO 中的角色权限管理并不叫 RBAC，VRO 通过 Scope 来控制所有用户的访问权限，Scope 控制了用户在 VRO 中能访问哪些备份和灾备资源以及能对这些资源进行什么样的操作。 ","date":"2023-05-26","objectID":"/2023/05/vro-v6-guide-03/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（三） -  基本组件 · 上篇","uri":"/2023/05/vro-v6-guide-03/"},{"categories":[],"content":"Scope 的操作权限 先来说说 Scope 的操作权限，和其他系统 RBAC 的权限分类设定类似，在 VRO 中，这些权限分类我们叫做 Scope Inclusions，包含以下五类： Groups Recovery Locations Plan Steps Credentials Template Jobs 对于拥有这五类 Scope Inclusions 中某一个资源的操作权限的 Scope 来说，该 Scope 就能使用这个对象。这里这五大类的对象都可以同时属于不同的 Scope。 另外，Scope 中还有个非常特殊的对象 – Datalab，每一个 Datalab 都和一个 Scope 一一对应，也就是说，每个 Scope 都有一个或多个独立的属于自己的 DataLab。 关于 Scope Inclusions 将在 VRO 基础入门（四）- 基本组件 · 下篇 中详细介绍。 ","date":"2023-05-26","objectID":"/2023/05/vro-v6-guide-03/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（三） -  基本组件 · 上篇","uri":"/2023/05/vro-v6-guide-03/"},{"categories":[],"content":"Scope 的创建和用户分配 每个 Scope 可以分配 3 类不同的角色类型，分别是： Administrators - 可以做所有操作 Plan Authors - 可以启用、禁用、重置、创建、编辑和测试灾备计划 Plan Operators - 只能处理一些启用状态的灾备计划 VRO 中内置了一个 Admin Scope，默认情况下，在这个 Scope 中的 Administrator 权限最大，能做所有的操作。使用者可以通过新建 Scope 来为不同的用户限定不同的权限，执行不同的操作。 对于用户新建的 Scope，我们可以修改名称，可以删除。而这些 Scope 的 Roles 仅限于 Plan Authors 和 Plan Operators。以 Plan Authors 举例子，在每个 Scope 下的 Plan Authors Role 中，我们可以为这个 Scope 加入不同的用户。如下图所示。 在 VRO 中，这个 Scope 非常难理解，不过没关系，我来打这个比方说明： 我们可以把 Scope 想象成一个一个的房间，每个房间都会有把锁，而这把锁配了多把钥匙，我们现在把这些钥匙分给不同的用户，那么这些用户都能通过 A 钥匙进入房间（Scope A），通过 B 钥匙进入房间（Scope B），通过 C 钥匙进入房间（Scope C）。这样，就形成了 VRO 中特殊的一种权限的管理： 当前有房间（Scope）：A、B、C、D 用户 1：拥有房间 A、B 的钥匙。 用户 2：拥有房间 B、C、D 的钥匙。 用户 3：拥有房间 D 的钥匙。 转换成 VRO 中的 Scope 管理： 房间（Scope A）：用户 1 房间（Scope B）：用户 1、用户 2 房间（Scope C）：用户 2 房间（Scope D）：用户 2、用户 3 而分钥匙的方法，就是在 VRO 中设置User and Scopes，在 VRO 中，通过拥有 Administrator Role 的 User 登录后，可以至Administration界面下面，找到Permission-\u003eUsers and Scope来设定以上的管理权限，如下图： 按照这样设定完成后，我们用 test01 再次登入 VRO 的系统后，我们可以看到 Dashborad 上显示的当前用户的 Scope 如下图所示： 类似的，test02 这个用户登入系统后，将会看到房间 B、C、D，而 test03 登入系统后，将只会看到房间 D。 配置 Scope Inclusions 进入Administration界面，在Permissions下，可以找到Scope Inclusions，在这个界面上，可以为每个Scope设定不同的可用组件。如下图，可以在红框位置选择 Scope 来切换并且设定。 这里面大家可以注意到这是一个复选框，也就是说，可以同时选择多个 Scope 进行相关设定，但是为了更准确的设置相关内容，我还是建议大家逐个勾选设定会比较好。 ","date":"2023-05-26","objectID":"/2023/05/vro-v6-guide-03/:3:0","tags":["VAO","VRO"],"title":"VRO 基础入门（三） -  基本组件 · 上篇","uri":"/2023/05/vro-v6-guide-03/"},{"categories":[],"content":"Datalabs VRO 的 Datalab 其实就是 VBR 中的 Virtual Lab，只要在 VBR 中配置了 Virtual Lab 后，VRO 就能直接识别到。在识别到这些 Virtual Labs 之后，VRO 需要做一个分配的动作，将这些 Virtual Lab 按照实际使用的需求分配给不同的 Scope。特别注意，每一个 Virtual Lab 只能分配给一个指定的 Scope。 要分配 Datalab，可以使用 Administrator 账号进入Administration界面，找到Permission下面的Datalab Configuration，在这个页面下，勾选中间 VRO 扫描到的 Virtual Lab 名称，然后点击 Edit 按钮。 当点击了 Edit 按钮后会打开 Edit DataLab Configuration 的对话框，在这里选择需要分配给哪个 Scope 即可。如下图所示： 如果需要调整或者重新分配 Datalab，可以勾选 Virtual Lab 名称，然后同样点击 Edit 按钮回到前面的向导界面，就能通过 Clear 按钮取消关联。 Lab Groups 我相信熟悉 DataLabs 的同学一定会好奇，我们 VBR 上的 Datalabs 的功能包含三个核心组件：Virtual Lab、Application Group 和 Surebackup Job。那么在 VRO 中我们将 DataLab 和 VBR 的 Virtual Lab 做了一一的对应，剩下的 Application Group 和 Surebackup Job 去哪里了？ 在 VRO 中，也有一个和 VBR 中的 Application Group 一一对应的组件，那就是 Lab Groups。在 Administration 控制台中并没有这个 Lab Groups 的设定，这个 Lab Groups 需要使用每个用户的账号登入自己的 VRO 控制台中，用各自的账号进入 DataLabs 主页面进行设置。和 Virtual Lab 不同的是，Lab Groups 并不是从 VBR 的 Application Group 中继承，在 VRO 中，这个 Lab Group 是全新创建的，需要用 VRO 中的对象来创建。 一般来说，Lab Group 可以保持空的状态，这和我们之前在 Application Group 的说明中提到的完全一致，除非是业务有依赖关系，必须依赖某个系统才能运行，那么此时，我们需要将这个被其他系统依赖的系统放入 Lab Group 之中。 而 Surebackup Job，在 VRO 中就不需要用到了，这个 Job 会自动集成入 Orchestration Plan 之中，这里就不展开讨论，在后面的章节会详细介绍。 以上就是本章节的主要内容，谢谢关注。 ","date":"2023-05-26","objectID":"/2023/05/vro-v6-guide-03/:4:0","tags":["VAO","VRO"],"title":"VRO 基础入门（三） -  基本组件 · 上篇","uri":"/2023/05/vro-v6-guide-03/"},{"categories":[],"content":"系列目录： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 ","date":"2023-05-25","objectID":"/2023/05/vro-v6-guide-02/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（二） -  安装与部署","uri":"/2023/05/vro-v6-guide-02/"},{"categories":[],"content":"VRO 安装包获取 Veeam 官网可以直接下载 VRO 试用版，**Veeam Data Platform — Premium **的安装包就是我今天文章中用到的安装包，直达电梯 在此，可以直接前往下载。 这个安装包是一套完整的 VRO 套件，其中包括 VRO 主程序、内嵌的 VBR 以及内嵌的 VeeamONE，需要注意的是，这个安装包虽然包含了内嵌的 VBR和内嵌的 VeeamONE但是这两个软件都无法被提取出来单独安装，这两个内嵌的软件都是 VRO 工作的必要组件，它们是跟着 VRO 一起工作的。 这两个内嵌的 VBR 和 VeeamONE 和正常的软件没有任何区别，在安装完 VRO 后可以使用 VBR 或者 VeeamONE 控制台的访问方式远程访问使用，目前在这个安装包中包含的 VBR 是 V12 版本，VeeamONE 是 V12 版本。 ","date":"2023-05-25","objectID":"/2023/05/vro-v6-guide-02/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（二） -  安装与部署","uri":"/2023/05/vro-v6-guide-02/"},{"categories":[],"content":"安装前提条件 非常重要的三点提示： 请不要在已经安装了 VBR 或者 VeeamONE 的服务器上安装 VRO 软件包。 请不要在域控制器上安装 VRO 软件包。 请不要在一台已经安装了 PostgreSQL 的服务器上安装 VRO 一般来说，我建议如果是进行 VRO 的安装，都应该准备一台全新的 Windows 服务器来安装 VRO 的安装包。 安装完成后，可以将您原来的 VBR 加入到 VRO 环境中来由 VRO 纳管，也可以使用 VRO 内嵌的 VBR 来进行常规的备份和复制任务。 其他更多的安装前提条件，请参考官网的 前提条件说明。 ","date":"2023-05-25","objectID":"/2023/05/vro-v6-guide-02/:3:0","tags":["VAO","VRO"],"title":"VRO 基础入门（二） -  安装与部署","uri":"/2023/05/vro-v6-guide-02/"},{"categories":[],"content":"安装方法 安装包是个 ISO 文件，通过挂载 ISO 的方式打开这个镜像后自动运行，可以找到 VRO 的安装按钮： 整个安装过程非常简单，和 Veeam 其他产品的安装一样，跟着向导无脑点完下一步就能做完最基础的安装。 需要注意的是，在安装过程中会要求输入用户名密码，此处的用户名密码为 VRO、VBR、VeeamONE 的服务和它们的数据库需要使用的用户名密码，因此此密码要求的最小权限为这台 VRO Server 的 Windows 本地管理员权限，隶属于本地 Administrators 组即可。 这个账号虽然和后续灾备所使用的灾备管理员的账号没有任何关系，但是在后续的初始化配置的第一步需要输入此账号来登入 VRO 的 UI 界面。 整个安装过程根据不同的硬件能力会大约持续 20-30 分钟，安装完成后这台服务器上就可以使用 VRO 了。由于 VRO 都是基于浏览器的访问，因此我一般会推荐我们从其他电脑的桌面端，通过 Chrome 或者 Edge 浏览器来打开 VRO 的控制台。 ","date":"2023-05-25","objectID":"/2023/05/vro-v6-guide-02/:4:0","tags":["VAO","VRO"],"title":"VRO 基础入门（二） -  安装与部署","uri":"/2023/05/vro-v6-guide-02/"},{"categories":[],"content":"初始化配置 安装结束后，请先不要去打开内置的 VBR 和 VeeamONE 的控制台，而是打开浏览器进入 VRO 的控制台开始初始化配置，系统只有在初始化配置完成后才能够正常工作，进入初始化配置的界面请访问：https://VROIP:9898/ 这时候浏览器会提示输入凭据，请使用上图安装时所用到的凭据作为初始化登入使用的凭据。特别注意，这个凭据只在初始化配置时使用 1 次，在初始化配置完成后，将会使用初始化配置步骤 3 中设定的 VRO 灾备管理员的凭据。 登入账号后，系统进入初始化向导，在 Welcome 页面中描述了这个基础配置向导的一些任务，点击 Next 进入下一步服务器配置。 在服务器配置步骤中，有两个重要内容要选择，一个是选择灾备管理员，通过图中“Choose users and groups”按钮打开添加向导，在右边配置用户属于哪个域（Domain），选择 Account Type 是 User 还是 group，最后从 Account 列表中选取合适的账号点击 Add 即可完成用户配置。这里配置的账号将会用户此次初始化配置之后的 VRO 使用和访问。 在 Server Details 中，可以为 VRO 服务器配置一些基础信息，这些信息会在报表中被使用到。 在基础架构配置步骤中，可以添加用于连接基础架构系统的凭据（Add Credentials）、部署 Orchestrator Agent（其实这个步骤就是添加 VBR）、连接 vCenter 以及连接存储系统。在这个步骤中添加的 vCenter 和存储系统的配置会被自动同步至内嵌的 VBR 和 VeeamONE 中，因此内嵌的 VBR 和 VeeamONE 组件中不需要做任何额外的配置。当然，这些步骤都是可选步骤，我们可以在这个向导里完成最初始的设定，也可以在后期从 VRO 的 Configuration 中再进行调整和配置。 配置完以上步骤后，点击 Finish 就能完成所有的初始化配置。在点击完 Finish 后，网页将会重新刷新回到最开始的 VRO UI 登入界面，使用上面第二步中设定的账号密码就能登入 VRO 正式的 UI 界面了。 欢迎各位来到 VRO！接下去就可以正式开始使用 VRO 了。在下一篇中，我会详细介绍 VRO 的各个组件。 ","date":"2023-05-25","objectID":"/2023/05/vro-v6-guide-02/:5:0","tags":["VAO","VRO"],"title":"VRO 基础入门（二） -  安装与部署","uri":"/2023/05/vro-v6-guide-02/"},{"categories":[],"content":"Veeam Data Platform v12 发布后，产品版本做了重新的组合，其中在最高的白金版中包含了 Veeam Recovery Orchestrator （VRO）组件，这个组件是从以前的 Veeam Availability Orchestrator 升级而来，目前的版本是 v6 版本，配合 VBR v12 和 Veeam ONE v12 一起使用。v6 的版本相比之前 v2 的版本有了全面的更新，功能也更加强大，因此我对我的这个基础入门系列文章进行了一轮更新。 ","date":"2023-05-24","objectID":"/2023/05/vro-v6-guide-01/:0:0","tags":["VAO","VRO"],"title":"VRO 基础入门（一） -  简介","uri":"/2023/05/vro-v6-guide-01/"},{"categories":[],"content":"什么是 VRO？ 作为 Veeam 数据管理平台的最高配组件，它全面加强了 Veeam Backup \u0026Replication 在恢复时的能力。在 v6 中能够支持非常丰富的备份和灾备数据，主要包括： VBR 备份的 vSphere 虚拟机 Veeam Agent 备份的各种 Windows 和 Linux 虚拟机 VBR 复制的 vSphere Replica 存档 Veeam CDP 复制的 vSphere VM 存档 通过 NetApp 和 HPE 存储设备复制的存储卷（仅限存储用于 vSphere 环境） 在 v6 中，这些数据支持非常丰富的恢复场景和功能，主要包括 能够通过软件的设置，来保证企业实施的灾备基础架构的满足所要求的 RPO 和 RTO； 能够尽可能自动化的完成灾备的切换过程，该操作同时支持备份存档、复制存档和 CDP 存档； 能够通过数据实验室，来确保灾备的精准可靠，所有灾备演练将在数据实验室中 1:1 的完整演练。 而对于恢复目的地的选择，VRO 也将范围从单一的 vSphere 扩充到了 Azure 云，支持了 Direct to Azure 的恢复。 VRO 替代了 VBR 中 Recovery、Failover 以及 Surebackup 的操作，可以说是对于这 3 个关键操作的进一步加强，在这些关键操作中，可以加入各种自定义的步骤和脚本，使之能够更加接近实际业务场景中的使用。对于管理员来说，合理的设计这 3 个操作中的额外步骤能极大程度的降低 IT 运维中灾备流程的复杂度。 ","date":"2023-05-24","objectID":"/2023/05/vro-v6-guide-01/:1:0","tags":["VAO","VRO"],"title":"VRO 基础入门（一） -  简介","uri":"/2023/05/vro-v6-guide-01/"},{"categories":[],"content":"VRO 支持哪些场景使用？ VRO 支持的数据中心从简单到复杂，都可以使用，以下仅简单从最基本的架构举两个例子： ","date":"2023-05-24","objectID":"/2023/05/vro-v6-guide-01/:2:0","tags":["VAO","VRO"],"title":"VRO 基础入门（一） -  简介","uri":"/2023/05/vro-v6-guide-01/"},{"categories":[],"content":"单个数据中心 单个数据中心内，加入 VRO 的组件后，和原有备份的架构几乎没有太大差别，所有 VBR 上的操作不会有任何改变，常规的所有备份恢复操作都在 VBR 上可以完成，而 VRO 则在这里开始担当关键业务的 RPO 和 RTO 的确保任务。通常来说关键业务出现宕机后，都会在原始位置实现恢复，因此也没有特别的专用资源用于恢复准备。 因此，在这种场景下，唯一需要改变的是选择一些关键的 VM，由 VRO 来接管这些 VM 的 RPO 和 RTO。 ","date":"2023-05-24","objectID":"/2023/05/vro-v6-guide-01/:2:1","tags":["VAO","VRO"],"title":"VRO 基础入门（一） -  简介","uri":"/2023/05/vro-v6-guide-01/"},{"categories":[],"content":"一主一备数据中心 稍微复杂点，也是很典型的场景，就是跨区域的主备数据中心，主中心承担生成业务，而备中心承担灾备业务。我们通常备份的设计会将备份存档拷贝到灾备中心进行存放，也可能会将一些关键的 VM 直接 1:1 的复制到灾备中心。而这时候，在灾备中心的数据恢复流程都将可以被编制到 VRO 的 Replica Plan 或 Restore Plan 中，同时这些 Plan 也将会被在相应的 Datalabs 中做完整的恢复演练。 这种场景下，原先备份的架构也没有太大变化，和单数据中心非常相似，只是我们可以规划一部分资源专用于灾备恢复。 ","date":"2023-05-24","objectID":"/2023/05/vro-v6-guide-01/:2:2","tags":["VAO","VRO"],"title":"VRO 基础入门（一） -  简介","uri":"/2023/05/vro-v6-guide-01/"},{"categories":[],"content":"VRO 支持的五种 Plan VRO 本身并不提供备份和复制功能，所有对于源数据的处理功能，都会在 VBR 中完成。VRO 中目前提供了五种 Plan： Replica Plan - 通过 VBR 复制功能创建的的副本恢复计划 CDP Replica Plan - 通过 VBR CDP 复制功能创建的副本恢复计划 Restore Plan - 通过 VBR vSphere 备份和通过 Veeam Agent 备份创建的备份存档，恢复至 vSphere 恢复计划 Storage Plan - 通过 NetApp 和 HPE 存储卷复制创建的 VMware Datastore 恢复计划 Cloud Plan - 通过 VBR vSphere 备份和通过 Veeam Agent 备份创建的备份存档，恢复至 Azure 恢复计划 这些 Plan 支持的操作： 资源可用性测试 完整报告自动生成 一键式全自动恢复、故障切换 另外，作为 Veeam 产品看家本领，DataLabs 功能在 VRO 中也是极大增强，在 VRO 中不仅能将 DataLabs 用于 Replica Plan 和 Restore Plan 的测试，还能利用 VRO 中强大的脚本和步骤添加功能，自动化的生成各种复杂的用于测试的环境。通过这种增强，复杂的测试用例，复杂的环境部署工作将会被简化成一键式的按钮，极大提升 DataLabs 的使用效率。 ","date":"2023-05-24","objectID":"/2023/05/vro-v6-guide-01/:3:0","tags":["VAO","VRO"],"title":"VRO 基础入门（一） -  简介","uri":"/2023/05/vro-v6-guide-01/"},{"categories":[],"content":"VRO 可以用来做什么？ 简单来说，我总结了下，有以下主要能力： 全自动恢复到 Azure 云和 VMware 虚拟化 “零污染”还原 - 通过智能检测引擎在还原前扫描病毒，确保还原的数据没有被污染 全自动灾备和恢复测试 即时可用的数据实验室创建 全面的应用可用性验证 一键式灾备恢复 全自动动态灾备文档 以上就是 VRO 的简单介绍，欢迎关注 VRO 基础入门系列，在最近一段时间我会陆续更新以下内容： VRO 基础入门（一）- 简介 VRO 基础入门（二）- 安装与部署 VRO 基础入门（三）- 基本组件 · 上篇 VRO 基础入门（四）- 基本组件 · 下篇 VRO 基础入门（五）- 成功灾备计划的第一步 VRO 基础入门（六）- 数据实验室 VRO 基础入门（七）- Plan Step · 上篇 VRO 基础入门（八）- Plan Step · 下篇 VRO 基础入门（九）- 文档模板解析 VRO 基础入门（十）- 使用 VRO 搭配 K10 实现全自动容器灾备 ","date":"2023-05-24","objectID":"/2023/05/vro-v6-guide-01/:4:0","tags":["VAO","VRO"],"title":"VRO 基础入门（一） -  简介","uri":"/2023/05/vro-v6-guide-01/"},{"categories":[],"content":"在 VBR v10 的时候，产品中加入了一些隐藏功能，最近 v12 发布后，隐藏按键和功能又多了一些。 ","date":"2023-03-28","objectID":"/2023/03/v12update-hidden-key/:0:0","tags":["VBR"],"title":"VBR v12 中的那些隐藏键","uri":"/2023/03/v12update-hidden-key/"},{"categories":[],"content":"[Ctrl]+鼠标右键 Repair 修复 VACM 文件 我们知道，v12 更新后几乎所有的数据都能够安全地储存在 Veeam Hardened Repository(VHR) 中，但是对于 Oracle RMAN、SAP Hana 和新推出的 SQL Plugins，他们的 Backup job metadata (VACM) 是无法实现 WORM 功能的。这时候会出现一种情况就是黑客恶意删除了 VACM 文件，造成 VACM 文件丢失。 在 Enterprise Plugin 备份存档中，按住 Ctrl 后点击鼠标右键，可以调出两个新菜单，其中一个是 Repair 按钮，这个按钮可以用于修复备份作业的 metadata 文件。 Remove from configuration 在使用 Veeam Hardened Repository(VHR) 后，数据存放在这些存储库中非常安全，黑客如果攻破了 VBR 也无法通过 Delete from disk 按钮从备份服务器上删除备份存档。但是，在 v11 的 VBR 中，除了有个 Delete from disk 按钮之外，我们还有个 Remove from configuration 按钮，这个按钮并不删除 VHR 里的数据，而是用于删除 VBR 后台数据库中的记录。当我们按下这个按钮后，备份记录就从 VBR 控制台消失，虽然这对备份运维来说是一个非常重要的功能，但这在某种程度上也给黑客入侵提供了一些便利。 在 v12 中，Remove from configuration 按钮被隐藏起来了，这样可以避免一些不必要的误操作，如果真需要使用这个功能，一样可以通过 Ctrl+右键调出这个功能。 Rebalance 重新平衡 SOBR 容量 SOBR 使用时间久了，特别是不同容量混用存放大量虚拟机的时候，很容易碰到几个 Extent 之间容量不平衡，在 v12 中，新增了 Rebalance 按钮可以用来平均分配备份存档至各个 Extent 中。这个按钮也是通过 Ctrl+右键调出来。 ","date":"2023-03-28","objectID":"/2023/03/v12update-hidden-key/:0:1","tags":["VBR"],"title":"VBR v12 中的那些隐藏键","uri":"/2023/03/v12update-hidden-key/"},{"categories":[],"content":"新增隐藏的鼠标右键 由于全新的 Per-vm backup chain 的能力，在备份作业历史记录中，每一个机器都新增了全新的右键按钮。这个按钮包含两种功能，一个是 Active full 全备份，另外一个是 Retry。在以前的版本中，这两个功能都仅针对整个备份作业有效，也就是说，当我有个作业中有 4 个虚拟机/物理机时，我如果需要进行一次全新的 Active Full 操作，那么这 4 个机器将会都被同时执行 Active Full，无法为单台机器进行单独操作；而 v12 中，每一台机器都可以单独进行操作了。 ","date":"2023-03-28","objectID":"/2023/03/v12update-hidden-key/:0:2","tags":["VBR"],"title":"VBR v12 中的那些隐藏键","uri":"/2023/03/v12update-hidden-key/"},{"categories":[],"content":"隐藏的时间戳 这个功能其实我是用来凑数的，并不是 v12 新增的。在备份作业历史记录中，右键点击 Action 附近，可以调出一列新的内容，这是每一个备份步骤的开始时间，这个功能对于排查错误非常有用，特别是在分析排查一些性能问题的时候特别有帮助。 好了，以上就是本期隐藏按钮更新。欢迎下载 v12 探索新功能，有啥新发现也可以留言告诉我。 ","date":"2023-03-28","objectID":"/2023/03/v12update-hidden-key/:0:3","tags":["VBR"],"title":"VBR v12 中的那些隐藏键","uri":"/2023/03/v12update-hidden-key/"},{"categories":[],"content":"学习了一段时间 vSphere with Tanzu，发现功能非常强大，但是搭建这个学习环境成本略高。经过一些资料搜索和亲自试验，摸索出一些门道，记录在此篇博客中，方便那些希望学习 vSphere with Tanzu 的朋友快速搭建实验环境。 先放出本文涉及到的脚本的 Github 地址： https://github.com/Coku2015/Nested-TKGs-automate-deployment 本文的脚本改编自 William Lam 的博客，原版的脚本适用于自动化部署 VMware 完整的 Tanzu Kubernetes 产品，适应的场景会比较丰富，有强大脚本能力的小伙伴可以参考大神的脚本进行按需改编。 本文分为上下两部分，其中第一部分为虚拟化基础架构搭建，第二部分为 Tanzu Kubernetes Cluster 创建。对于环境准备条件，将在本文开头一次性给出。 ","date":"2022-07-03","objectID":"/2022/07/nested-tkgs-lab-automation-script/:0:0","tags":["VMware","Tanzu"],"title":"虚拟化嵌套 TKGs 实验环境自动化脚本","uri":"/2022/07/nested-tkgs-lab-automation-script/"},{"categories":[],"content":"0. 条件准备 本文中环境为 vSphere 虚拟化嵌套环境，所有 VM 将会被部署至 vSphere vCenter 管理的物理 ESXi 服务器上，因此在宿主机上建议预留以下资源用于部署： vCPU：9 个 内存：40.5GB 磁盘：1421GB（分配容量） 这套环境部署完成后，将会生成 4 个虚拟机，分别是： Nested ESXi （基本配置）：4vCPU/24GB 内存/1TB 磁盘/3 个网卡 vCenter（基本配置）：2vCPU/12GB 内存/400GB 磁盘 haproxy: 2vCPU/4GB 内存/5GB 磁盘 openwrt router: 1vCPU/0.5G 内存/1GB 磁盘 在嵌套的 ESXi 中，将会部署 Tanzu Kubernetes 环境： 1 台 Supervisor VM：2vCPU/8GB 内存 1 台 K8S Control Plane：2vCPU/4GB 内存 2 台 K8S Worker Node：2vCPU/4GB 内存 部署完成后整个环境的拓扑如下： 在环境准备中，我们一共会需要以下镜像，这些镜像需要提前下载： Nested ESXi 7.0u3c vCenter 7.0u3e haproxy.ova Openwrt router 在本文的第二部分中，系统还会全自动的在 Nested ESXi 中开启一组虚拟机，这些虚拟机属于 vSphere with Tanzu 管理。这需要订阅 VMware 官方的 Content Library，当然也可以手工下载 Content Library 中的内容，创建自己的本地的 Content Library。 在宿主机的环境中，需要准备一个接入 IP，这个接入 IP 将会被这套嵌套环境用于上联口，在我的环境中我使用 SHLAB_NET1 这个端口组来提供这个接入；而环境中的其他网络地址，都将会使用没有上联口的内部通讯地址。 因此，需要在宿主机 ESXi 上创建一个包含 3 个端口组的虚拟交换机，比如我的环境中，如下图所示。这 3 个端口组所在的虚拟交换机还需要打开混杂模式，用于嵌套的 ESXi 的通讯访问。 最后，我们还需要一台 VM 控制台，这台 VM 需要同时能够访问宿主机的 vCenter 和 Tanzu Lab 内部网络，我们将会在这台 VM 上运行本文提到的自动化脚本。 这个脚本全自动部署这套环境时，会用到 VMware vSphere PowerCLI 脚本，这首先需要安装 Powershell 7。 在 Powershell 7 中，执行在线安装命令，就能快速安装最新版的 VMware PowerCLI： PS C:\\\u003e Install-Module VMware.PowerCLI -Scope CurrentUser 关于 PowerCLI 的配置和安装，可以参考： Getting Started with VMware PowerCLI – A Beginner’s Guide 所以最终当我搭建完成这个 Lab 后，环境网络连接如下： ","date":"2022-07-03","objectID":"/2022/07/nested-tkgs-lab-automation-script/:1:0","tags":["VMware","Tanzu"],"title":"虚拟化嵌套 TKGs 实验环境自动化脚本","uri":"/2022/07/nested-tkgs-lab-automation-script/"},{"categories":[],"content":"Part 1. vSphere with Tanzu 基础架构搭建 在准备完以上条件后，我们还需要根据实际环境，将脚本中的一些参数进行设置： # vCenter Server used to deploy vSphere with Tanzu Basic Lab $VIServer = \"172.19.226.20\" $VIUsername = \"administrator@vsphere.local\" $VIPassword = \"P@ssw0rd\" 这段设置用于部署这套环境的物理 ESXi 主机所在的 vCenter。 # Full Path to both the Nested ESXi 7.0 VA, Extracted VCSA 7.0 ISO \u0026 HA Proxy OVAs $NestedESXiApplianceOVA = \"C:\\Temp\\Nested_ESXi7.0u3c_Appliance_Template_v1.ova\" $VCSAInstallerPath = \"E:\\\" $HAProxyOVA = \"C:\\Temp\\haproxy-v0.2.0.ova\" $tkgrouterOVA = \"C:\\Temp\\tkgrouter.ova\" 这段需要配置所有 OVA 镜像的目录，其中 VCSA 需要将 ISO 挂载，并指定挂载后的 ISO 路径。 # TKG Content Library URL $TKGContentLibraryName = \"TKG-Content-Library\" $TKGContentLibraryURL = \"https://wp-content.vmware.com/v2/latest/lib.json\" 这段为新建的 tkg vc 配置 Content Library，用于全自动部署 K8S 虚拟机。 #tkgrouter configuration $tkgrouterdisplayname = \"tkgopenwrt\" $WANNETWORK = \"SHASELAB_NET01\" $WANIP = \"172.19.226.149\" $WANGW = \"172.19.226.1\" $WANDNS1 = \"172.19.226.21\" $WANDNS2 = \"172.19.192.10\" $WANNETMASK = \"255.255.255.0\" $TKGMGMTNETWORK = \"TKG-MGMT\" $TKGMGMTIP = \"10.10.1.1\" $TKGWORKLOADNETWORK = \"TKG-Workload\" $TKGWORKLOADIP = \"10.10.2.1\" $TKGFRONTENDNETWORK = \"TKG-Frontend\" $TKGFRONTENDIP = \"10.10.3.1\" 这段为 Openwrt 路由器配置相关网络。 # Nested ESXi VMs to deploy $NestedESXiHostnameToIPs = @{ \"tkgesxi1\" = \"10.10.1.100\"; } 这段设定 Nested ESXi 主机的主机名和 IP 地址，当需要部署多个 ESXi 的时候，只需要每行加一个即可。 # Nested ESXi VM Resources $NestedESXivCPU = \"4\" $NestedESXivMEM = \"24\" #GB $NestedESXiCapacityvDisk = \"1000\" #GB ESXi 最小的资源配置，可以根据实际需求增加相关资源。 # VCSA Deployment Configuration $VCSADeploymentSize = \"tiny\" $VCSADisplayName = \"tkgsvc\" $VCSAIPAddress = \"10.10.1.101\" $VCSAHostname = \"10.10.1.101\" #Change to IP if you don't have valid DNS $VCSAPrefix = \"24\" $VCSASSODomainName = \"tkg.local\" $VCSASSOPassword = \"P@ssw0rd\" $VCSARootPassword = \"P@ssw0rd\" $VCSASSHEnable = \"true\" VCSA 的配置。 # HA Proxy Configuration $HAProxyDisplayName = \"tkghaproxy\" $HAProxyHostname = \"haproxy.tkg.local\" $HAProxyDNS = \"10.10.1.1\" $HAProxyManagementNetwork = \"TKG-Mgmt\" $HAProxyManagementIPAddress = \"10.10.1.102/24\" # Format is IP Address/CIDR Prefix $HAProxyManagementGateway = \"10.10.1.1\" $HAProxyFrontendNetwork = \"TKG-Frontend\" $HAProxyFrontendIPAddress = \"10.10.3.2/24\" # Format is IP Address/CIDR Prefix $HAProxyFrontendGateway = \"10.10.3.1\" $HAProxyWorkloadNetwork = \"TKG-Workload\" $HAProxyWorkloadIPAddress = \"10.10.2.2/24\" # Format is IP Address/CIDR Prefix $HAProxyWorkloadGateway = \"10.10.2.1\" $HAProxyLoadBalanceIPRange = \"10.10.3.64/26\" # Format is Network CIDR Notation $HAProxyOSPassword = \"P@ssw0rd\" $HAProxyPort = \"5556\" $HAProxyUsername = \"wcp\" $HAProxyPassword = \"P@ssw0rd\" 3 网卡的 HAproxy 的配置，分别对应 3 个网段，其中 10.10.3.x 为 Load Balance 使用。这段的内容非常重要，里面的很多信息，将在 Part 2 中手工填写步骤中用到。 # General Deployment Configuration for Nested ESXi, VCSA \u0026 HA Proxy VM $VMDatacenter = \"SHALABDC\" $VMCluster = \"SHALAB\" $VMNetwork = \"TKG-Mgmt\" $VMDatastore = \"SHASEESX_DS_01\" $VMNetmask = \"255.255.255.0\" $VMGateway = \"10.10.1.1\" $VMDNS = \"172.19.226.21\" $VMNTP = \"172.19.226.21\" $VMPassword = \"P@ssw0rd\" $VMDomain = \"shlab.local\" $VMSyslog = \"10.10.1.1\" $VMFolder = \"Lab Infra\" # Applicable to Nested ESXi only $VMSSH = \"true\" $VMVMFS = \"false\" 通用环境参数设置，需要特别注意的时候，环境中必须能够访问 NTP Server，不管是内部还是外部，否则 vCenter 服务部署将会失败。 # Name of new vSphere Datacenter/Cluster when VCSA is deployed $NewVCDatacenterName = \"tkgs-dc\" $NewVCVSANClusterName = \"tkgs-Cluster\" $NewVCVDSName = \"tkgs-VDS\" $NewVCMgmtPortgroupName = \"tkgs-mgmt\" $NewVCWorkloadPortgroupName = \"tkgs-workload\" 新 vCenter 上网络端口组的设置 # Tanzu Configuration $StoragePolicyName = \"tkgs-demo-storage-policy\" $StoragePolicyTagCategory = \"tkgs-demo-tag-category\" $StoragePolicyTagName = \"tkgs-demo-storage\" Tanzu 存储策略的设置。 在这些脚本参数设定完成后，可以直接在 Powershell 7 中运行这个脚本。脚本启动后，会提示当前即将部署的环境概括，询问是否继续，回答 Y 之后，就开始全自动的部署了。 部署过程根据不同的硬件性能和资源状况大概会历时 30~45 分钟，在我的环境中，整个部署过程历时 40 分钟，整个过程会有一些黄色的 Warning 警告，那些可以忽略，如下图： 安装完成后，可以通过浏览器访问 vCenter web Client，检查安装完成后各组件的情况。 在脚本安装完成后，我们还需要通过 SSH 连接到 haproxy 这台虚拟机中，进行一些调整，调整可以通过脚本完成。 #!/b","date":"2022-07-03","objectID":"/2022/07/nested-tkgs-lab-automation-script/:2:0","tags":["VMware","Tanzu"],"title":"虚拟化嵌套 TKGs 实验环境自动化脚本","uri":"/2022/07/nested-tkgs-lab-automation-script/"},{"categories":[],"content":"Part 2. 启用 Tanzu Kubernetes Cluster ","date":"2022-07-03","objectID":"/2022/07/nested-tkgs-lab-automation-script/:3:0","tags":["VMware","Tanzu"],"title":"虚拟化嵌套 TKGs 实验环境自动化脚本","uri":"/2022/07/nested-tkgs-lab-automation-script/"},{"categories":[],"content":"2.1 启用 Supervisor Cluster 进入 vCenter 后，在主页面导航栏中找到 Worload Management，从这里进去开始 Tanzu Kubernetes 的管理。点击右边的Get Started开始创建 Supervisor Cluster。当然这个过程也完全可以通过 Powershell 脚本方式来完成，这个不在本文中展开讨论，本文通过 GUI 图形化界面来完成 Supervisor Cluster 的创建。 Supervisor Cluster 的创建会进入一个 8 个步骤的向导。 vCenter Server and Network 步骤，这里我们的这个 Lab 没有 NSX，只能选择 VDS。点击 Next 进入下一步。 Cluster 步骤，选择 tkgs-Cluster，点击 Next 进入下一步。 Storage 步骤，选择 Control Plane Storage Policy 为tkgs-demo-storage-policy。点击 Next 进入下一步。 Load Balancer 步骤，这里需要填入 haproxy 的相关信息，Name 中填入 tkghaproxy，Load Balancer Type 修改为 HAproxy，Management IP Address 为 Part 1 中配置信息里$HAProxyManagementIPAddress = \"10.10.1.102/24\"的地址，同时需要补充默认的 HAProxy 的服务端口5556，Username 为wcp，Password 为P@ssw0rd，Virtual IP Ranges 为10.10.3.64-10.10.3.127。 HAProxy Management TLS Certificate 的内容，需要 ssh 至 HAProxy 中找到/etc/haproxy/ca.crt 文件获取。 点击 Next 进入下一步。 Management Network 步骤，Network Mode 选择 Static，Network 选择 TKGs-MGMT，为 Supervisor 配置一个静态 IP。点击 Next 进入下一步。 Workload Network 步骤，选择 Network Mode 为 DHCP，Portgroup 为 tkgs-workload。点击 Next 进入下一步。 Tanzu Kubernetes Grid Service 步骤，选择 Content Library 为 TKG-Content-Library。点击 Next 进入最后一步。 Review and Confirm 步骤，将 Control Plane Size 从 Small 更改为 Tiny，这时候需要注意的是，还需要回到步骤 6 中，重新点下 Next 按钮，使 Internal Network for Kubernetes Services 从 10.96.0.0/23 自动更新为 10.96.0.0/24。 点击 Finish 后，Supervisor Cluster 就开始进入自动部署过程，Workload Management 界面切换成如下图： ","date":"2022-07-03","objectID":"/2022/07/nested-tkgs-lab-automation-script/:3:1","tags":["VMware","Tanzu"],"title":"虚拟化嵌套 TKGs 实验环境自动化脚本","uri":"/2022/07/nested-tkgs-lab-automation-script/"},{"categories":[],"content":"2.2 部署 Tanzu Kubernetes Cluster 等待大约 30 分钟后，就能看到 Tanzu Supervisor Cluster 进入 Running 状态，Control Plane Node 获取到了正确的 ip 地址。 这时候我们可以切换到 Namespace 标签卡下，创建 Namespace 了，需要注意的是，这个 Namespace 并非 Kubernetes 的 Namespace，这是 vSphere Tanzu 的 Namespace，我们的 Tanzu Kubernetes Cluster 将会创建在这个 Namespace 之下。 创建完 Namespace，会看到当前这个 Namespace 的 config Status，为了进行接下去的配置，我们需要在 Namespace 的管理中进行 3 项设置，分别是 Permissions、Storage 和 VM Service 设置。首先是 Permissions，我们通过 Add Permissions 按钮添加一个管理员用户。 通过 Add Storage 按钮，为 Namespace 新增数据存储空间。 通过 Add VM Class 按钮，为 Namespace 添加各种规格的 VM，后续的 Kubernetes 的 Node 都会自动根据选择的规格来配置相应的 CPU 和内存。推荐可以将这里默认的 16 个规格都选择上。 通过 Add Content Library 按钮，将 Tanzu Content Library 再次关联上。 Namespace 全部配置完成后，如下图，这时候就完成了我们 Tanzu Kubernetes Cluster 创建的所有准备工作了。 在上图的 Status 卡片中，最下面一行，有个 Link to CLI Tools，我们需要点击 Open，打开一个新网页，在这个网页上，我们能够下载到 kubectl vsphere plugins，这个命令行 plugins 将帮助我们管理和使用 Tanzu Kubernetes Cluster。 根据网页上的提示，下载安装完成后，我们来到 CLI 控制台上，使用 CLI 登入我们的 Supervisor Cluster。server 地址为中 Control Plane Node 中看到的 IP 地址。此时一切正确的情况下，命令行会提示输入用户名密码，该用户名密码为步骤 2 中设置的管理员用户。登入后，会看到 Logged in successfully 的信息。 c:\\bin\u003ekubectl-vsphere.exe login --server=10.10.3.65 --insecure-skip-tls-verify Username: administrator@tkg.local KUBECTL_VSPHERE_PASSWORD environment variable is not set. Please enter the password below Password: Logged in successfully. You have access to the following contexts: 10.10.3.65 tkgs If the context you wish to use is not in this list, you may need to try logging in again later, or contact your cluster administrator. To change context, use `kubectl config use-context \u003cworkload name\u003e` c:\\bin\u003e 这时，我们已经成功登入了 Supervisor Cluster，接下去我们会使用以下的 yaml 配置文件来创建 Tanzu Kubernetes Cluster。 apiVersion: run.tanzu.vmware.com/v1alpha1 kind: TanzuKubernetesCluster metadata: name: sedemo-tkc-01 namespace: tkgs spec: distribution: version: v1.21 topology: controlPlane: class: best-effort-xsmall count: 1 storageClass: tkgs-demo-storage-policy workers: class: best-effort-small count: 2 storageClass: tkgs-demo-storage-policy settings: storage: classes: [\"tkgs-demo-storage-policy\"] #Named PVC storage classes defaultClass: tkgs-demo-storage-policy 其中，metadata 下的 name 为创建出来的 cluster 的名字，Namespace 则是 vSphere 中我们刚刚创建的 Namespace 名称。 spec 下的内容里，distribution 为需要创建的 Kubernetes 的版本。topology-controlplane-class/topology-workers-class 分别是对应步骤 14 中，我们所设定的 VM class 类型，此处分别选择为 best-effort-xsmall 和 best-effort-small。数量分别是 1 和 2。 运行下面的命令，Tanzu Kubernetes Cluster 会自动在 vCenter 中创建出来： c:\\bin\u003ekubectl apply -f tkc.ymal tanzukubernetescluster.run.tanzu.vmware.com/sedemo-tkc-01 created 等待几分钟后，在 vCenter 中，能够看到被创建出来的 3 台 VM，如图。 再次回到 CLI 控制台，执行如下登录命令，我们可以登入到 Tanzu Kubernetes Guest Cluster 中。 c:\\bin\u003ekubectl vsphere login --server=10.10.3.65 --tanzu-kubernetes-cluster-name sedemo-tkc-01 --tanzu-kubernetes-cluster-namespace tkgs --vsphere-username administrator@tkg.local --insecure-skip-tls-verify KUBECTL_VSPHERE_PASSWORD environment variable is not set. Please enter the password below Password: Logged in successfully. You have access to the following contexts: 10.10.3.65 sedemo-tkc-01 tkgs If the context you wish to use is not in this list, you may need to try logging in again later, or contact your cluster administrator. To change context, use `kubectl config use-context \u003cworkload name\u003e` 至此，我们已经能够正常访问我们的 Kubernetes cluster 了，可以通过所有常规的 kubectl 命令执行所有的管理任务。 ","date":"2022-07-03","objectID":"/2022/07/nested-tkgs-lab-automation-script/:3:2","tags":["VMware","Tanzu"],"title":"虚拟化嵌套 TKGs 实验环境自动化脚本","uri":"/2022/07/nested-tkgs-lab-automation-script/"},{"categories":[],"content":"在 Veeam 推出 v11 版本后，细心的朋友也许注意到了在做即时磁盘恢复时，有下面这个选项： 这是在 6.5 以后的 vSphere 中，VMware 引入了一种全新的磁盘格式，叫”头等舱磁盘（First Class Disks）“。这个名字足够霸气，而实际上，这类虚拟磁盘也确实有着自己独特的”特权“。今天我就来和大家详解下这类 FCD。 ","date":"2022-03-23","objectID":"/2022/03/pvc-and-fcd/:0:0","tags":["VMware"],"title":"头等舱磁盘（First Class Disks）详解","uri":"/2022/03/pvc-and-fcd/"},{"categories":[],"content":"背景 先说说背景，这个 FCD 在早期的 vSphere 中，曾经被叫做是 Improved Virtual Disk（IVD）。所以，FCD 的本质，其实就是个 VMware 的虚拟磁盘：vmdk。我们知道在 vSphere 中，每台虚拟机都会拥有一个或多个虚拟磁盘，这些虚拟磁盘的日常管理都和其对应的虚拟机一一关联。让我们来以物理环境和虚拟环境做一个简单的类比： 一台物理服务器，连接了存储设备上的多个存储卷，假如存储设备有快照功能，这时候存储是可以对单个卷进行快照操作的。 一台 VMware 虚拟机，上面有多个 vmdk，执行快照只能对整个虚拟机进行，无法对单个 vmdk 进行。 FCD 就是在这样的背景下诞生，FCD 的管理完全独立于 VM 的生命周期，vmdk 变成一个单独的存储对象进行管理，它独立于任何的虚拟机。我们可以不需要关心这个磁盘的挂载状态，直接对磁盘完成创建、删除、快照、备份、还原和其他磁盘生命周期管理的操作。 FCD 诞生后，使用的场景非常多，比如 VDI、OpenStack Cinder 等。今天我们来说一个我最近在 Homelab 中一直使用的重要场景，为 Kubernetes 环境提供持久存储的 vSphere Cloud Native Storage(CNS)。 ","date":"2022-03-23","objectID":"/2022/03/pvc-and-fcd/:1:0","tags":["VMware"],"title":"头等舱磁盘（First Class Disks）详解","uri":"/2022/03/pvc-and-fcd/"},{"categories":[],"content":"Kubernetes 使用 vSphere FCD FCD 存放在每个 Datastore 的 fcd 目录下，如图： 每个 FCD 由一个 vmdk 文件和一个 vmfd 文件组成，也就是说，相比普通的 vmdk 多了一个 vmfd 文件。 FCD 在 vSphere Client 上是看不到的，实际上所有 FCD 的日常管理，都是通过 API 进行的。一个比较方便的入口是通过 vSphere Mob 进行管理： https:///vslm/mob//?moid=VStorageObjectManager 在这个 Mob 管理器中，可以对 FCD 进行创建、挂载、克隆、快照管理、删除等一系列操作。 只是这个 Mob 管理器实际上操作也不太够，通过 PowerCLI 可以进行更多的补充，比如通过 PowerCLI 来查询当前 vCenter 中所有注册的 FCD 磁盘。 Get-VDisk 每个 FCD 都有其唯一的标识 UUID 来识别，这个 UUID 存放在 vCenter 的 catalog 中，因此不管是 vSphere Mob 还是 PowerCLI 中，操作这些 FCD 的时候都需要这个 ID。 当这些 FCD 和 Kubernetes 中的 PVC 关联上之后，vSphere Client 中就能够通过每个 Datastore 下的 Monitor-\u003e Cloud Native Storage -\u003e Container Volumes 看到这些 FCD。 其中，Volume Name 对应 Kubernetes 中 PVC Name，而 Volume ID 则是 vSphere 中 FCD 的 UUID。 当 vSphere 为 Kubernetes Worker Node 提供 PVC 存储的时候，实际上这些 FCD 都会被 attach 到每一个 Worker Node 的虚拟机中。比如我这台 Worker Node： 这样就很容易理解，Kubernetes 中的应用是如何往它们的持久化 PVC 中写入数据了。实际上工作的时候，就是这些 Worker Node 虚拟机在往这些 vmdk 中写入数据。 ","date":"2022-03-23","objectID":"/2022/03/pvc-and-fcd/:2:0","tags":["VMware"],"title":"头等舱磁盘（First Class Disks）详解","uri":"/2022/03/pvc-and-fcd/"},{"categories":[],"content":"K10 的备份 当 K10 使用 vSphere Integration 进行 Kubernetes 上应用的备份时，K10 不再需要 VolumeSnapshot CRD 来完成 PVC 卷的快照，此时替代的方法是 vSphere FCD Snapshot。本文开篇我们提到过，FCD 的生命周期管理是完全独立于虚拟机的，这时候当我们发起备份任务的时候，K10 不需要对整个 Worker Node 进行 Snapshot，而是换成了对某个 FCD 进行 Snapshot，从而实现了 Kubernetes 平台上 PVC 的 Snapshot。 FCD 的 Snapshot 和普通 vmdk 的 Snapshot 结构完全一致，也是由父磁盘和子磁盘组成，一样是差异磁盘的模式，文件组成和文件名的结构也完全一样。因此 vmdk 上被诟病多年的问题，FCD 上依然存在，然而不也是一种优势吗？ 因为这个原因，在 K10 备份的时候，我们不建议将 Snapshot 保留超过 3 份，为了性能和容量考虑，我建议 1 份 Snapshot 就已经足够了，其他的数据挪到 Repository 中吧。 K10 备份下来的数据，其中一部分可以导出至 VBR 中，这部分数据其实就是 FCD 的快照镜像，在 VBR 接收到这份数据后，VBR 可以利用强大的恢复能力来对 FCD 进行恢复。 事实上在 VBR 中，VBR 可以将任何的数据卷转换成 VMware 上的 FCD，只需要使用 VBR Instant Disk Recovery 功能。 ","date":"2022-03-23","objectID":"/2022/03/pvc-and-fcd/:3:0","tags":["VMware"],"title":"头等舱磁盘（First Class Disks）详解","uri":"/2022/03/pvc-and-fcd/"},{"categories":[],"content":"即时 PVC 恢复小实验 我在我的 Lab 中使用 VBR 的 Instant Disk Recovery 做了一个 PVC 恢复的小实验，试着强强联合，让他们碰撞出一些火花。 ","date":"2022-03-23","objectID":"/2022/03/pvc-and-fcd/:4:0","tags":["VMware"],"title":"头等舱磁盘（First Class Disks）详解","uri":"/2022/03/pvc-and-fcd/"},{"categories":[],"content":"场景 在我的 Tanzu 集群中，有一个叫 leihomedemo3 的 app，这个 app 非常简单，就是个 alpine linux，当前这个 alpine 并没有挂载任何数据卷。我想通过即时 FCD 恢复技术，将一个之前备份下来的 FCD 恢复并挂载到这个 alpine linux 的/data 目录。 ","date":"2022-03-23","objectID":"/2022/03/pvc-and-fcd/:4:1","tags":["VMware"],"title":"头等舱磁盘（First Class Disks）详解","uri":"/2022/03/pvc-and-fcd/"},{"categories":[],"content":"步骤 在 VBR 中，找到 k10 的备份存档，使用 Instant Disk Recovery 按钮打开恢复向导并选择最新的还原点。 在 Mount Mode 中，选择 First class disk(FCD)。 在 Disks 中，可以看到要恢复的磁盘的一些信息，这一步我保持默认，不做任何修改。 在 Destination 中，选择我的环境中运行着 Tanzu 的 Cluster。 接下去 Write Cache 之后的步骤都不做任何修改，一直到 Finish，就开始启动即时磁盘恢复了。大约几十秒之后，这个 FCD 就被成功挂载了。在即时恢复的 Session 中，可以看到这个磁盘被注册成 FCD，它的 ID 是 540eedc6-9a48-4f07-9ec1-cd3b9ec9a67e。 有了这个 FCD ID 之后，我来到 Tanzu 集群中，通过下面的 yaml 文件，将这个 FCD 绑定成 pvc。 kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: vbrinstant annotations: storageclass.kubernetes.io/is-default-class: \"false\" provisioner: csi.vsphere.vmware.com parameters: datastoreurl: ds:///vmfs/volumes/ae2b924e-83e53e07/ --- apiVersion: v1 kind: PersistentVolume metadata: name: vbrinstantrecoverypv annotations: pv.kubernetes.io/provisioned-by: csi.vsphere.vmware.com spec: storageClassName: vbrinstant capacity: storage: 1Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete csi: driver: \"csi.vsphere.vmware.com\" volumeAttributes: type: \"vSphere CNS Block Volume\" volumeHandle: \"540eedc6-9a48-4f07-9ec1-cd3b9ec9a67e\" --- kind: PersistentVolumeClaim apiVersion: v1 metadata: name: vbrinstantrecoverypvc namespace: leihomedemo3 spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: vbrinstant 到 Tanzu 控制台上执行命令： k10@tceconsole:~/demo$ kubectl apply -f vbrdemopvc.yaml storageclass.storage.k8s.io/vbrinstant unchanged persistentvolume/vbrinstantrecoverypv created persistentvolumeclaim/vbrinstantrecoverypvc created k10@tceconsole:~/demo$ kubectl get pvc -n leihomedemo3 NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE vbrinstantrecoverypvc Bound vbrinstantrecoverypv 1Gi RWO vbrinstant 28s 绑定成功了，FCD 就正式转换成了 Container Volume，此时从 vSphere Client 中也就能看到绑定后的 pv 卷了。 修改 deployment，加入挂载卷，修改完后，deployment 重启，几秒钟后，重启完成，这时候 pod 内就能看到数据了。 k10@tceconsole:~/demo$ kubectl edit deploy -n leihomedemo3 demo-app ## 在 container 部分加入挂载卷 containers: - name: demo-container volumeMounts: - name: data mountPath: /data ## 在 template spec 中加入 pvc 卷名称 spec: volumes: - name: data persistentVolumeClaim: claimName: vbrinstantrecoverypvc deployment.apps/demo-app edited k10@tceconsole:~/demo$ kubectl exec --namespace=leihomedemo3 demo-app-7758b547ff-gf4n8 -- ls -l /data/ total 24 -rw-rw-r-- 1 1000 117 811 Mar 15 05:49 depoly-pvc.yaml drwx------ 2 root root 16384 Mar 12 14:01 lost+found -rw-rw-r-- 1 1000 117 13 Mar 12 14:33 mytest 在 VBR 中，依然可以使用老套路，Migration to Production，将 PVC 从 vbr 的 cache 中迁移至生成系统的 Datastore 里。 整个迁移过程，系统没有任何中断，迁移完成后，在 Tanzu 中无需做任何修改，系统使用一切正常。唯一一点点小瑕疵在于，此时通过kubectl get pvc -n leihomedemo3 查询到 pvc，看到它依然是位于 VBR 挂载上来的 StorageClass。修改的方法也不算复杂，并且不修复也不影响使用： k10@tceconsole:~/demo$ kubectl delete -n leihomedemo3 pvc vbrinstantrecoverypvc persistentvolumeclaim \"vbrinstantrecoverypvc\" deleted ## 系统会卡在这一步，通过 ctrl+c 直接结束命令即可，然后运行下面这个命令强制解除 k10@tceconsole:~/demo$ kubectl patch pvc -n leihomedemo3 vbrinstantrecoverypvc -p '{\"metadata\":{\"finalizers\":null}}' ## 将步骤 6 中用到过的绑定的 yaml 中的 pv 和 pvc 部分的 storageClassName: vbrinstant 修改为 storageClassName:isonfs，然后重新应用这个 yaml 即可。 k10@tceconsole:~/demo$ kubectl apply -f vbrdemopvc.yaml storageclass.storage.k8s.io/vbrinstant unchanged persistentvolume/vbrinstantrecoverypv configured persistentvolumeclaim/vbrinstantrecoverypvc created 以上就是 FCD，这个全新的头等舱磁盘的分享。更多内容欢迎关注我的更新。 ","date":"2022-03-23","objectID":"/2022/03/pvc-and-fcd/:4:2","tags":["VMware"],"title":"头等舱磁盘（First Class Disks）详解","uri":"/2022/03/pvc-and-fcd/"},{"categories":[],"content":"最近刷新了下 Homelab，开始在 Homelab 中玩玩 Tanzu。去年 VMware 开源了 Tanzu Community Edition，正好利用这个机会装上配上 k10 和 VBR 玩一把。 ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:0:0","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"硬件部分 我的环境由 2 台机器组成，一台是服役了 6 年多的 Dell Precision M4800，另外一台是新加入的 NUC11 猎豹峡谷。Dell 笔记本纯粹是在这个环境中打酱油的，而猎豹峡谷的配置如下： CPU：Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 内存：ADATA 32GB×2 DDR4-3200 硬盘：aigo NVMe SSD P2000 1TB 网卡：Intel Corporation Ethernet Controller I225-V ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:1:0","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"软件部分 M4800 上，使用 DellEMC 的自定义 ESXi 镜像，从 DellEMC 的官网能够下载到，里面包含了所有 Dell 硬件的驱动。 NUC11 上安装 ESXi 最大的挑战来自于网卡驱动，这个网卡是 2.5GbE 的网卡，VMware 官方驱动中并不包含。不过大神们总有解决办法，社区版网卡驱动 戳这里 就能找到。 两台主机都安装 vSphere 7.0.3，vCenter 版本也是 7.0.3. ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:2:0","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"开动安装 TCE ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:3:0","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"环境准备 首先我需要一个控制台来安装并操作 TCE，TCE 的官方手册 上提供了 macOS、Linux 和 Windows 的三种平台安装。我选择在我的环境中安装一台 Ubuntu 20.04 LTS 的虚拟机来安装 Tanzu CLI 软件。 这台 Ubuntu，并不是一台最小化安装的普通 Ubuntu，需要另外准备以下环境： 安装 Docker，并配置 non-root 用户使用 Docker。配置方法很简单，只需要使用 non-root 用户，在安装完 docker 之后，按顺序执行下列命令即可。 ## 1. 先加 docker 组 k10@tceconsole:~$ sudo groupadd docker ## 2. 把当前用户加到 docker 组里 k10@tceconsole:~$ sudo usermod -aG docker $USER ## 3. 接下去最好注销后重新登录，或者直接用下面的命令激活 $ newgrp docker ## 4. 试试 docker 命令，是否正常 k10@tceconsole:~$ docker run hello-world 安装 kubectl，这个没啥特别，根据官网指引或者其他的说明直接安装即可。 有了这些条件后，就可以使用 TCE 官网手册中的安装方法来安装 Tanzu CLI 了 在 Tanzu CLI 安装好之后，还需要从 VMware 官网 下载 OVA 镜像，这个镜像是用来在 vSphere 中部署 k8s node 的，我选择了ubuntu-2004-kube-v1.21.5+vmware.1-tkg.1-12483545147728596280-tce-010.ova。 下载完成后，在 vSphere 中导入这个 ova，并立刻将这个 ova 转换成模板，如下图在 vSphere 中可以看到这样的状态即可： 另外，我还要在我的环境中配置一个 DHCP 服务器，在部署集群时，TCE 必须依赖 DHCP 服务才能完成所有工作。 最后，是用下面的命令准备图形化安装第一步要用的 ssh public key ## 创建一个 SSH 密钥对 k10@tceconsole:~$ ssh-keygen -t rsa -b 4096 -C \"administrator@backupnext.cloud\" ## 获取下这个公钥备用 k10@tceconsole:~$ cat .ssh/id_rsa.pub ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:3:1","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"部署管理集群 TCE 和其他 Tanzu 一样，都由管理集群（Management Cluster）和工作负载集群（Workload Cluster）组成，我在我的环境中首先需要配置一个管理集群，配置启动方法非常简单，只需要运行下面的命令即可： k10@tceconsole:~$ tanzu management-cluster create --ui --bind 0.0.0.0:8080 --browser none 命令运行后，我在我本地的浏览器中，打开http://\u003cubuntuip\u003e:8080/ 就可以进入 Tanzu 安装向导图形界面了。 选择部署平台，VMware vSphere 填入 vCenter 信息并连接，这里连接后，需要将前面准备好的 SSH 公钥填入到 SSH Public Key 框中。 设置管理集群信息，我选择了 Development 模式，这样在我的小 Lab 中只需要一台 Control Plane 节点，并且我将 Instance Type 选择了 small 的最小配置。我填写了 Management Cluster Name 为leihome，启用了 Machine Health Checks。Control Plane Endpoint Provider 选择 Kube-vip，指定 Control Plane Endpoint 地址为 10.10.1.182，设定了 Worker Node Instance Type 为 Small，Audit Logging 为不 Enable。 VMware NSX Advanced Load Balancer 和 Metadata 部分，都禁用不选择。 在第五步 Resource 中，指定部署到 VM Folder 为/HomelabDC/vm/tkg，Datastore 为/HomelabDC/datastore/localnvme，Cluster、Hosts、and Resource Pools 选择TanzuCE这个资源池。 Kubernetes Network 步骤中，配置没进行修改，保持默认。 Identity Management 步骤中，禁用 Identity Management Settings。 OS image 步骤中，选择准备工作中已经导入的虚拟机模板 node 节点。 然后以上配置就完成了，Review 下 configuration 之后，就进入了全自动的配置，大约半小时左右管理集群将会被自动部署完并且可以使用。 管理集群部署完成后，回到我的 Ubuntu 控制台上，执行命令： ## 查询下前面安装的管理集群 k10@tceconsole:~$ tanzu management-cluster get NAME NAMESPACE STATUS CONTROLPLANE WORKERS KUBERNETES ROLES leihome tkg-system running 1/1 1/1 v1.21.5+vmware.1 management Details: NAME READY SEVERITY REASON SINCE MESSAGE /leihome True 8d ├─ClusterInfrastructure - VSphereCluster/leihome True 8d ├─ControlPlane - KubeadmControlPlane/leihome-control-plane True 8d │ └─Machine/leihome-control-plane-2mz2v True 8d └─Workers └─MachineDeployment/leihome-md-0 └─Machine/leihome-md-0-6f69758844-zpfsj True 8d Providers: NAMESPACE NAME TYPE PROVIDERNAME VERSION WATCHNAMESPACE capi-kubeadm-bootstrap-system bootstrap-kubeadm BootstrapProvider kubeadm v0.3.23 capi-kubeadm-control-plane-system control-plane-kubeadm ControlPlaneProvider kubeadm v0.3.23 capi-system cluster-api CoreProvider cluster-api v0.3.23 capv-system infrastructure-vsphere InfrastructureProvider vsphere v0.7.10 ## 获取 kubectl 的管理权限 k10@tceconsole:~$ tanzu management-cluster kubeconfig get leihome --admin Credentials of cluster 'leihome' have been saved You can now access the cluster by running 'kubectl config use-context leihome-admin@leihome' ## 试下 kubectl k10@tceconsole:~$ kubectl get node NAME STATUS ROLES AGE VERSION leihome-control-plane-2mz2v Ready control-plane,master 8d v1.21.5+vmware.1 leihome-md-0-6f69758844-zpfsj Ready \u003cnone\u003e 8d v1.21.5+vmware.1 这样，管理集群就全部完成了，这时候，回到 vCenter 上，也能够看到 2 台对应的 node 虚拟机。 ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:3:2","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"部署 Workload 集群 在管理集群部署完成后，以上的集群配置会以 yaml 文件自动保存在~/.config/tanzu/tkg/clusterconfigs/目录下，部署 Workload 集群的方法非常简单，只需要利用自动生成的管理集群的 yaml 文件，稍加修改，即可使用。 通过以下命令，先创建一份并修改用于部署 Workload 集群的 yaml 文件： k10@tceconsole:~$ cp ~/.config/tanzu/tkg/clusterconfigs/pkwmre6kuu.yaml ~/.config/tanzu/tkg/clusterconfigs/workload1.yaml k10@tceconsole:~$ vi ~/.config/tanzu/tkg/clusterconfigs/workload1.yaml 修改文件中以下字段： CLUSTER_NAME: leihome-workload-01 VSPHERE_CONTROL_PLANE_ENDPOINT: 10.10.1.191 VSPHERE_WORKER_MEM_MIB: \"8192\" 其中CLUSTER_NAME是 Workload 集群的名称，我这里使用leihome-workload-01，VSPHERE_CONTROL_PLANE_ENDPOINT是这个 Workload 集群的 APIServer 的访问地址，设置为固定 IP 比较合适，我使用10.10.1.191，VSPHERE_WORKER_MEM_MIB是 Workload 集群的内存，我的环境中默认 Small 配置的 4GB 不太够用，我设置成了8192。 修改完成后，运行如下命令，就能自动部署 Workload 集群了。 k10@tceconsole:~$ tanzu cluster create leihome-workload-01 --file ~/.config/tanzu/tkg/clusterconfigs/workload1.yaml 大约 10 来分钟，Workload 集群就会部署完成，部署后和管理集群一样，默认配置为一个 Control Plane 和一个 Worker。我计划多运行几个应用程序，因此我用下面这条命令来增加 Worker Node： k10@tceconsole:~$ tanzu cluster scale leihome-workload-01 --worker-machine-count=2 Successfully updated worker node machine deployment replica count for cluster leihome-workload-01 Workload cluster 'leihome-workload-01' is being scaled Workload 集群部署完成后，和管理集群一样，需要获取下 Workload 集群的访问权限： ## 获取当前的 Workload 集群列表 k10@tceconsole:~$ tanzu cluster list NAME NAMESPACE STATUS CONTROLPLANE WORKERS KUBERNETES ROLES PLAN leihome-workload-01 default running 1/1 2/2 v1.21.5+vmware.1 \u003cnone\u003e dev ## 获取 leihome-workload-01 这个 Workload 集群的访问权限 k10@tceconsole:~$ tanzu cluster kubeconfig get leihome-workload-01 --admin Credentials of cluster 'leihome-workload-01' have been saved You can now access the cluster by running 'kubectl config use-context leihome-workload-01-admin@leihome-workload-01' ## 用 kubectl 查下当前的 context 清单 k10@tceconsole:~$ kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * leihome-admin@leihome leihome leihome-admin leihome-workload-01-admin@leihome-workload-01 leihome-workload-01 leihome-workload-01-admin ## 用 kubectl 命令切换下集群，开始使用部署出来的集群 k10@tceconsole:~$ kubectl config use-context leihome-workload-01-admin@leihome-workload-01 Switched to context \"leihome-workload-01-admin@leihome-workload-01\". ## 获取下 node k10@tceconsole:~$ kubectl get node NAME STATUS ROLES AGE VERSION leihome-workload-01-control-plane-c4k4q Ready control-plane,master 7d18h v1.21.5+vmware.1 leihome-workload-01-md-0-668d8747d6-4hd6z Ready \u003cnone\u003e 7d18h v1.21.5+vmware.1 leihome-workload-01-md-0-668d8747d6-hcs4k Ready \u003cnone\u003e 7d18h v1.21.5+vmware.1 回到 vCenter 中，可以看到 3 台 Workload Node 虚拟机已经运行起来了。 以上过程，Kubernetes 集群的计算资源就已经算是配置完成了。 ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:3:3","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"存储资源配置 Tanzu 集群可以通过 vSphere CSI 使用 vSphere 7.0 上的 datastore 存放持久化数据，但是默认情况下并没有自动将 datastore 和 Tanzu 集群关联，这时候我通过下面这个 yaml 文件，将 datastore 的访问开放给 Workload。 kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: standard annotations: storageclass.kubernetes.io/is-default-class: \"true\" provisioner: csi.vsphere.vmware.com parameters: datastoreurl: ds:///vmfs/volumes/622a19d3-91aee82b-59df-1c697aafcbf9/ 其中最下面一行 datastoreurl 可以通过 vCenter 中 datastore 的 summary 中的地址获取，如图： 配置这个新的 StorageClass，并取消原来 default 的 storage Class 作为默认 Storage Class： ## 添加新的 Storage Class，连接 vSphere 上的 Datastore k10@tceconsole:~$ kubectl apply -f ~/storage/localnvme.yaml ## 取消原来自动配上的 Hostpath 作为默认 Storage Class，当然也可以直接删除掉 default 的 storage class k10@tceconsole:~$ kubectl patch storageclass default -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"false\"}}}' ## 用 kubectl 查询下目前的 sc 状况 k10@tceconsole:~$ kubectl get sc NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE default csi.vsphere.vmware.com Delete Immediate true 7d19h standard (default) csi.vsphere.vmware.com Delete Immediate false 7d18h ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:3:4","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"开个测试 demo 应用试下环境 这个小 demo 很简单，就是个 alpine Linux，挂一个数据目录/data，这个 data 目录实际上就会映射至 vSphere 的 Datastore 中，分配一个 vmdk 文件。关于这个 vmdk 文件，我先卖个关子，在下期推送中详细讨论。 小 Demo 的 yaml： apiVersion: v1 kind: PersistentVolumeClaim metadata: name: demo-pvc labels: app: demo pvc: demo spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: demo-app labels: app: demo spec: replicas: 1 selector: matchLabels: app: demo template: metadata: labels: app: demo spec: containers: - name: demo-container image: alpine:3.7 resources: requests: memory: 256Mi cpu: 100m command: [\"tail\"] args: [\"-f\", \"/dev/null\"] volumeMounts: - name: data mountPath: /data volumes: - name: data persistentVolumeClaim: claimName: demo-pvc 创建过程很简单，下面 2 条命令即可，创建完成后，拷贝个文件进持久数据卷试试： k10@tceconsole:~$ kubectl create ns leihomedemo k10@tceconsole:~$ kubectl apply -n leihomedemo -f ~/demo/demoapp.yaml k10@tceconsole:~$ kubectl cp mytest leihomedemo/demo-app-696f676d47-dsbcr:/data/ k10@tceconsole:~$ kubectl exec --namespace=leihomedemo demo-app-696f676d47-dsbcr -- ls -l /data total 24 drwx------ 2 root root 16384 Mar 12 14:01 lost+found -rw-rw-r-- 1 1000 117 13 Mar 12 14:33 mytest 一切正常，环境完美运行。 ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:3:5","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"安装配置 K10 ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:4:0","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"安装 K10 安装 K10 前，我准备了一台 VBR v11a 的 Windows 服务器和一台 Minio S3 的对象存储，用于存放 K10 的备份数据。 K10 的安装和常规部署没任何区别，在安装前还是惯例运行下 Pre-flight 脚本检查环境： k10@tceconsole:~$ curl https://docs.kasten.io/tools/k10_primer.sh | bash % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 7045 100 7045 0 0 918 0 0:00:07 0:00:07 --:--:-- 1757 Namespace option not provided, using default namespace Checking for tools --\u003e Found kubectl --\u003e Found helm Checking if the Kasten Helm repo is present --\u003e The Kasten Helm repo was found Checking for required Helm version (\u003e= v3.0.0) --\u003e No Tiller needed with Helm v3.4.1 K10Primer image --\u003e Using Image (gcr.io/kasten-images/k10tools:4.5.11) to run test Checking access to the Kubernetes context leihome-workload-01-admin@leihome-workload-01 --\u003e Able to access the default Kubernetes namespace K10 Kanister tools image --\u003e Using Kanister tools image (ghcr.io/kanisterio/kanister-tools:0.74.0) to run test Running K10Primer Job in cluster with command- ./k10tools primer serviceaccount/k10-primer created clusterrolebinding.rbac.authorization.k8s.io/k10-primer created job.batch/k10primer created Waiting for pod k10primer-b5nf9 to be ready - ContainerCreating Pod Ready! I0319 05:28:41.931353 8 request.go:665] Waited for 1.043641473s due to client-side throttling, not priority and fairness, request: GET:https://100.64.0.1:443/apis/scheduling.k8s.io/v1beta1 Kubernetes Version Check: Valid kubernetes version (v1.21.5+vmware.1) - OK RBAC Check: Kubernetes RBAC is enabled - OK Aggregated Layer Check: The Kubernetes Aggregated Layer is enabled - OK W0319 05:28:42.188135 8 warnings.go:70] storage.k8s.io/v1beta1 CSIDriver is deprecated in v1.19+, unavailable in v1.22+; use storage.k8s.io/v1 CSIDriver CSI Capabilities Check: VolumeSnapshot CRD-based APIs are not installed - Error Validating Provisioners: csi.vsphere.vmware.com: Storage Classes: default K10 supports the vSphere CSI driver natively. Creation of a K10 infrastucture profile is required. Valid Storage Class - OK isonfs K10 supports the vSphere CSI driver natively. Creation of a K10 infrastucture profile is required. Valid Storage Class - OK standard K10 supports the vSphere CSI driver natively. Creation of a K10 infrastucture profile is required. Valid Storage Class - OK Validate Generic Volume Snapshot: Pod Created successfully - OK GVS Backup command executed successfully - OK Pod deleted successfully - OK serviceaccount \"k10-primer\" deleted clusterrolebinding.rbac.authorization.k8s.io \"k10-primer\" deleted job.batch \"k10primer\" deleted 以上可以看到其中 CSI Capabilities Check 出现了个 Error，这个没关系，因为是使用 vSphere CSI，快照部分功能是利用 vSphere 源生的 vmdk 快照实现，因此在集群里我并没有安装 VolumeSnapshotClass。 安装 K10 还是老方法，官网手册中的可以直接使用，而我这边还是依旧使用 ccr.ccs.tencentyun.com/kasten 这个镜像库： k10@tceconsole:~$ helm repo add kasten https://charts.kasten.io/ k10@tceconsole:~$ helm repo update k10@tceconsole:~$ helm install k10 kasten/k10 \\ --namespace=kasten-io \\ --set global.persistence.storageClass=standard \\ --set global.airgapped.repository=ccr.ccs.tencentyun.com/kasten \\ --set metering.mode=airgap ## 通过 Nodeport 暴露 k10 图形界面访问 k10@tceconsole:~$ kubectl expose -n kasten-io deployment gateway --type=NodePort --name=gateway-nodeport-svc --port=8000 等待 10 来分钟之后，我的 K10 就能通过 http://10.10.1.14:32080/k10/#/进行访问了。 ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:4:1","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"k10 配置 vCenter 和 VBR 进入 K10 主页后，在 Settings 中找到 Location Profile，首先需要添加一个 S3 对象存储作为主备份存储，就算我有 VBR 的存储库，这个都不能少。如下图配置非常简单： 再来添加一个 VBR 的 Repository，用于 vmdk 数据备份存储，也就是 pvc 的备份。 在 Location Profile 下面，找到 Infrastructure，使用 New Profile 按钮新增一个 vCenter 的连接，配置信息非常简单，和任何设备添加 vCenter 几乎没区别，IP 地址、用户名、密码，3 要素。 接下来，就可以进行备份策略的配置了。备份策略和其他 Kubernetes 平台 K10 的备份策略稍有不同，在 Snapshot Retention 上，可以看到 K10 自动感知到这是 VMware 平台，给出了 VMware 平台中 Snapshot 保留的最佳实践，建议不能超过 3 个 Snapshot。因此如下图，我将 Snapshot 设置为 1。在 Export Location Profile 中，可以选择 Minio S3 对象存储作为第一级备份 Export 目标，此处 VBR 的 Location Profile 不可选。 在这个Enable Backups via Snapshot Exports之后，会有个新增的选项Export snapshot data to a Veeam Backup Server repository，勾选这个选项后，可以选择 Veeam Backup Location Profile。 其他配置没有什么特别，这样配置后的 Policy 如下： 备份自动运行后，可以从 Dashboard 进入查看到详细的备份 Action 详情，其中 VBR 的导出部分由 Kanister 完成： 而在 VBR 中，可以看到 K10 的 Policy 和 K10 的备份存档也已经出现： 关于 VBR 中 K10 的操作，可以参考 Veeam 官方的手册，已经在官网上线。 ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:4:2","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"最后 到目前为止，整个环境资源消耗： 虚拟机 用途 CPU 内存 vCenter vCenter 2vCPU 12GB TCEconsole Tanzu 控制台 2vCPU 8GB leihome-control-plane-2mz2v TCE 管理集群控制节点 2vCPU 4GB leihome-md-0-6f69758844-zpfsj TCE 管理集群工作节点 2vCPU 4GB leihome-workload-01-control-plane-c4k4q TCE 工作集群控制节点 2vCPU 4GB leihome-workload-01-md-0-668d8747d6-4hd6z TCE 工作集群工作节点 2vCPU 8GB leihome-workload-01-md-0-668d8747d6-hcs4k TCE 工作集群工作节点 2vCPU 8GB VBR VBR 4vCPU 8GB 总计 18vCPU 56GB 还没超过我的 NUC11 总内存，一台 NUC11 跑这么个环境绰绰有余啦。 ","date":"2022-03-19","objectID":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/:5:0","tags":["VMware"],"title":"Tanzu Community Edition（TCE）试玩","uri":"/2022/03/vmware-tanzu-community-edition-%E8%AF%95%E7%8E%A9/"},{"categories":[],"content":"月初，VMware 官网博客发了一则 通告，他们将 vCenter Converter 从 VMware 产品下载清单中移除了，也就是说，我们以后再也无法在 VMware 官网下载到这一产品了。从 VMware 官方的说法是，vCenter Converter 多年没更新，产品有一些安全隐患并且不太稳定。而在我看来，VMware 是将他们最强力的武器给拿下来了。 ","date":"2022-02-28","objectID":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/:0:0","tags":["VMware"],"title":"vCenter Converter 下架后 p2v 怎么玩","uri":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/"},{"categories":[],"content":"这个工具能干啥？ 可能不少朋友并没有接触过这个工具，但是对于 VMware 管理员来说，这个工具可以说是他们的最佳搭档，这个工具的装机率之高，可以说是 VMware 自身一大堆产品中，仅次于 vCenter，绝大多数环境中都是装完 vCenter 立刻同时装上 vCenter Converter。 这个工具是早期 VMware 成功的重要功臣，早在 VI3.0 的年代，就普遍被管理员使用，当时它的基础功能很简单，目标也非常简单：帮助管理员将物理机转化成 VMware 上的虚拟机。这可是帮到管理员的大忙了，全自动的完成物理到虚拟的转换，工作负载变成了虚拟机状态运行在 VMware 平台。 早期的 Converter 工具仅限于 Windows 的转换，后期它的功能越来越强大，同时支持 Windows 和 Linux 系统，还能支持从其他虚拟化平台转换成 VMware vSphere 上的虚拟机。 ","date":"2022-02-28","objectID":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/:1:0","tags":["VMware"],"title":"vCenter Converter 下架后 p2v 怎么玩","uri":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/"},{"categories":[],"content":"工作过程 vCenter Converter 一般会有两种实现方式，分别是热迁移和冷迁移。其中热迁移相对系统要求较高，如果一切顺利的情况下，整个过程业务基本上没有中断，但是数据一致性上因为业务持续在运行并不是太高；而冷迁移相对系统要求低，适用性广，并且因为系统关机状态进行，迁移前后数据完全一致。 这两种迁移转换方式，都会存在较长的转换时间，这个时间基本上是取决于源系统的磁盘容量大小。 ","date":"2022-02-28","objectID":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/:2:0","tags":["VMware"],"title":"vCenter Converter 下架后 p2v 怎么玩","uri":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/"},{"categories":[],"content":"替代方案 这里隆重介绍下 Veeam 的神技能：Instant Recovery！ 这个技术在 v10 开始就不断突破，在目前 v11 的版本里面可以说是已经脱胎换骨。原本这只是一个即时挂载，快速恢复的功能，然而想象力创造力无限的 Veeam 用户提出了将物理机的备份存档在虚拟化平台即时恢复的概念后，Veeam 的研发团队将这一概念落地成了实实在在的功能并且将这功能进一步延伸扩展： 将 Hyper-V 上虚拟机的备份存档，即时恢复到 VMware vSphere 将 Veeam Agent for Microsoft Windows 或 Linux 的备份存档，即时恢复到 VMware vSphere 将 Nutanix AHV 上虚拟机的备份存档，即时恢复到 VMware vSphere 将 Amazon EC2 上虚拟机的备份存档，即时恢复到 VMware vSphere 将 Microsoft Azure 上虚拟机的备份存档，即时恢复到 VMware vSphere 将 Google Compute Engine 上虚拟机的备份存档，即时恢复到 VMware vSphere 将 RHV 上虚拟机的备份存档，即时恢复到 VMware vSphere 因此，任何迁移，只需要通过 Veeam 进行备份，然后 Instant Recovery，最后 Migration 恢复的虚拟机至生成虚拟化系统即可。 ","date":"2022-02-28","objectID":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/:3:0","tags":["VMware"],"title":"vCenter Converter 下架后 p2v 怎么玩","uri":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/"},{"categories":[],"content":"技术要点和操作建议 最后敲黑板来划下重点，功能很强大，但是用的时候一定要注意以下问题： 热迁移数据偏差量问题，非常建议在做 Instant Recovery 之前做一次最后的增量备份，并且保证这次增量在几分钟内完成，如果增量花的时间久，可以在这个增量做完之后立刻再做下一个增量，最后的增量备份完成后，立马将源机关机，然后使用这个最新的增量还原点进行下一步的即时恢复。这样做的效果可以实现 10 分钟以内的停机完成迁移。 在做 Instant Recovery 的时候，对于 Windows 系统成功率几乎是 100%的，但是对于 Linux 系统，可能会存在一些这样或者那样的问题，建议在备份前，检查 Linux 系统，确保正确安装了dracut和mkinitrd，这个能大大提升恢复成功率。 注意 IRcache 目录的空间大小，这几年很多物理机的内存容量会特别大，比如一台服务器配置 256GB/512GB 内存，可能非常常见。对于这些机器的 Instant Recovery，IRcache 的容量一定要预留比内存大。 迁移方法可以用 Storage vMotion，也可以使用 Veeam Quick Migration。这两个各有优劣，具体可以参考我之前的帖子。 好了，以上就是今天的内容，希望 VMware 的 vCenter Converter 的下架不会对大家的日常工作造成太多困扰。 ","date":"2022-02-28","objectID":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/:4:0","tags":["VMware"],"title":"vCenter Converter 下架后 p2v 怎么玩","uri":"/2022/02/vmware-vcenter-converter%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/"},{"categories":["Repository"],"content":"脚本用途 根据Veeam最佳实践，一键脚本配置Linux系统，操作系统配置完成后，可以回到VBR控制台完成存储库的添加。 关于手工配置和原理介绍，请参考以下帖子： veeam-v11-hardened-linux-repository-配置指南-centos8 加固的备份存储库hardened-repository配置指南-ubuntu veeam-hardened-repository-quick-starter ","date":"2022-02-25","objectID":"/2022/02/veeam-hardened-linux-repository-configurator/:1:0","tags":["备份"],"title":"Veeam Hardened Linux Repository Configurator","uri":"/2022/02/veeam-hardened-linux-repository-configurator/"},{"categories":["Repository"],"content":"使用前提条件 确保系统满足使用Veeam Hardened Linux Repository的最低要求。 服务器上有未格式化的磁盘/dev/sdb，/dev/sdc等。 必须使用root账号运行本脚本。 ","date":"2022-02-25","objectID":"/2022/02/veeam-hardened-linux-repository-configurator/:2:0","tags":["备份"],"title":"Veeam Hardened Linux Repository Configurator","uri":"/2022/02/veeam-hardened-linux-repository-configurator/"},{"categories":["Repository"],"content":"系统要求 本脚本在Redhat 8.2/CentOS 8.2/Ubuntu 20.04以上版本中测试通过，其他系统版本暂不支持。 ","date":"2022-02-25","objectID":"/2022/02/veeam-hardened-linux-repository-configurator/:3:0","tags":["备份"],"title":"Veeam Hardened Linux Repository Configurator","uri":"/2022/02/veeam-hardened-linux-repository-configurator/"},{"categories":["Repository"],"content":"脚本仓库 https://github.com/Coku2015/Veeam_Repo_Configurator ","date":"2022-02-25","objectID":"/2022/02/veeam-hardened-linux-repository-configurator/:4:0","tags":["备份"],"title":"Veeam Hardened Linux Repository Configurator","uri":"/2022/02/veeam-hardened-linux-repository-configurator/"},{"categories":["Repository"],"content":"脚本使用详解 下载脚本： curl -O https://ghproxy/https://raw.githubusercontent.com/Coku2015/Veeam_Repo_Configurator/main/HLRepo_configurator.sh 运行脚本 bash HLRepo_configurator.sh 脚本运行后，会首先检测当前是否为root用户以及相应的操作系统，如果不是则退出脚本。 提示用户设定Veeam存储管理用户、密码和备份数据的存放路径，这些信息将会用于VBR控制台上的后续配置。 为服务器上空闲的磁盘创建LVM卷，并格式化成xfs文件系统，启用reflink功能用于VBR的fast clone功能。 往/etc/fstab文件中添加记录并挂载格式化后的磁盘空间，分配用户权限。 回VBR控制台配置备份存储库，配置完成后，脚本会锁定Veeam存储管理用户，禁止登陆，同时提示用户禁用SSH访问，进一步加固系统。 ","date":"2022-02-25","objectID":"/2022/02/veeam-hardened-linux-repository-configurator/:5:0","tags":["备份"],"title":"Veeam Hardened Linux Repository Configurator","uri":"/2022/02/veeam-hardened-linux-repository-configurator/"},{"categories":["Linux Agent"],"content":"一。组成和作用 Veeam Agent for Linux（以下简称 VAL）由两部分组成，一个是 Veeam 主程序，另外一个是 Veeamsnap 驱动程序。以 centos/redhat 举例，如果想让 Veeam Agent for Linux 正常工作，一般来说我们需要安装上两个程序，分别是： veeam-\u003cxxxxxxxxxxx\u003e.rpm veeamsnap-\u003cxxxxxxxxxxx\u003e.rpm 其中，Veeamsnap 驱动程序负责系统快照和变化数据块追踪工作，而 Veeam 主程序则负责其他所有相关的工作，当 Veeam 主程序被安装时，依赖包 Veeamsnap 会被自动安装。 ","date":"2021-10-12","objectID":"/2021/10/veeam-agent-for-linux-installation-deep-dive/:1:0","tags":["备份"],"title":"Veeam Agent for Linux 安装深度分析","uri":"/2021/10/veeam-agent-for-linux-installation-deep-dive/"},{"categories":["Linux Agent"],"content":"二。安装过程 在安装时，VAL 需要安装一系列 Linux 依赖包，这些依赖包会自动通过 Linux 的包管理器去 Linux 相关的软件镜像源中搜索，关于这部分，可以参考 《Veeam Agent for Linux 基础知识》。 大部分比较顺滑的情况，是通过 VBR 进行 VAL 的推送安装，VBR 会自动处理以下的所有安装逻辑，自动判断自动安装最合适的软件包，但是在这背后，有多种特殊情况存在。 ","date":"2021-10-12","objectID":"/2021/10/veeam-agent-for-linux-installation-deep-dive/:2:0","tags":["备份"],"title":"Veeam Agent for Linux 安装深度分析","uri":"/2021/10/veeam-agent-for-linux-installation-deep-dive/"},{"categories":["Linux Agent"],"content":"2.1. dkms 编译安装 对于 Veeamsnap 来说，它是一个 Linux 内核外的驱动程序，对于不同的 Linux 系统，绝大多数情况下无法通用。因此 Veeam 采用了 DKMS 来帮助维护这个驱动程序，安装veeamsnap-\u003cxxxxxxxxxxx\u003e.rpm时，会将 Veeamsnap 模块自动添加至 dkms 中并执行编译和安装模块的过程。 关于 DKMS，它是 Dell 创建的开源项目，全称是 Dynamic Kernel Module Support，用于维护内核外的驱动程序，详细内容可以参考 https://www.cnblogs.com/wwang/archive/2011/06/21/2085571.html 要正确安装并编译 Veeamsnap 快照驱动，就需要首先安装并配置 dkms 能正常工作，这部分在绝大多数 Linux 系统中并不算复杂，Veeamsnap 会去自动寻找 dkms 依赖包并把和 dkms 相关的 gcc、make、kernel-header 自动装上，然后使用它们进行安装和编译驱动过程。 ","date":"2021-10-12","objectID":"/2021/10/veeam-agent-for-linux-installation-deep-dive/:2:1","tags":["备份"],"title":"Veeam Agent for Linux 安装深度分析","uri":"/2021/10/veeam-agent-for-linux-installation-deep-dive/"},{"categories":["Linux Agent"],"content":"2.2. 预编译安装包 对于特定的 Linux 发行版，Veeam 还制作了无需编译安装的 Veeamsnap，这些 Veeamsnap 安装包我们称为 kmod-veeamsnap，这些安装包和上面提到的veeamsnap-\u003cxxxxxxxxxxx\u003e.rpm功能完全相同，只是在使用时，无需通过 dkms 编译，而是直接使用。这时候 dkms 编译的前提条件和依赖对于 kmod-veeamsnap 就完全不需要了。 已经预编译的系统包括： 内核版本 2.6.32-131.0.15 以上的 Radhat 6 内核版本 3.10.0-123 以上的 CentOS/Radhat 7.0-7.9 CentOS/Radhat 8 SLES openSUSE 这些系统的 kmod 安装包都可以在 http://repository.veeam.com/.private/rpm 中找到。 需要注意的是，因为是预编译的软件包，对于不同的系统需要选择不同的驱动，这时候这个选择 Veeam 需要借助 python3 脚本来完成，这时候 Linux 系统需要依赖 Python3。在安装kmod-veeamsnap--\u003cxxxxxxxxxxx\u003e.rpm时，VAL 会自动寻找 python3 依赖包，安装并使用，最终完成 kmod-veeamsnap 的安装。 ","date":"2021-10-12","objectID":"/2021/10/veeam-agent-for-linux-installation-deep-dive/:2:2","tags":["备份"],"title":"Veeam Agent for Linux 安装深度分析","uri":"/2021/10/veeam-agent-for-linux-installation-deep-dive/"},{"categories":["Linux Agent"],"content":"2.3. 启用安全引导（UEFI 的 Secure Boot） 对于启用了 UEFI 安全引导的 Linux 系统，要使用 kmod-veeamsnap，需要将 kmod-veeamsnap 的证书导入到 UEFI 控制台中。这个证书可以先使用 veeamsnap-ueficert-5.0.1.4493-1.noarch.rpm 这个包获取，具体步骤如下： 下载并安装 veeamsnap-ueficert-5.0.1.4493-1.noarch.rpm，比如 Redhat8： curl -O http://repository.veeam.com/.private/rpm/el/8/x86_64/veeamsnap-ueficert-5.0.1.4493-1.noarch.rpm rpm -ivh veeamsnap-ueficert* 执行导入命令 mokutil --import veeamsnap-ueficert.crt 重启 Linux 系统进入 UEFI Bios 控制台里，去分配下这个证书 后续的 kmod-veeamsnap 安装过程和 2.2 中没任何区别。 ","date":"2021-10-12","objectID":"/2021/10/veeam-agent-for-linux-installation-deep-dive/:2:3","tags":["备份"],"title":"Veeam Agent for Linux 安装深度分析","uri":"/2021/10/veeam-agent-for-linux-installation-deep-dive/"},{"categories":["Linux Agent"],"content":"2.4. 😂😂不使用 Veeamsnap 以上这些 veeamsnap 都没条件使用时，从 VAL 5.0.1 起，Veeam 提供 snapless 的备份方式，提供了不依赖 veeamsnap 工作的 VAL 主程序，比如 Redhat 8： http://repository.veeam.com/.private/rpm/el/8/x86_64/veeam-nosnap-5.0.1.4493-1.el8.x86_64.rpm 这个程序无法支持快照备份，只能通过 File level snapshot-less 的方式进行文件备份，如下图： 当然，在 VBR 中也有同样的选项： 这个主程序可以直接单独安装，在安装的时候它不会再去要求 veeamsnap 的依赖，而其他的常规依赖包依然是通过 Linux 包管理器自动获取。 以上就是今天的内容，希望对大家安装 VAL 有帮助。 ","date":"2021-10-12","objectID":"/2021/10/veeam-agent-for-linux-installation-deep-dive/:2:4","tags":["备份"],"title":"Veeam Agent for Linux 安装深度分析","uri":"/2021/10/veeam-agent-for-linux-installation-deep-dive/"},{"categories":["Kubernetes"],"content":"Kasten K10 入门系列目录 Kasten K10 入门系列 01 - 快速搭建 K8S 单节点测试环境 Kasten K10 入门系列 02 - K10 安装 Kasten K10 入门系列 03 - K10 备份和恢复 Kasten K10 入门系列 04 - K10 安装包下载 ","date":"2021-07-22","objectID":"/2021/07/k10offline-script-2/:1:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 05 - K10 安装包下载（2）","uri":"/2021/07/k10offline-script-2/"},{"categories":["Kubernetes"],"content":"正文 在上一篇中，我们介绍了通过脚本实现从网络上下载并推送 k10 安装镜像至私有镜像库，今天我想来分享一些离线的镜像包，在完全无法访问外网的环境中，这也许是一种最方便的方式。 首先放上下载链接： https://cloud.189.cn/web/share?code=zIVZ3uaIzUr2（访问码：8fbw） ","date":"2021-07-22","objectID":"/2021/07/k10offline-script-2/:2:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 05 - K10 安装包下载（2）","uri":"/2021/07/k10offline-script-2/"},{"categories":["Kubernetes"],"content":"内容说明 在这个下载链接中，K10 安装包按版本都放置在每个版本号命名的文件夹中。在版本号文件夹里面，会包含两个文件： kasten_k10_offline_images_\u003c版本号\u003e.tar.gz : 镜像包 k10_\u003c版本号\u003e.json : 推送至私有镜像库的配置文件 在这个镜像包中，包含了所有 k10 的安装镜像 (4.0.8 版本，其他版本可能会略有不同）： 原始 Repository 镜像名 ghcr.io/kanisterio kanister-tools quay.io/datawire ambassador quay.io/prometheus prometheus jimmidyson configmap-reload quay.io/dexidp dex gcr.io/kasten-images frontend gcr.io/kasten-images kanister gcr.io/kasten-images aggregatedapis gcr.io/kasten-images config gcr.io/kasten-images auth gcr.io/kasten-images bloblifecyclemanager gcr.io/kasten-images catalog gcr.io/kasten-images crypto gcr.io/kasten-images dashboardbff gcr.io/kasten-images executor gcr.io/kasten-images jobs gcr.io/kasten-images logging gcr.io/kasten-images metering gcr.io/kasten-images state gcr.io/kasten-images upgrade gcr.io/kasten-images cephtool gcr.io/kasten-images datamover gcr.io/kasten-images k10tools gcr.io/kasten-images restorectl gcr.io/kasten-images k10offline ","date":"2021-07-22","objectID":"/2021/07/k10offline-script-2/:3:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 05 - K10 安装包下载（2）","uri":"/2021/07/k10offline-script-2/"},{"categories":["Kubernetes"],"content":"前提条件 和上一篇中的脚本使用差不多，需要准备一台 Linux 服务器，在这台服务器上： 能够正常访问目标镜像库\u003ctarget\u003e; 安装了 jq 软件，可以使用 jq 命令，可以通过以下链接了解 jq； 安装了 docker，可以通过以下链接了解 docker； ","date":"2021-07-22","objectID":"/2021/07/k10offline-script-2/:4:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 05 - K10 安装包下载（2）","uri":"/2021/07/k10offline-script-2/"},{"categories":["Kubernetes"],"content":"使用方法 将上面对应版本下载到的文件，离线传送至 Linux 服务器上，使用以下命令加载镜像包至本地 docker 缓存： docker load \u003c kasten_k10_offline_images_4.0.8.tar.gz 加载后，可以通过以下命令，查看确认镜像状况： docker images 下载推送脚本： curl -O https://blog.backupnext.cloud/kasten_private_repo.sh 需要提醒的是，脚本下载后，请务必查看内容，确保正确再使用。 修改脚本执行权限： chmod +x kasten_private_repo.sh 脚本命令和参数： ./kasten_private_repo.sh \u003ck10-ver\u003e \u003ctarget repo\u003e 其中 k10-ver 是 k10 的版本，比如最新版本为4.0.8。 target repo 是目标私有镜像库，比如private.target.repo/kasten 举个例子，按照上面的配置，这条命令变成了： ./kasten_private_repo.sh 4.0.8 private.target.repo/kasten 运行这个命令，接下去 k10 的镜像就会自动上传至 private.target.repo/kasten 中，而在安装 k10 时，就可以使用这个私有镜像库了： helm install k10 k10-4.0.8.tgz --namespace kasten-io \\ --set global.airgapped.repository=private.target.repo/kasten --set metering.mode=airgap 以上就是今天的第二种离线安装方法。 ","date":"2021-07-22","objectID":"/2021/07/k10offline-script-2/:5:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 05 - K10 安装包下载（2）","uri":"/2021/07/k10offline-script-2/"},{"categories":["Kubernetes"],"content":"Kasten K10 入门系列目录 Kasten K10 入门系列 01 - 快速搭建 K8S 单节点测试环境 Kasten K10 入门系列 02 - K10 安装 Kasten K10 入门系列 03 - K10 备份和恢复 ","date":"2021-06-04","objectID":"/2021/06/k10offline-script/:1:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 04 - K10 安装包下载","uri":"/2021/06/k10offline-script/"},{"categories":["Kubernetes"],"content":"正文 K10 的下载很纠结，我相信习惯了 Veeam 软件的下载使用方式的朋友，一定会从各种程度上对于 K10 的下载和使用感觉到很不舒服。没错，这就对了，哪怕是像我这样下载 k10 软件超过 100 次以上的，也依旧觉得这种开源世界中的软件下载方式绝对是属于反人类的下载方式。 在 Kasten K10 的官网手册中，给出了软件的部署方式，然而这个软件竟然没有下载链接，原因可能是软件作者认为互联网畅通无阻，网络下载速度远大于本地磁盘速度，任何大小的软件都是下载无需等待的。然而，不巧的是，软件正好存放在 gcr.io 这样的普通人类无法访问的“火星”，这对普通人的使用造成了极大的阻碍。 好在 Kasten K10 还是考虑到了这一点，给出了一些看似还行的解决办法，比如使用 Jfrog artifactory 作为替换的镜像下载站。这对于在线安装来说，没有任何问题，有了这个镜像站，国内普通用户不用掌握特殊技巧就能完成在线安装了。 然而，当我们需要通过 Air-gap 方式，将镜像下载到自己私有的镜像库时，这时候就会发现 Jfrog artifactory 无法和 Kasten K10 官网手册中所提供的 offline 脚本一起配合使用了。不过没关系，我制作了个小脚本，可以实现利用非 gcr.io 来下载 kasten 镜像。 首先放上官网的 Air-gap 下载说明：官方下载方法说明 ","date":"2021-06-04","objectID":"/2021/06/k10offline-script/:2:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 04 - K10 安装包下载","uri":"/2021/06/k10offline-script/"},{"categories":["Kubernetes"],"content":"脚本使用前提条件 简单来说，这个脚本需要在 Linux 环境中运行，这个 Linux 机器需要有以下条件： 能够正常访问源镜像库\u003csource\u003e，脚本中内置了 Jfrog 的镜像库地址，如需修改请编辑脚本文件； 能够正常访问目标镜像库\u003ctarget\u003e; 安装了 jq 软件，可以使用 jq 命令，可以通过以下链接了解 jq； 安装了 docker，可以通过以下链接了解 docker； ","date":"2021-06-04","objectID":"/2021/06/k10offline-script/:3:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 04 - K10 安装包下载","uri":"/2021/06/k10offline-script/"},{"categories":["Kubernetes"],"content":"脚本使用方法 脚本下载： $ curl -O https://blog.backupnext.cloud/k10offline.sh 需要提醒的是，脚本下载后，请务必查看内容，确保正确再使用。 修改脚本执行权限： $ chmod +x k10offline.sh 脚本命令和参数： $ ./k10offline.sh \u003ck10-ver\u003e \u003ctarget repo\u003e 其中 k10-ver 是 k10 的版本，比如最新版本为4.0.3。 target repo 是目标私有镜像库，比如private.target.repo/kasten 举个例子，按照上面的配置，这条命令变成了： $ ./k10offline.sh 4.0.3 private.target.repo/kasten 运行这个命令，接下去 k10 的镜像就会自动上传至 private.target.repo/kasten 中，而在安装 k10 时，就可以使用这个私有镜像库了： $ helm install k10 k10-4.0.3.tgz --namespace kasten-io \\ --set global.airgapped.repository=private.target.repo/kasten ","date":"2021-06-04","objectID":"/2021/06/k10offline-script/:4:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 04 - K10 安装包下载","uri":"/2021/06/k10offline-script/"},{"categories":["Kubernetes"],"content":"Kasten K10 入门系列目录 Kasten K10 入门系列 01 - 快速搭建 K8S 单节点测试环境 Kasten K10 入门系列 02 - K10 安装 ","date":"2021-05-18","objectID":"/2021/05/k10-configuration/:1:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 03 - K10 备份和恢复","uri":"/2021/05/k10-configuration/"},{"categories":["Kubernetes"],"content":"正文 之前我介绍了 K10 的安装，整个安装过程其实就是一行helm install命令，在安装完成后，后续的使用可以通过浏览器打开 K10 的仪表盘，进行 K10 备份系统的配置、K10 备份策略管理和数据恢复。 和所有的备份系统一样，在开始备份工作之前，需要为 K10 配置一个数据存放的位置，用于存放备份数据。目前 K10 支持将数据存放至对象存储中，暂时还没加入 VBR Repository。在 K10 的 Settings 中可以找到 Locations 设置，这就是 K10 的备份存储库，在这个 Locations 中，如图使用 New Profiles 按钮即可。 新建时需要提供 S3 的访问地址、access key 和 secret key 就可以完成 Locations Profile 的配置了。在配置完成后，后续的备份策略设置中就可以将备份数据 Export 指向到这个备份存储库中。 在 K10 中，不需要去添加备份对象，K10 能够自动发现当前 K10 实例运行的 Kubernetes Cluster 中的所有 Application，这一点上，和以往的备份软件有很大的不同。 初始化的配置除了设置 Locations 之外，还需要去启用 K10 Disaster Recovery，只有启用了这一步操作后，K10 才能在当前 Kubernetes Cluster 出现任何故障时，恢复我们之前备份的数据。这个 Disaster Recovery 将当前群集中 K10 的备份 catalog 库储存到了对象存储中，群集出现任何问题，都可以在新的群集中恢复备份存档的 catalog，提取数据恢复。 配置 K10 DR 时，管理员需要将 K10 DR 启用后显示在屏幕上的 Cluster ID 记录下来，妥善保存好，用于后续的 K10 catalog 的恢复。另外，在启用 K10 DR 时，系统会提示输入一个“通行码（passphrase）”，用于在恢复时，创建 dr-secret。因此这个通行码也需要和 Cluster ID 一样，被妥善保管。 ","date":"2021-05-18","objectID":"/2021/05/k10-configuration/:2:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 03 - K10 备份和恢复","uri":"/2021/05/k10-configuration/"},{"categories":["Kubernetes"],"content":"备份 K10 的备份都是通过 Policy 来发起。在仪表盘正中间位置就是 Policy 相关的内容，包括显示当前的 Policy 总数和新建 Policy。 要保护一个 Application，需要管理员通过 new policy 来打开 Policy 的配置页面。如下图，在这个配置页面中需要填入一些相关信息才能完成备份策略的创建。 创建完成后，可以在 Policies 中查看到这个 Policy，并且可以通过 run once 来做一个单次备份作业的发起和运行，而正常情况，Policy 就会根据计划任务的设置，自动在设定的时间运行。 ","date":"2021-05-18","objectID":"/2021/05/k10-configuration/:3:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 03 - K10 备份和恢复","uri":"/2021/05/k10-configuration/"},{"categories":["Kubernetes"],"content":"恢复 数据完成备份后，可以在 Applications 中看到应用的状态变成了 Compliant 而在 Restore Points 中能看到不同的还原点。 选择还原点后，可以还原整个应用，也可以删除还原点。 以上就是本节内容 K10 的基本备份和恢复，完全图形化界面，使用非常简单。更多内容欢迎关注本系列后续更新。 ","date":"2021-05-18","objectID":"/2021/05/k10-configuration/:4:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 03 - K10 备份和恢复","uri":"/2021/05/k10-configuration/"},{"categories":["Kubernetes"],"content":"Kasten K10 入门系列目录 Kasten K10 入门系列 01 - 快速搭建 K8S 单节点测试环境 ","date":"2021-05-12","objectID":"/2021/05/k10-setup/:1:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 02 - K10 安装","uri":"/2021/05/k10-setup/"},{"categories":["Kubernetes"],"content":"正文 Kasten K10 的安装使用 Kubernetes 安装包管理工具 Helm，如果不熟悉 Kubernetes 的朋友可能不知道什么是 Helm，简单来说，Kubernetes 上的 Helm 来说就像 CentOS 上的 yum，有啥软件需要安装在 CentOS 上直接 yum install，而在 Kubernetes 上就是 helm install。 Helm 的命令和其他 Linux 命令一样，一大堆参数，看着就头疼，不过没关系，那么复杂的我们不用全明白，记住我下面的这几个关键的就足够玩转 k10 了： # 添加 chart $ helm repo add \u003crepo name\u003e \u003curl\u003e # 安装软件 $ helm install \u003cchart\u003e \u003crepo/chart\u003e --namespace \u003cnamespace name\u003e # 卸载软件 $ helm uninstall \u003cchart\u003e --namespace \u003cnamespace name\u003e 对于 k10 安装，几个关键要素分别是： Repo name （仓库名）: kasten Chart（软件名） : k10 URL（仓库地址）: https://charts.kasten.io/ Namespace name: kasten-io（默认值） ","date":"2021-05-12","objectID":"/2021/05/k10-setup/:2:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 02 - K10 安装","uri":"/2021/05/k10-setup/"},{"categories":["Kubernetes"],"content":"k10 起飞检查 当然，在安装前，因为各个用户的环境错综复杂，会产生各种不满足条件的情况，Kasten 提供了起飞检查脚本（pre-flight checks），用于帮助我们判断是否满足最基本的安装条件。简单来说，这个脚本跑完，看到上面是全绿的 Ok 状态，那么安装 k10 就完全没问题。 由于一些不可理解的网络问题，gcr.io 无法正常访问，官网手册中的起飞检查脚本就没办法正常运行，这里我提供修改过的脚本可以用于国内网络正常访问： $ curl https://blog.backupnext.cloud/k10_primer.sh | bash 这个 k10 起飞检查脚本还有一个 storageclass 检查专用参数，有需要的时候也可以针对创建好的 storageclass 做一系列体检： $ curl -s https://blog.backupnext.cloud/k10_primer.sh | bash /dev/stdin -s ${STORAGE_CLASS} ","date":"2021-05-12","objectID":"/2021/05/k10-setup/:3:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 02 - K10 安装","uri":"/2021/05/k10-setup/"},{"categories":["Kubernetes"],"content":"k10 安装 k10 基本上能够通吃所有 Kubernetes 的发行版，在官网手册上，对于像 AWS、Azure、Red Hat Openshift、Google Cloud、DigitalOcean 和 VMware vSphere 这些特殊的发行版，给出了一些特别的安装指导，大部分都是关于 service account 的。而除了这些之外的 Kubernetes 发行版，都可以按照通用安装方式来进行。 还是一样因为 gcr.io 无法访问，我们国内的网络对应到手册中去找一些步骤，就需要找 Air-Gapped Install 章节。安装步骤如下： 将安装脚本下载到本地，运行命令后，会在本地文件夹中看到一个叫 k10-4.0.2.tgz 的文件，其中 4.0.2 是当前最新的 k10 版本。 # 更新 helm 库，将 k10 的 chart 抓到本地来 $ helm repo update \u0026\u0026 \\ helm fetch kasten/k10 # 上面命令中，kasten 就是 repo 名字，而 k10 就是 chart 名字 在 Kubernetes 群集中创建 kasten-io 的 namespace。 # 创建名称为“kasten-io”的命名空间 $ kubectl create namespace kasten-io 使用国内镜像 ccr.ccs.tencentyun.com/kasten/ 安装 k10 的 4.0.2 版本。 # 使用 helm 安装 kasten k10 $ helm install k10 k10-4.0.2.tgz --namespace kasten-io \\ --set global.airgapped.repository=ccr.ccs.tencentyun.com/kasten # 上面命令中，k10 就是 chart 名字，而 repo 就没有指定，直接使用了下载下来的 tgz 压缩包中的内容，不需要再去 repo 中找相关 chart 了。 由于整个安装过程，会自动去指定的容器镜像库中抓取容器镜像，比如我们这个例子就是去腾讯国内镜像 ccr.ccs.tencentyun.com/kasten/ 中抓 k10 镜像，因此会需要等待一段时间，在这段等待的过程中，可以用以下命令来查询 k10 的所有 pod 的状态。 # 查询 k10 状态 $ watch -n 2 \"kubectl get pod -n kasten-io\" 等到所有 pod 状态都是 running 的时候，就可以 Ctrl+C 来终止这条命令了。 安装过程到此结束，接下去就是通过图形化界面来进行 k10 的使用了，访问 Dashboard 需要将 k10 的服务从 Kubernetes 中暴露出来，方法有很多，这里说一个最简单的，我自己测试时候最常用的。 # 后台运行命令，通过 kubectl 将 k10 仪表盘的网页服务发布出来。 $ kubectl -n kasten-io port-forward --address 0.0.0.0 svc/gateway 8080:8000 \u003e /dev/null 2\u003e\u00261 \u0026 通过网页浏览器访问 http://cluster ip:8080/k10/#/就能访问 k10，愉快的玩耍了。 好了，以上就是今天 Kasten K10 的第二课内容，感谢阅读，欢迎动手装一装玩一把。 ","date":"2021-05-12","objectID":"/2021/05/k10-setup/:4:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 02 - K10 安装","uri":"/2021/05/k10-setup/"},{"categories":[],"content":"Veeam Agent for MAC 随着 Veeam v11 版本推出，原本这个产品是集成在 VBR 之中，我也一直以为这个只能是被 VBR 统一管理才能使用，然而当我仔细阅读官网的 UserGuide 之后，发现在 Veeam Agent for MAC 竟然可以工作在 Standalone 模式下。惊喜之下，赶紧动手来玩了一把。 Veeam Agent for MAC 的安装包可以通过 VBR 中 Create Protection Group 向导获得，当然如果觉得太麻烦，可以直接到下面这个链接下载我已经提取出来的 pkg 安装包。 https://cloud.189.cn/t/eEZVvifyqIrm Veeam Agent for MAC 的 pkg 包安装相当简单，双击运行即可，和普通的其他 pkg 软件包完全一致，一路下一步即可。大约 3~5 分钟之内，备份软件就按照好了。在安装完毕后，需要进行初始化设置，因为属于第三方软件，按照 Apple 惯例，需要在系统偏好设置-\u003e安全性和隐私-\u003e隐私设置中为 Veeam Agent for MAC 启用完全磁盘访问功能，如图： Veeam Agent for MAC 遵循了极简的软件设计原则，整个软件由两部分组成，第一部分为 Command-line，命令行软件交互，用户备份作业设定以及所有软件功能的配置；第二部分为 Control Panel，图形化软件界面，主要用于数据还原和管理工作。在日常使用中，通常第一次配置完备份计划任务后，就不需要再使用命令行做任何操作了，需要恢复数据时只需要通过 Control Panel 中的 Restore 来进行数据还原即可。 ","date":"2021-04-04","objectID":"/2021/04/mac-agent/:0:0","tags":["backup"],"title":"Veeam Agent for MAC 单机版使用全攻略","uri":"/2021/04/mac-agent/"},{"categories":[],"content":"Command Line 命令行的 Veeam Agent for MAC 操作命令为： user@macOS-BigSur ~ % veeamconfig ","date":"2021-04-04","objectID":"/2021/04/mac-agent/:1:0","tags":["backup"],"title":"Veeam Agent for MAC 单机版使用全攻略","uri":"/2021/04/mac-agent/"},{"categories":[],"content":"第一步：设置 Repository Standalone 模式下，配置备份系统都在 MAC 上进行，因此需要为备份作业首先设置一个备份存放位置，一般来说可以是以下几种： 本地磁盘上某一个目录 外接移动硬盘 SMB 共享文件夹，远程的某个 NAS 目录 以 SMB 共享为例，可以使用以下命令创建一个备份存储库，在 Veeam 中通常都叫 Repository： user@macOS-BigSur ~ % veeamconfig repository create --name macbackup --type smb --location //\u003cip address or dns\u003e/sharefoldername/ --username adminuser --password 这里有几个关键参数： –name：后面跟着一个 Repository 的名称，可以随意设置自己希望的名称，但是需要注意的是这个名称在后面备份任务设定中会用到，不要忘记记下来。 –type：如果是共享文件夹，需要加这个参数，如果不是，就不需要了。但是这个参数如果使用的话，他后面的类型必须加上 smb，不能是其他的。 –location：远程 smb 路径，或者是本地某个目录。 –username 和–password：smb 访问专属 整个命令的意思是：创建一个备份存储库（veeamconfig repository create）, 存储库名称（–name）叫 “macbackup”，类型（–type）为“smb”共享文件夹，共享路径（–location）是“//IP 地址/共享文件夹名” ，访问这个共享需要使用用户名（–username）“adminuser”，访问这个共享需要输入密码（–password）。 ","date":"2021-04-04","objectID":"/2021/04/mac-agent/:1:1","tags":["backup"],"title":"Veeam Agent for MAC 单机版使用全攻略","uri":"/2021/04/mac-agent/"},{"categories":[],"content":"第二步：创建并运行备份作业 因为参数太多，这里不一一详解，举个最简单的例子，供大家参考： user@macOS-BigSur ~ % veeamconfig job create filelevel --name VeeamBigSur --reponame macbackup --includedirs /Users --daily --at 22:00 整句命令的意思是：创建一个文件级备份作业（veeamconfig job create filelevel），作业名称（–name）是“VeeamBigSur”，备份到（–reponame）“macbackup”这个存储库，备份所有“/Users”下面的目录和文件（–includedirs），每天（–daily）在（–at）晚上“22:00”执行备份。 如上，备份作业就创建好了，这时候可以通过 veeamconfig 进行进一步的备份作业查询和管理，可以参考官网 Veeam Agent for MAC 的 UserGuide，此处不再详述。 通常按照上面设置后备份作业就会按计划任务每天进行了，当然有临时需求可以发起临时备份任务。 ","date":"2021-04-04","objectID":"/2021/04/mac-agent/:1:2","tags":["backup"],"title":"Veeam Agent for MAC 单机版使用全攻略","uri":"/2021/04/mac-agent/"},{"categories":[],"content":"Control Panel Veeam Agent for MAC 在安装后，在 MAC 的应用程序中会有程序快捷方式，但是这个应用程序通常不需要运行，因为 Veeam Service 会在安装后自动运行在后台，而这个快捷方式的唯一作用是进行数据恢复，点击 Restore 后，就会出现如下图的文件级恢复界面，因为是 Standalone 模式运行，因此不支持 Restore Users。 ","date":"2021-04-04","objectID":"/2021/04/mac-agent/:2:0","tags":["backup"],"title":"Veeam Agent for MAC 单机版使用全攻略","uri":"/2021/04/mac-agent/"},{"categories":[],"content":"License 及工作模式 Veeam Agent for MAC 一共有 3 种许可模式，Server 版、Workstation 版和 Free 版，Standalone 模式属于 free 版，因此功能相对来说更简单一些，装上即可使用，无需导入任何许可，而当连接上 VBR 之后，则会由 VBR 分配许可变成 Server 版和 Workstation 版本来消耗许可发挥更强大的功能。 当然，果粉们肯定会问，这和 MAC 自带的 Time Machine 有啥区别呢，这就留给大伙儿自行探索吧，其实在我本人使用了 1 周后，两者之间区别还是蛮明显的，但是好在两者并行运行并不冲突，大家有兴趣可以试试看。 以上就是 Standalone 版本 Veeam Agent for MAC 的使用方法，更多内容欢迎阅读原文访问我的博客了解。 ","date":"2021-04-04","objectID":"/2021/04/mac-agent/:3:0","tags":["backup"],"title":"Veeam Agent for MAC 单机版使用全攻略","uri":"/2021/04/mac-agent/"},{"categories":[],"content":"我觉得这几天朋友们看了不少关于 Veeam 在 v11 中如何抵御勒索软件的方法，但是应该还是没有看够。方法是不是有点太单一？黑客们都在不断研究，我们 IT 管理员们怎么可以停下来。 今天我想给各位分享一个另类的数据存放方法，使用轮换移动硬盘的方法来存放 VBR 的备份数据。这个存放方法脑洞比较大，很少被管理员使用，通常这类轮换的方法会在光盘和磁带上用的比较多，而移动硬盘上几乎很少用。需要注意的是，这个方法并不是一种可以让您高枕无忧的方法，它更多的是给了你一种使用离线硬盘的野路子。 ","date":"2021-04-02","objectID":"/2021/04/rotated-driver/:0:0","tags":["backup"],"title":"野路子 - 用 Veeam 抵御勒索攻击的另类方法","uri":"/2021/04/rotated-driver/"},{"categories":[],"content":"场景和条件 一个方便硬盘插拔的移动硬盘盒，速度越快越好，一般来说现在 USB 3、USB-C 或者 eSATA 这类的接口都是不错的选择，USB 3 和 USB-C 会更通用一些。 多块大容量机械硬盘，可以使用 7200 转的 SATA 盘，一般和这些移动硬盘盒接口兼容。 备份数据按一定周期分别逐个写入硬盘中，备份管理员按一定周期取出硬盘，离线存放。 ","date":"2021-04-02","objectID":"/2021/04/rotated-driver/:1:0","tags":["backup"],"title":"野路子 - 用 Veeam 抵御勒索攻击的另类方法","uri":"/2021/04/rotated-driver/"},{"categories":[],"content":"实现效果 只要保证数据在离线前，没有被篡改被加密，那么离线后硬盘中的数据是妥妥的。 在各个硬盘上的备份数据自成一体，对于其他硬盘没有依赖性。 每个硬盘中的备份数据都有独立的元数据配置文件，用于数据使用时的信息读取。 相比磁带更有优势，数据使用和还原时更加直接。 ","date":"2021-04-02","objectID":"/2021/04/rotated-driver/:2:0","tags":["backup"],"title":"野路子 - 用 Veeam 抵御勒索攻击的另类方法","uri":"/2021/04/rotated-driver/"},{"categories":[],"content":"使用方法 来，直接上视频，戳下方视频，仔细观看。 看完后感觉如何？其实这个方法对于 Veeam Backup \u0026 Replication、Veeam Agent for Windows、Veeam Agent for Linux 都可以使用，赶紧可以来下载用用看哟。 ","date":"2021-04-02","objectID":"/2021/04/rotated-driver/:3:0","tags":["backup"],"title":"野路子 - 用 Veeam 抵御勒索攻击的另类方法","uri":"/2021/04/rotated-driver/"},{"categories":[],"content":"今天的内容非常简单，没太多技术含量，纯粹水一把。提醒大家做个备份，不管是个人的还是公司的，对于今天来说，一年一度的这个日子，做一个备份显得尤为重要。今天是世界备份日（World Backup Day）。 ","date":"2021-03-31","objectID":"/2021/03/world-backup-day/:0:0","tags":["backup"],"title":"保存美好回忆，就在此时此刻！","uri":"/2021/03/world-backup-day/"},{"categories":[],"content":"先来说说这个日子 也许有人还不太清楚这个日子咋回事。这个日子的由来也是网络发起的，有个叫 Ismail Jadun 的人，在 Reddit 上看了个某人数据丢失很后悔的帖子有感而发，顺手在 Reddit 上发帖，他觉得 3/31 不错，愚人节（4/1）的前一天，提前一天做好备份，不做愚人节那天的傻子。他的这个倡议在 2011 年得到了互联网上用户的广泛响应，在 2011 年 3 月 31 日那天很多人在互联网上宣誓承诺会备份他们的重要文件和美好回忆，并且还会将这个消息告诉周围的朋友和家人，希望每个人都有一份数据的备份。 这一日子，3 月 31 日，就这么被定下来，在每一年的这一天，互联网上大家都会来互相提醒，一年下来，如果还没备份的，那么趁着这个日子，赶紧把自己的数据做一份备份，哪怕是最简单的一个拷贝也好。 ","date":"2021-03-31","objectID":"/2021/03/world-backup-day/:1:0","tags":["backup"],"title":"保存美好回忆，就在此时此刻！","uri":"/2021/03/world-backup-day/"},{"categories":[],"content":"再来说说备份 有些什么内容我们需要备份？ 其实这个没有固定的要求，只要您觉得您的数据重要，不管是什么内容，那都值得备份，无论是一段文字、一张照片、一段音频还是一段视频。这些数据可能存在于您的手机、Pad、笔记本电脑甚至是 SD 卡中，别忘了，在今天，就是今天，赶紧做一份备份。 做备份可以非常简单，记住一个原则，3-2-1 数据保护黄金法则。最基本的方法就是，将您的数据往其他地方拷一份，拷 U 盘、拷移动硬盘和拷到家用 NAS 上都是很不错的方法，重视数据安全的同学可能会放好多份，这就是很好的践行了数据保护黄金法则。很朴实的方法，但是很有效！ 然而，当我们的设备越来越多的时候，特别是像博主这样的 IT 直男，在家中信息技术领域绝对是 CIO 的地位，管理着家中各个成员的各种设备和数据，这时候全家老小的数据备份绝不是一件简单的拷贝活。因此，在这里我向您隆重推荐 Veeam Backup 社区版软件，可以完成 30 台笔记本设备或 5TB 数据的备份，有了这套软件，家里大大小小的笔记本电脑，不管是 Windows 还是 MAC 系统都能使用它将数据集中备份下来，这个就会远比拷贝到移动硬盘方便的多了。 它的使用方法也很简单，开一台 Workstation 的虚拟机或者找个方便好用、访问便捷的公有云，开一台 Windows2019 服务器，将 Veeam Backup 社区版软件装上，装完以后使用 V11 中的新特性“Catch All 模式的 Veeam Agent”，可以获得一份客户端的安装包和配置文件，拿着这些安装包去各个笔记本上安装和配置吧，配置完成后就可以使用它进行备份了。 当然，如果觉得家中数据没有那么多，不需要安装庞大 Veeam Backup 社区版软件，也可以使用 Veeam Agent 免费版来保护 Windows 服务器，这依然能够从 Veeam 官网下载获取到。 好了，以上就是今天的内容，如果还没备份的，赶紧趁今天，把数据备一份，明天不会后悔！ ","date":"2021-03-31","objectID":"/2021/03/world-backup-day/:2:0","tags":["backup"],"title":"保存美好回忆，就在此时此刻！","uri":"/2021/03/world-backup-day/"},{"categories":[],"content":"勒索病毒自从 2017 年 5 月 12 日大规模爆发以来，在过去的 4 年里，也不断的自我进化，产生各种变种病毒，并且学会了各种弱点攻击，甚至是买通了门卫大叔。.. 但是不管怎么样，门卫大叔是我们最值得信赖的，是我们的最后一道防线，我今天就想来和大家聊聊如何基于这最后一道防线，来构建我们安全的备份数据环境。 ","date":"2021-03-22","objectID":"/2021/03/hardened-linux-repository/:0:0","tags":["VBR v11 实用技巧"],"title":"用了这个方法，您的备份数据再也不怕被勒索了","uri":"/2021/03/hardened-linux-repository/"},{"categories":[],"content":"实现效果 先来说说实现效果： 存放数据的设备我们选用大容量磁盘的机架式服务器，满配 SATA 硬盘，实现机架上容量密度最大化且每 TB 容量成本最低，这部分非常容易实现，咨询各大服务器厂商购买这样的服务器就行了。 这台机架服务器上线提供服务后，禁用所有账号的远程登录行为。唯一可访问的方式被限制在使用服务器上外接显示器、键盘和鼠标才能访问控制台。上架后对机柜进行上锁，控制机柜钥匙。 网络交换机和防火墙上，无需修改和设置这台服务器的任何访问，因为本身端口和服务的限制，这台服务器只被开放了 Veeam 服务用到的 2500-3300 的数据传输端口，这个数据传输链路仅限 Veeam Datamover 组件访问。 对于 Veeam 服务，只允许将数据写入到这个存储设备和从这个设备读取数据，而无法进行这些写入数据的修改和删除。 简单来说，就是这台设备只留了单通道使数据从 Veeam 进入这台服务器，进入后就被封起来了，只让外界通过 Veeam 的透明数据封存边界能读取数据并使用数据。 ","date":"2021-03-22","objectID":"/2021/03/hardened-linux-repository/:0:1","tags":["VBR v11 实用技巧"],"title":"用了这个方法，您的备份数据再也不怕被勒索了","uri":"/2021/03/hardened-linux-repository/"},{"categories":[],"content":"实现工具 非常简单，只需要 Linux 和 Veeam v11，任何 Veeam 版本都具备这个功能，包括社区版。在 v11 新产品特性中，它叫 Hardened Linux Repository。它有两部分功能组成： Single-use credentials for hardened repository 这个功能，用来完成对数据存储设备的初始配置，在初始配置时，会使用到一个单次使用的配置用途的账号，这个账号不会记忆留存于 Veeam 的任何服务上，并且在初始配置结束后，就可以禁用这个账号的远程访问以及 sudo 权限了。 immutable flag 这个功能，用来建立透明的数据封存边界，允许 Veeam 写入并读取数据，但是不允许 Veeam 来删除和修改已写入的数据。当然为了平衡容量，immutable 被设计成一个时间周期，指定周期内的短期数据才会进入封存边界内，而超过了这个周期的数据自动从边界内退出来，从而实现过期后可以被删除后释放空间。 ","date":"2021-03-22","objectID":"/2021/03/hardened-linux-repository/:0:2","tags":["VBR v11 实用技巧"],"title":"用了这个方法，您的备份数据再也不怕被勒索了","uri":"/2021/03/hardened-linux-repository/"},{"categories":[],"content":"配置方法 以下配置方法包括 Linux 服务器上的配置和 Veeam 存储库的配置，其中 Linux 以 Ubuntu 20.04LTS 为例子来说明，其他发行版请各位大拿自行修改。 Ubuntu Repository 预配置 创建用于一次性登录配置的用户。 admin@hardenedrepo:~$ sudo useradd -m veeamrepo admin@hardenedrepo:~$ sudo passwd veeamrepo 准备好相应备份空间格式化完成，并挂载到 Ubuntu 中的目录，比如/backupdata，请通过以下命令确认挂载结果。 admin@hardenedrepo:~$ df -h | grep /backupdata 赋予 veeamrepo 管理备份空间的权限。 admin@hardenedrepo:~$ sudo chown -R veeamrepo:veeamrepo /backupdata 修改 sudoers 配置文件，临时赋予 veeamrepo 用户 sudo 权限。 admin@hardenedrepo:~$ sudo vi /etc/sudoers 添加以下信息到 sudoers 文件后，保存。 veeamrepo ALL=(ALL:ALL) ALL 这样，Ubuntu 这边就算配置完成了，可以到 Veeam 中配置 Hardened Repository 了。 VBR 的配置 选择配置 Repository，配置类型为 Direct attached Storage -\u003e Linux。整个过程和以往普通的 Linux Repository 无任何区别，唯一不同的是，在配置 New Linux Server 的 SSH Connection 时，选择使用“Single-use credentials for hardened repository…”这个方式作为 Credentials 的选项，如下图： 填入 veeamrepo 的账号和密码，并允许自动提权使用 sudo。接下去其他步骤和普通 Linux 存储库添加完全一致。 在创建 repository 向导的 Repository 步骤中，勾选 Mark recent backups immutable for: xx days 的复选框，并在空格处填入具体的天数，如下图： 这样，VBR 中的 Repository 也配置完成，我们需要再回到 Ubuntu 中，做一些后续的进一步安全加固，来确保数据的安全。 Ubuntu 加固处理配置 重新修改/etc/sudoers 文件，取消 veeamrepo 用户的 sudo 权限，收回管理员权限。修改方法很简单，只需要将之前添加的内容前加上#注释即可。 关闭 ssh 服务，禁止任何用户通过 ssh 登录。 admin@hardenedrepo:~$ sudo systemctl disable ssh admin@hardenedrepo:~$ sudo systemctl stop ssh 关闭其他相关网络服务，不允许其他任何非 Veeam 应用的访问。 至此，所有配置完成，剩下的就是像使用其他普通存储一样，去使用这个存储库了，所有 Veeam 的功能，不管是备份、即时恢复、细颗粒度对象恢复、备份校验以及数据实验室，都不受任何影响。 以上就是今天的内容，更详细的配置过程，请参考官网的用户手册。 ","date":"2021-03-22","objectID":"/2021/03/hardened-linux-repository/:0:3","tags":["VBR v11 实用技巧"],"title":"用了这个方法，您的备份数据再也不怕被勒索了","uri":"/2021/03/hardened-linux-repository/"},{"categories":[],"content":"IT 管理员的绝佳搭档，完全免费！ 今天来给大家介绍 Veeam Software 的免费好工具，推荐给每一位 IT 管理员，Veeam 作为备份解决方案领域的领军者，除了有强大的旗舰产品 Veeam Availability Suite 之外，还为每一位 IT 管理员配备了全套的免费工具。这些工具完全没有任何广告、没有任何限制、可以随意使用，但是这又和开源软件有所不同，Veeam 称它们为社区版软件。 Veeam 的这些社区版软件和 Veeam 商业版全功能软件略有不同，部分高级产品功能上做了限制，并且许可使用数量上做了一些限制，关于详细的限制请查看官网，链接如下： https://www.veeam.com/cn/products-edition-comparison.html 然而，就算有这些限制，也无法阻挡无数管理员喜欢上这套强大的社区版软件。下面我就来和大家说说这套社区版软件 Veeam Backup \u0026Replication Community Edition 在管理员日常运维中可以做的一些事情，使用这些功能，完全不需要消耗任何的 Veeam 许可，包括内置的 10 个免费礼品许可，但是却能为我们的运维管理带来极大的便利。 ","date":"2021-03-09","objectID":"/2021/03/gift-from-veeam-free-community-edition/:0:0","tags":["VBR"],"title":"免费好工具，绝不套路","uri":"/2021/03/gift-from-veeam-free-community-edition/"},{"categories":[],"content":"功能一：VeeamZIP，来自 Veeam 的免费压缩软件。 这是 Veeam 产品的经典功能之一，在 Veeam 第一代产品出来后就一直深藏在 Veeam 产品中，作为产品的一个标配功能。从这个名字上我们就能猜出一二，它其实简单来说就是能够把一个 VMware 或者 Hyper-V 的虚拟机打包成一个压缩文件，变成一个 ZIP 包，这和我们平时打包压缩某些文件的做法完全一样，而恢复的时候，一样可以从这个压缩存档中解压出我们需要的原始数据。 然后，实际上 VeeamZIP 并不止这么简单，强大的功能也并未止步于 ZIP 包。VeeamZIP 使用了标准的 Veeam 备份引擎，只是它并不是普通的备份计划任务，它是一个完整的虚拟机全备份，你的每一次 VeeamZIP 操作都会触发备份引擎去对虚拟机执行一次全备份，并得到一份 vbk 全备份存档。 而在恢复时，这个 VeeamZIP 在 Veeam 中一样是一等公民，全套的恢复功能都可以使用，包括： 即时恢复，包括 v11 的跨平台恢复至 VMware 或 Hyper-V 即时磁盘恢复 整机还原 虚拟机磁盘还原 虚拟机文件还原 客户机细颗粒度文件对象还原 还原至 Amazon EC2 还原至 Microsoft Azure 更重要的是，VeeamZIP 是真正免费的功能，不消耗社区版中任何的内置 10 个实例的许可，您的环境无论是有 100 台 ESXi 主机、1000 台 VM 还是 1PB 的数据容量，您一样可以用社区版的 VeeamZIP 来为这些虚拟机创建压缩存档，没有任何限制。 ","date":"2021-03-09","objectID":"/2021/03/gift-from-veeam-free-community-edition/:0:1","tags":["VBR"],"title":"免费好工具，绝不套路","uri":"/2021/03/gift-from-veeam-free-community-edition/"},{"categories":[],"content":"功能二：存储快照的最佳搭档 存储快照集成是 Veeam 的高级功能，通常它会出现在 Veeam 的企业增强版中，而且因为配置略微复杂，不仅要了解虚拟化还要了解存储基础架构，因此很多刚入门的管理员通常不太会用到这个功能。 然而，假如您的存储是 NetApp、Dell EMC SC 或 Unity、HPE 3PAR 或 Nimble、联想 V 系列或 DM 系列、以及华为的 OceanStore 系列存储，您完全可以免费无限制的使用社区版中的存储快照恢复功能。这一功能，将会极大的扩展这些存储在虚拟化环境中的能力，借助 Veeam 的存储快照解析和恢复能力，任何这些存储上执行的卷快照都可以用于 Veeam 的全功能恢复技术，包括： 从卷快照中执行单台即时虚拟机恢复； 从卷快照中执行单个虚拟磁盘即时恢复； 从卷快照中恢复客户机操作系统的细颗粒度文件； 从卷快照中恢复应用程序对象，包括 SQL、Oracle、Exchange、AD 等。 这一恢复能力，一样是因为没有备份任务，不需要 Veeam 执行备份作业，对于广大的快照用户来说是完全免费，无论您的环境有 100 台 ESXi 主机、10 台企业级存储、1000 个虚拟机，还是 1PB 数据使用这个功能恢复存储快照中的数据，完全免费。可以说是为这些存储额外提供了强大的增值功能。 所以，别在说存储快照不好用了，还没用存储快照的，可以赶快动手试试看吧！ ","date":"2021-03-09","objectID":"/2021/03/gift-from-veeam-free-community-edition/:0:2","tags":["VBR"],"title":"免费好工具，绝不套路","uri":"/2021/03/gift-from-veeam-free-community-edition/"},{"categories":[],"content":"功能三：免费磁带机/库管理工具 买个磁带机，通常来说必须配个昂贵的备份软件才能配套使用，很多备份软件对于磁带的使用还按驱动器进行收费，加一个驱动器动不动就是大几十万的授权许可费用。 在 Veeam 社区版中，磁带机/库的管理和使用完全免费。管理员可以使用 File to Tape 功能，将数据写入磁带中。重点是，和上两个能力一样，无论您的环境有 1 台磁带机、10 台磁带机、10000 盘磁带、1 千万个文件还是 1PB 的数据，使用 Veeam 的磁带机/库管理，授权完全免费，无限量使用。 所以，下次买了磁带机之后，别傻乎乎的再去为了一个文件写磁带功能买昂贵的配套软件啦，一个 Veeam 社区版软件就足够了。 ","date":"2021-03-09","objectID":"/2021/03/gift-from-veeam-free-community-edition/:0:3","tags":["VBR"],"title":"免费好工具，绝不套路","uri":"/2021/03/gift-from-veeam-free-community-edition/"},{"categories":[],"content":"功能四：Veeam 初代旗舰 FastSCP 这个功能可能对于绝大多数人都非常陌生，甚至是接触了多年 Veeam 的老鸟都可能完全不知道它的存在。然而如果您是 Veeam 的死忠粉，从 2008 年就开始关注 Veeam，也许就不会陌生。是的它就是 Veeam 公司初创时候的第一款产品，Veeam FastSCP。 https://www.veeam.com/vmware-esxi-fastscp.html 这款产品曾经有单独的软件包，而现在，它藏身于 VBR 社区版的 Files 视图下。在 Files 视图中，上面的所有操作都是标准的 Veeam FastSCP 内容，在这里受管理的任意一台 Server 节点都可以利用 FastSCP 的能力轻松的完成数据的传递。Veeam 能够在这些受 Veeam 管理的节点中的数据通过 Veeam 的数据传输服务轻松的传递到数据的目的地。 更强大的功能是，对于 VMware 的虚拟机文本配置文件，比如 VMX、VMDK 描述文件等，FastSCP 还提供了在线编辑功能，管理员再也不需要打开 ESXi Shell 进入控制台去修改这些数据了。 这个功能，对于所管理的节点，也没有任何的数量限制，管理员可以自由的使用 FastSCP 来传输数据。 ","date":"2021-03-09","objectID":"/2021/03/gift-from-veeam-free-community-edition/:0:4","tags":["VBR"],"title":"免费好工具，绝不套路","uri":"/2021/03/gift-from-veeam-free-community-edition/"},{"categories":[],"content":"功能五：VMware vMotion 的替代方案 Quick Migration 作为 VMware 管理员，往往会有很尴尬的时候，VMware vMotion 总有某一场景下，不合适使用的时候，这时候在没有合适的工具时，是迁好呢还是不迁好呢？ 不用担心，免费的 Veeam 社区版来帮忙，vMotion 搞不定的，Quick Migration 来搞。付出一点点代价，获得最终迁移完成的结果，然而又是不需要任何产品许可，可以免费无限量使用的解决方案。 以上五大功能，如果您用上了，我坚信 Veeam 社区版软件一定会常驻于您的 IT 基础架构之中，它能为 IT 运维带来极大的便利性，堪称虚拟化环境的最佳搭档。 当然，您如果喜欢 Veeam 的技术，认为 Veeam 很适合您的环境，可以选择社区版上可以直接点击的按钮，寻找适合的途径直接联系到我们，升级到 Veeam Backup Essentials 或者 Veeam Availability Suite。 ","date":"2021-03-09","objectID":"/2021/03/gift-from-veeam-free-community-edition/:0:5","tags":["VBR"],"title":"免费好工具，绝不套路","uri":"/2021/03/gift-from-veeam-free-community-edition/"},{"categories":[],"content":"前言 2 月 25 日，Veeam 推出全新的 v11 版本，在去年，我曾经写过一篇升级到 v10 的帖子，其实本次 v11 的升级和之前的 v10 升级没有太多的差别，今天的内容，我将之前的这个帖子提到的做一些针对 v11 的调整，算是一些些小更新吧。 ","date":"2021-03-03","objectID":"/2021/03/how-to-upgrade-vbr-v11-edition/:1:0","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2021/03/how-to-upgrade-vbr-v11-edition/"},{"categories":[],"content":"升级前 请按照下面的流程图检查当前环境，在升级 VBR 之前确保其他组件已经正常升级。 v11 完全兼容之前 v10 的 VUL 许可，因此已经在使用 VUL 许可的，可以完全不需要准备或者导入许可文件。 ","date":"2021-03-03","objectID":"/2021/03/how-to-upgrade-vbr-v11-edition/:1:1","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2021/03/how-to-upgrade-vbr-v11-edition/"},{"categories":[],"content":"升级方式 可以采用两种方式升级，没有太大区别。 在原 VBR 服务器上原地升级； 全新安装一台 VBR 服务器，然后将 Configuration Backup File 还原至这台全新安装的 VBR 中。 由于第二种方式和全新安装几乎没有任何区别，因此本文不详细展开讨论，而只讨论第一种原地升级方式。 ","date":"2021-03-03","objectID":"/2021/03/how-to-upgrade-vbr-v11-edition/:1:2","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2021/03/how-to-upgrade-vbr-v11-edition/"},{"categories":[],"content":"升级准备 准备好 Veeam 升级介质，Veeam 的产品非常简单，升级介质和全新安装使用同一个介质包，只需要把产品包挂载到 VBR 服务器上即可。在执行 Upgrade 之前，需要做一系列准备工作： 仔细阅读 Release Notes，检查自己环境，看看是否有不支持的系统。 - VMware vSphere 5.1 以及之前的版本 - Windows 2003 和 XP - Microsoft SQL Server 2005 使用 Veeam Configuration Backup 功能，将 VBR 的配置做一个备份，这个备份请确保是用 Encrypted 模式，这样所有在 VBR 中使用的用户名和密码将会妥善的被保存在。bco 文件中。 检查 VBR 上面的所有备份作业，确保没有任何作业正在运行，这里要特别注意如下作业，需要手工点击 Disable 来停止： - Backup Copy Job - SQL、Oracle 的日志备份作业 ​ 看看是否有 Instant VM Recovery 正在运行； ​ 看看是否有 Veeam Explorer 正处于打开并在执行恢复； ​ 看看是否有 Surebackup/Virtual Lab 正在运行。 最终，所有任务都停止后，会是如下图状态： ","date":"2021-03-03","objectID":"/2021/03/how-to-upgrade-vbr-v11-edition/:1:3","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2021/03/how-to-upgrade-vbr-v11-edition/"},{"categories":[],"content":"升级过程 整个升级过程非常简单，只需要按照向导点击几下鼠标，然后静静的等待 30 分钟以后，软件就能升级完成，因此在这里我就不详细去一步一步说明这个过程了。 ","date":"2021-03-03","objectID":"/2021/03/how-to-upgrade-vbr-v11-edition/:1:4","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2021/03/how-to-upgrade-vbr-v11-edition/"},{"categories":[],"content":"可能碰到的问题 升级过程中，升级包会首先停止 VBR 的所有服务，有可能碰到停止服务超时或者失败，导致升级过程中断，建议碰到失败后首先检查下 Services.msc 中 veeam 开头的服务是否被正常停止。 服务都正常停止后，原地升级如果还报错，建议可以把 VBR 服务器重启一下后，再尝试升级，这里特别注意一下，在 VBR 重启后，需要重新检查所有 VBR 的作业，确保没有作业在自动运行。 如果尝试多次都无法进行正常升级，建议使用上面提到的方法二，全新安装一台 VBR，然后将 Configuration backup 文件导入。 如果以上方法全部失败，请及时联系 Veeam Support 团队，我们的攻城狮将会及时为您提供升级支持。 以上就是升级的一些小提示，感谢阅读！ ","date":"2021-03-03","objectID":"/2021/03/how-to-upgrade-vbr-v11-edition/:1:5","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2021/03/how-to-upgrade-vbr-v11-edition/"},{"categories":["VMware"],"content":"下周，Veeam 即将发布旗舰产品 VAS 套件全新的 v11 版本，在这个版本中最重要的一个功能就是 Veeam CDP。我相信不少朋友期待这个功能已经很久了，而事实上 Veeam 通过接近 5 年的精雕细琢，终于在 v11 中正式发布了这个功能。由于这个 CDP 功能在使用 VMware 相关技术时和以往的备份复制有很大的不同，今天我想带大家提前来做一些准备，介绍一些 CDP 背后使用的 VMware 相关技术和 API 接口，以帮助大家更好的理解这个 CDP 技术。 ","date":"2021-02-19","objectID":"/2021/02/vmware-vaio-overview/:0:0","tags":["Veeam CDP"],"title":"VMware VAIO 技术概览","uri":"/2021/02/vmware-vaio-overview/"},{"categories":["VMware"],"content":"vSphere APIs for I/O filtering 简介 Veeam CDP 使用的是 VMware vSphere APIs for I/O Filtering （VAIO）技术，这个技术早在 vSphere 6.0U1 的时候就发布了第一版，而到了 vSphere 6.5 开始这个技术逐渐成熟。简单来说，VAIO 是一个框架，它可以为使用这个框架的一系列应用程序提供在虚拟机 I/O 路径中插入 I/O 过滤器（I/O Filters）的能力。而这些 I/O 过滤器则可以在 I/O 路径中来捕获虚拟机的 I/O，从而实现在 I/O 写入物理磁盘前的各种处理。 VMware 定义了 I/O 过滤器的 4 种使用场景，分别是： 复制 (Replication) 缓存 (Caching) 存储 I/O 控制 (Storage I/O control) 加密 (Encryption) 其中存储 I/O 控制和加密这两种场景目前仅限于 VMware 自己使用，而复制和缓存这两种场景则开放给第三方厂商制作第三方的解决方案。和备份解决方案利用 VADP 接口一样，利用 VAIO 接口的第三方解决方案同样会通过严格的 VMware Ready 认证，认证之后可以在 VMware 官网上查询到第三方组件的兼容性列表。 ","date":"2021-02-19","objectID":"/2021/02/vmware-vaio-overview/:1:0","tags":["Veeam CDP"],"title":"VMware VAIO 技术概览","uri":"/2021/02/vmware-vaio-overview/"},{"categories":["VMware"],"content":"vSphere APIs for I/O filtering 技术原理 VAIO 由两部分组成，一部分是 VMware 端的 VAIO 过滤器框架 (VAIO Filter Framework)，这部分是 VMware 在每个 ESXi 中标准化提供的内容，从 vSphere 6.0U1 以后就已经内置在 ESXi 核心中了；另外一部分是 I/O 过滤器，这些过滤器都会在 VAIO 过滤器框架中逐个运行。如下图，一台虚拟机在运行时，它的 I/O 路径会从客户机操作系统 (GuestOS) 经过 VAIO 过滤器框架再进入 VMDK 之中，而在经过 VAIO 过滤器框架的时候，会逐个逐个被框架定义好的过滤器进行处理，当 VAIO 过滤器框架中所有的过滤器都完成处理后，这个 I/O 请求就会被移到最终的 VMDK 中。 很显然，通过上面这个过程，大家可以看到，VAIO 工作的时候是针对某一台虚拟机的，VAIO 框架为每台虚拟机定义了各自可以使用的过滤器，因此每台虚拟机在各自的 I/O 路径上如果发生任何的 I/O 错误，甚至是过滤器层面的错误，也被严格的隔离在这台虚拟机之内，并不会影响整台 ESXi 以及其他虚拟机。 另外，VAIO 框架还做了一些限定，I/O 过滤器根据使用场景对应定义了 4 个大类，在每台 ESXi 上每一类的 I/O 过滤器只能同时存在一个。比如，对于复制类的 I/O 过滤器，如果 Veeam 提供的 CDP 过滤器已经存在，那么其他厂商的过滤器就无法在这台 ESXi 上进行安装了。 ","date":"2021-02-19","objectID":"/2021/02/vmware-vaio-overview/:2:0","tags":["Veeam CDP"],"title":"VMware VAIO 技术概览","uri":"/2021/02/vmware-vaio-overview/"},{"categories":["VMware"],"content":"vSphere APIs for I/O filtering 管理技巧 通常来说，除了内置的 I/O 过滤器之外，第三方的 I/O 过滤器一般都会由第三方厂商提供集成安装服务，因此在 vSphere Client 中并无相关的安装按钮。然而，在 vSphere Client 中，管理员可以很方便的找到自己的 Cluster 和 ESXi 上的 VAIO 部署和使用情况，了解当前的状态。 ","date":"2021-02-19","objectID":"/2021/02/vmware-vaio-overview/:3:0","tags":["Veeam CDP"],"title":"VMware VAIO 技术概览","uri":"/2021/02/vmware-vaio-overview/"},{"categories":["VMware"],"content":"在 Cluster 中查看 选中需要查看的 Cluster，找到右边的 Configure 标签，然后可以在 Configuration 节点下找到 I/O Filters 来查看当前群集中 Filters 的安装状况，如下图。 ","date":"2021-02-19","objectID":"/2021/02/vmware-vaio-overview/:3:1","tags":["Veeam CDP"],"title":"VMware VAIO 技术概览","uri":"/2021/02/vmware-vaio-overview/"},{"categories":["VMware"],"content":"在 ESXi 中查看 选中需要查看的 ESXi，找到右边的 Configure 标签，然后可以在 Storage 节点下找到 I/O Filters 来查看当前 ESXi 上 Filters 的安装情况，如下图。 在 ESXi 上和在 Cluster 上看到的 I/O 过滤器情况略有不同，在 ESXi 上可以看到 VMware 自己使用的两种过滤器类型，其中 spm 是数据存储 I/O 控制用的过滤器，vmwarevmcrypt 则是加密用的过滤器。 特别要注意的是，在图中显示的 Type 列中会列出各个过滤器的类型，每种类型有且只能有一个过滤器。 ","date":"2021-02-19","objectID":"/2021/02/vmware-vaio-overview/:3:2","tags":["Veeam CDP"],"title":"VMware VAIO 技术概览","uri":"/2021/02/vmware-vaio-overview/"},{"categories":["VMware"],"content":"I/O 过滤器存储策略 I/O 过滤器的使用必须配合着 vSphere 中 VM Storage Policy 来进行，通常来说在 I/O 过滤器的使用过程中，第三方软件会全自动来配置相关的 VM Storage Policy，而配置完成后，在 vSphere Client 的 VM Storage Policy 中能找到配置好的 VM Storage Policy，比如 Veeam CDP 的过滤器，如下图： 当虚拟机使用了 I/O 过滤器进行处理后，可以选中某个虚拟机，找到 Configure 标签，在 Policies 节点下，能看到当前的 Policies 使用和分配情况，如下图： ","date":"2021-02-19","objectID":"/2021/02/vmware-vaio-overview/:3:3","tags":["Veeam CDP"],"title":"VMware VAIO 技术概览","uri":"/2021/02/vmware-vaio-overview/"},{"categories":["VMware"],"content":"vSphere APIs for I/O filtering 安装排错技巧 VAIO 由框架和过滤器组成，框架方面集成在 ESXi 内，天然具备；因此绝大多数可能碰到的问题都会集中在过滤器方面，特别是过滤器的安装过程，会有可能碰到一些挑战。然而这个过滤器的安装其实就是一个标准的 ESXi VIB 软件包的安装，这时候碰到的问题其实也相当简单，可以做如下检查和排错： VIB 软件包 URL 是否能够正常被访问？ 厂商提供的 VIB 软件包是否正确？ 升级和卸载过程中 VIB 软件包要求的 ESXi 主机维护模式状态是否正确？ VIB 软件包安装后可能会要求 ESXi 主机重启 自动切换维护模式过程中，切换失败？ 和其他同类过滤器的 VIB 软件包冲突？ 关于已经安装好的软件包的状况，可以通过选中 ESXi，在右边的 Configure 标签中，找到 System 节点下的 Packages 来查看 VIB 软件包的清单，如下图。 以上就是今天的内容，希望这些内容能够对大家后面了解 Veeam CDP 有所帮助。 ","date":"2021-02-19","objectID":"/2021/02/vmware-vaio-overview/:4:0","tags":["Veeam CDP"],"title":"VMware VAIO 技术概览","uri":"/2021/02/vmware-vaio-overview/"},{"categories":["Kubernetes"],"content":"Release Notes: v1.2 2021/06/04 - 加入本地 Registry，内置 K10 v4.0.3 镜像，可以在安装 k10 时使用--set global.airgapped.repository=localhost:5000 来直接调用本地的 docker 镜像库 Virtual Appliance 版本更新为 v1.2，对应网盘中文件为： UbuntuK10-v1.2.ova Release Notes: v1.1 2021/05/03 日 - 尝试了 Stateful MySQL 的部署，将一体机中内置的 Demo 应用改成了 Helm 安装的 MySQL，这样，可以通过这个 vApp 来快速 Demo 和测试有状态应用的备份和恢复。 Virtual Appliance 版本更新为 v1.1，对应网盘中文件为： UbuntuK10-v1.1.ova 自从 Veeam 收购 Kasten 之后，最近玩 K8S 特别多，最大的体会是，茫茫多的各种命令和对互联网的强烈需求，假如连不了网，特别是连不了国外的容器镜像站点时，通常的情况就是抓瞎，啥都干不了。当然，这在各位 K8S 和容器大拿眼里，并不是什么问题，而对于广大非软件开发专业的系统管理员和系统工程师来说，挑战着实不小。 要搭建一套 Kasten K10 的 Lab 环境，其基础条件是 K8S 群集，Kasten K10 是原生的云应用，它赖以运行的环境和备份恢复的对象都是 K8S。因此，摆在我们面前的难题变成了简单快速不费劲的搭建一套 K8S 环境并且部署一个简单的有状态应用。这在没有网络的情况下，实在是太为难了。不过，办法总比困难多，不是吗？这点小小的阻碍完全难不倒熟练使用虚拟化技术的虚拟化管理员，在做了一番功课之后，我借鉴了 Veeam 日本的同事分享的快速部署脚本，使用了虚拟化中独特的 OVF（Open Virtualization Format）方式，将这个过程封装成了一个虚拟一体机（Virtual Appliance），让这个 Demo Lab 的搭建过程大大简化，实现了不需要任何网络下载，即可搭建出这样一套单节点群集，并且内置了包含 MySQL 数据库的 WordPress 应用。 先放上这个虚拟一体机的下载链接： https://cloud.189.cn/t/mAnyMrA36vam（访问码：wd69） 需要说明的一点是，这个虚拟一体机为个人测试研究所用，不得用于任何商业目的，本人不保证这个设备的安全性、可靠性和稳定性，请各位使用者自行判断。 ","date":"2020-12-07","objectID":"/2020/12/setting-up-quick-demo-for-k10-01/:0:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 01 - 快速搭建 K8S 单节点测试环境","uri":"/2020/12/setting-up-quick-demo-for-k10-01/"},{"categories":["Kubernetes"],"content":"虚拟一体机使用说明： 熟练使用 VMware 虚拟化的管理员，可以将该 OVA 文件导入到 VMware vSphere 或者 VMware Workstation，导入过程中，导入向导会提示配置网络和 IP 地址信息如下图，特别注意其中 Netmask 需要用 CIDR 格式： 在导入完成后，虚拟一体机的首次启动中，会自动配置设备的 IP 地址。等到配置完成后，可以使用 ssh 连接登入系统进行 K8S 环境的基础配置。访问的初始用户名密码为： username: k10 Password: P@ssw0rd 进入系统后，使用sudo -i命令进入 root 用户。 K8S 群集初始化需要按顺序执行/root/目录下的 5 个脚本文件，分别是： 0-minio.sh 1-createk8s.sh 2-loadimage.sh 3-storage.sh 4-wordpress.sh 脚本执行过程中所涉及到的需要用到的相关文件，我已经全部放置在/root/目录下了，脚本会自动调用这些文件。 ","date":"2020-12-07","objectID":"/2020/12/setting-up-quick-demo-for-k10-01/:1:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 01 - 快速搭建 K8S 单节点测试环境","uri":"/2020/12/setting-up-quick-demo-for-k10-01/"},{"categories":["Kubernetes"],"content":"这些脚本都用来干啥？ 0-minio.sh 这个脚本会使用开源对象存储领域第一块招牌 minio(https://minio.io) ，创建出一套本地的对象存储，命令执行后，对象存储就运行起来了，可以通过 https://\u003c虚拟一体机 IP\u003e:9000 来访问对象存储的 web 界面，web 界面的初始用户名密码： username: minioadmin Password: minioadmin 1-createk8s.sh 这个脚本是使用 Kind 技术（K8S in Docker），在容器中运行 K8S 的节点来快速部署 K8S 的群集，K8S 所用到的容器镜像已经提前被内置在这个一体机中，因此不需要去网上下载 1.3G 左右的 K8S docker 镜像。可以在运行脚本之前通过以下命令来确认 K8S docker image 已经就位： $ docker images list | grep kind 在脚本运行完成后，就可以正常使用 kubectl 的命令来查看所有 K8S 的资源了，这时候 kubectl 的所有命令都能正常使用了。比如，你可以试试这个： $ kubectl get nodes 2-loadimage.sh 这个脚本其实没什么特别秘密，纯粹是为后面第四第五个脚本做准备，它会将本地的 docker 镜像 push 到localhost:5000这个本地镜像库中，同时将内置在本地 Ubuntu 中的部分 docker images 加载到 Kind 中，供 Kind 使用。 3-storage.sh 这个脚本为 K8S 群集创建本地的 CSI Hostpath driver，其用到的脚本可以在（https://github.com/kubernetes-csi/csi-driver-host-path）中找到，我对这个脚本要用到的互联网下载链接做了修改，更改为所有 yaml 文件都用本地/root/文件夹中的文件，并且对于这个脚本中用到的所有 docker image，也提前从互联网上 pull 下来并在上一步加载至 Kind 中。 在运行脚本前，可以通过以下命令查询部署前的 storage class： $ kubectl get sc 在脚本运行完成后，可以通过再次运行这个命令，查看到新配置好的 storage class。 另外，这一步中会部署多个 pod 到 default 的 namespace，查看这一步部署状况的另外一个有用命令为： $ kubectl get pod 4-wordpress.sh 该脚本作用也很简单，部署一个 WordPress 应用，内置 Stateful 的 MySQL 数据库，部署完成后，需要运行以下命令进行端口转发后，使用浏览器访问以下地址进行后续配置 http://\u003c虚拟一体机 IP\u003e。 $ kubectl port-forward --address 0.0.0.0 svc/wordpress 80:80 -n wordpress 以上就是这个虚拟 k8s 一体机的简要使用说明，在部署完这套环境后，即可使用（https://docs.kasten.io）上的文档进行 Kasten 的正常安装配置使用了。 ","date":"2020-12-07","objectID":"/2020/12/setting-up-quick-demo-for-k10-01/:2:0","tags":["Kubernetes"],"title":"Kasten K10 入门系列 01 - 快速搭建 K8S 单节点测试环境","uri":"/2020/12/setting-up-quick-demo-for-k10-01/"},{"categories":["数据保护"],"content":"自从年初 Veeam Agent for Linux 4.0（简称 VAL）随着 VBR V10 推出以来，这个功能越来越强大的备份代理使用也越来越广，不管是云上还是云下、虚拟还是物理，总有场景会用到 VAL。然而我们发现对于刚刚接触 VAL 的朋友们其实还是会受到这个代理安装过程的困扰，就算是全自动的推送安装，依然会有朋友会碰到各种各样的安装问题。这让本来以使用体验极佳著称的 Veeam 备份软件变得很尴尬，“It just works!”的口号都不敢随便喊了。 其实，Veeam 还是那么简单，VAL 一样是这种简单极致的体验，就算是在大众门槛略高的 Linux 开源世界，只需要稍稍注意，就可以体验到 VAL 的极致简单使用体验。当然这需要一点点小技巧，对于熟练使用 Linux 的朋友，这些都不是问题，而对于不少只是因为要备份才接触 Linux 的备份管理员来说，会略有一些挑战。这主要原因是来自于 VAL 的软件安装依赖包，和 Windows 不一样的是，Veeam 在所有 Windows Server 所需要安装的依赖包都集成在 Veeam 软件中，VBR 会全自动的去推送所有缺失的依赖包。而对于 Linux 来说，在 Veeam 软件包中其实并不包含任何的依赖包，所有这些依赖包都来自于 Linux 系统本身的 Software Package Manager，这里要划个重点！ 什么是 Package Manager？ 打个比方，这个就是和手机的应用市场类似，每一个 Linux 系统都内置了这样的 Package Manager，而不同发行版的 Linux 可能会使用不一样的 Package Manager。Package Manager 非常的智能，通常在主流的 Linux 发行版中安装软件最简单的方法就是通过 Package Manager 的一行命令就完成了，Package Manager 会全自动的完成所有依赖组件的安装，最终交付相应软件给管理员使用。 在 VAL 支持的多种操作系统中，不同的系统使用不同的 Package Manager，下面就是这些系统所对应使用的 Package Manager 清单。 Linux 发行版 默认常见的 Package Manager CentOS/Redhat/Oracle Linux/Fedora yum Debian/Ubuntu Apt SLES/openSUSE zypper 很显然，不管使用什么方式，我们要正常安装 VAL，第一个前提条件就是 Package Manager 能够正常的工作，这个在有互联网连接的 Linux 系统中，完全没问题，绝大多数情况下系统安装完成后就自带了合适的软件安装源；然而在无法访问互联网的服务器数据中心，如果没有合理配置内部源，就会碰到各种报错了。处理方法也很简单，只需要去对应的 Linux 发行版的官网，下载当前版本的最新版 ISO，并制作成本地源即可。比如，CentOS6.x 就下载 CentOS 6.10 的 iso，CentOS 7.x 就下载 CentOS 7.8.2003 的 iso 镜像，然后挂载到 CentOS 中。本文以常见的 CentOS 7.6 为例说明下这个配置的全过程。 首先找一个 CentOS 7.8.2003 的镜像下载点，比如阿里云的 https://mirrors.aliyun.com/centos/7.8.2003/isos/x86_64/ 在 CentOS 中，挂上这个刚刚下载到的镜像。 [centos@localhost ~]$ sudo mkdir /mnt/cdrom [centos@localhost ~]$ sudo mount /dev/cdrom /mnt/cdrom 备份并移动/etc/yum.repo.d/CentOS-Base.repo，确保系统不使用默认互联网上的 yum 源。 [centos@localhost ~]$ sudo mv /etc/yum.repo.d/CentOS-Base.repo ~/CentOS-Base.repo 编辑/etc/yum.repo.d/CentOS-Media.repo，其中需要修改 baseurl 字段和 enabled 字段。baseurl 指向本地源的 iso 路径，为第二步中挂载的路径/mnt/cdrom；enabled 为启用这个源配置文件。 [centos@localhost ~]$ sudo vi /etc/yum.repo.d/CentOS-Media.repo # CentOS-Media.repo # # This repo can be used with mounted DVD media, verify the mount point for # CentOS-7. You can use this repo and yum to install items directly off the # DVD ISO that we release. # # To use this repo, put in your DVD and use it with the other repos too: # yum --enablerepo=c7-media [command] # # or for ONLY the media repo, do this: # # yum --disablerepo=\\* --enablerepo=c7-media [command] [c7-media] name=CentOS-$releasever - Media baseurl=file:///mnt/cdrom/ gpgcheck=1 enabled=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 ~ \"/etc/yum.repos.d/CentOS-Media.repo\" 22L, 630C 配置完成后，执行 yum clean all 和 yum makecache 命令更新 yum 信息并检查可用性，用 yum repolist 列出本地源详细信息。 [centos@localhost ~]$ sudo yum clean all [centos@localhost ~]$ sudo yum makecache [centos@localhost ~]$ sudo yum repolist 接下去，回到 VBR 中，不管是使用 VBR 的推送 VAL 安装还是手工执行 standalone 版本的 VAL 安装，都将会畅通无阻，所有缺失的依赖包，VBR 会让 yum 自动去光盘镜像中找相关的内容安装上。 以上就是今天的推送，希望帮到那些刚接触 Veeam Agent for Linux 的朋友们。另外，近期我推出了一个全新的每日一图的公众号，在那边大家能够每天收到一个非常简单的 Veeam 操作示例，帮助大家快速了解配置 Veeam 的方法，也欢迎大家关注。 ","date":"2020-09-22","objectID":"/2020/09/veeam-linux-agent-101/:0:0","tags":["VBR"],"title":"Veeam Agent for Linux 基础知识","uri":"/2020/09/veeam-linux-agent-101/"},{"categories":[],"content":"Week 01 2020/09/07 - 添加 vCenter 2020/09/08 - 添加 VMware Windows Proxy 2020/09/09 - 添加 VMware Linux Proxy 2020/09/10 - 添加文件备份代理 File Proxy 2020/09/11 - 添加 Windows 服务器直连的磁盘为备份存储库 Week 02 2020/09/14 - 添加 Linux 服务器管理的 XFS 文件系统为备份存储库 2020/09/15 - 添加 SMB 共享为备份存储库 2020/09/16 - 添加 NFS 共享为备份存储库 2020/09/17 - 添加 HPE StoreOnce 2020/09/18 - 添加 AWS S3 对象存储库 Week 03 2020/09/21 - 添加 S3 兼容模式的对象存储 2020/09/22 - 添加含 Capacity Tier 的横向扩展存储库 SOBR。 2020/09/23 - 添加广域网加速器 2020/09/24 - 推送安装物理服务器的备份代理 2020/09/25 - 添加 SMB 文件共享备份文件数据 2020/09/27 - 添加 NFS 文件共享备份文件数据 2020/09/28 - 添加文件服务器备份文件数据 2020/10/09 - 添加磁带服务器 ","date":"2020-09-07","objectID":"/2020/09/backup-infra-gifs/:0:0","tags":["GIF"],"title":"备份基础架构高清版 GIF，同步公众号持续更新","uri":"/2020/09/backup-infra-gifs/"},{"categories":[],"content":"Veeam 的软件是一个极致简单的产品，简单易用贯穿了整个产品的设计，但是随着功能越来越多，也许刚刚接触 Veeam 的朋友们会不知道从哪里入手。 因此，我新开了一个每日一图的专用公众号，在这个公众号中，每个工作日都会推送一个简单的 GIF 动画，计划通过一个 10 多秒的动画来教您使用 Veeam 产品。 新公众号如下，欢迎关注。 由于微信公众号的额外压缩，在每日推送的动画中，可能清晰度欠佳，如果希望观看并收藏清晰版的朋友，可以访问我的 博客。 ","date":"2020-09-07","objectID":"/2020/09/new-subscription-daily-gif/:0:0","tags":["GIF"],"title":"微信搜一搜，10 秒学 Veeam","uri":"/2020/09/new-subscription-daily-gif/"},{"categories":[],"content":"Veeam 发布 v10 之后，推出了一个全新的功能，但是这个功能深深的埋藏在了 Powershell API 之下，并且被冠了一个令人高不可攀的名称：数据集成 API。我相信很多朋友看完这个名字，就可能不太想了解这个功能。对于系统管理员来说，有点略复杂了，还要开发什么东西才能把这个用起来？算了还是不用了。 ","date":"2020-07-13","objectID":"/2020/07/data-integration-api/:0:0","tags":["Automation Powershell"],"title":"数据集成 API 真的就只是 API？","uri":"/2020/07/data-integration-api/"},{"categories":[],"content":"功能 其实这个功能并不是那么的复杂，我们先来了解下怎么回事。 这个功能其实是通过 iSCSI 的磁盘服务，将备份存档通过 iSCSI 发布给相关服务器使用。它是数据利用的新形态，也就是说任何的 Veeam 的镜像级备份存档，都可以通过这种形式挂载给服务器去访问里面的数据。它和即时虚拟机恢复有那么一点点像，但是完全不一样的是，它完全不依赖于虚拟化环境，不依赖 VMware 和 Hyper-V，而是将数据直接通过 iSCSI 服务发布给 Windows 或者 Linux 系统访问。在 VBR 中，绝大多数镜像级的备份存档都支持这种形式的发布： VMware 镜像级备份 VMware 镜像级复制 Hyper-V 镜像级备份 Hyper-V 镜像级复制 Veeam Agent for Windows 的镜像级备份 Veeam Agent for Linux 的镜像级备份 ","date":"2020-07-13","objectID":"/2020/07/data-integration-api/:1:0","tags":["Automation Powershell"],"title":"数据集成 API 真的就只是 API？","uri":"/2020/07/data-integration-api/"},{"categories":[],"content":"原理 iSCSI 挂载的工作原理非常简单，在 API 发起后，VBR 的挂载服务器相当于变成一台 iSCSI 的存储机头，它能为所有可以访问 iSCSI 存储的系统提供 iSCSI 的服务，而这里面提供出去的数据则是 VBR 的存档，管理员可以按需从备份或复制存档中选择需要的数据。在这个数据集成服务建立起来后，数据使用者可以通过 iSCSI 的存储协议，直接挂载发布出来的卷，读取其中的数据，使用其中的数据。如图所示，在数据集成服务将备份存档发布后，备份系统变成了一套 iSCSI 的存储系统，里面存放的数据是之前的历史备份数据。 ","date":"2020-07-13","objectID":"/2020/07/data-integration-api/:2:0","tags":["Automation Powershell"],"title":"数据集成 API 真的就只是 API？","uri":"/2020/07/data-integration-api/"},{"categories":[],"content":"使用方法 因为它以 API 形式开放给用户使用，因此在 VBR 控制台上并没有直接的按钮来使用，但是这完全挡不住我们使用这么优秀的功能。可以直接使用本文最后面的这个 Powershell 的脚本来实现这个功能，需要做的很简单，只要 copy 脚本内容到记事本，存成。ps1 文件，然后在 VBR 服务器的 Powershell 控制台中执行这个交互式脚本即可，按照脚本执行过程中的提示输入必要的信息就能成功将存档通过 iSCSI 发布出来了。 执行脚本后，会看到 Powershell 控制台上输入内容后会看到以下效果： 而此时，在 VBR 上会看到发布出来的磁盘信息，它以 Instant Recovery 显示在 VBR 控制台中。 接下来，我们可以来到 iSCSI 客户端上，比如刚刚在脚本执行时输入 IP 地址的机器 10.10.1.175 上，打开 Windows 的 iSCSI Initiator，填入 iSCSI 的 target 为 10.10.1.201，端口默认 3260，来挂载这个 iSCSI 卷了。 在使用结束后，不要忘了在 VBR 上点击 Stop Publishing 来回收这个 iSCSI 卷。 以上就是简单实用的新功能，iSCSI 发布。赶紧下载 VBR 装上试一下吧。 附上脚本： # 本脚本是 Veeam DataIntegration API 的使用样例 # 用于通过 iSCSI 方式将备份数据挂载给指定的系统进行使用 # 使用脚本需要至少有 7 个还原点以上，否则请修改脚本使用 # 脚本暂时仅限 VMware、Hyper-V 的主备份存档，如需 Agent、Backup Copy、Replication、Storage Snapshot，请根据需求修改脚本。 # # 脚本作者：Wei Lei # Email:lei.wei@veeam.com # 脚本版本：v1.1 ################# Update log ###################### # 更新了 VBR 用户名密码错误后立刻停止脚本； # 更新了还原点选择错误后，自动终止脚本； ################################################### # Script Start # VBR Server (Server Name, FQDN or IP) $vbrServer = Read-Host \"请输入 VBR 地址，可以是域名或者 IP\" # VBR Credentials Write-Host \"请在弹出对话框中输入 VBR 的用户名密码。\" $Credential=Get-Credential -Message 请输入 VBR 的用户名密码 $vbrusername = $Credential.Username $vbrpassword = $Credential.GetNetworkCredential().password #region Connect # Load Veeam Snapin If (!(Get-PSSnapin -Name VeeamPSSnapIn -ErrorAction SilentlyContinue)) { If (!(Add-PSSnapin -PassThru VeeamPSSnapIn)) { Write-Error \"Unable to load Veeam snapin\" -ForegroundColor Red Exit } } # Connect to VBR server $OpenConnection = (Get-VBRServerSession).Server If ($OpenConnection -ne $vbrServer) { Disconnect-VBRServer Try { Connect-VBRServer -user $vbrusername -password $vbrpassword -server $vbrServer -ErrorAction Stop } Catch { Write-Host \"无法连接到 VBR 服务器 - $vbrServer\" -ForegroundColor Red exit } } #endregion $VMName = Read-Host \"请输入需要用于挂载的虚拟机名称\" $IP =Read-Host \"要挂载到哪台服务器（IP 地址）？\" $backup = Get-VBRBackup $backup = @($backup | ?{$_.JobType -eq \"Backup\"}) $points = Get-VBRRestorePoint -Backup $backup -Name $VMName | Sort-Object –Property CreationTime –Descending | Select-Object -First 7 if ($points -eq $null) { Write-Host \"找不到这台虚拟机的还原点。 - $VMName\" -ForegroundColor Red exit } While($InNumber -ne 7) { Write-Host \"##############已找到虚拟机 $VMName 的最近 7 个还原点##############\" -ForegroundColor Green $i = 0 foreach ($pt in $points) { $ptctime = $pt.CreationTime $i = $i + 1 Write-Host \"#\" $i . $ptctime \";\" } Write-Host \"#############################################################\" -ForegroundColor Green $InNumber = Read-Host \"请选择还原点（1-7）\" $ss =@() switch($InNumber) { 1 { $pt = $points | Select-Object -Index 0 $pttime = $pt.CreationTime Write-Host \"已选择还原点 $pttime 。\" -ForegroundColor Green $ss = Publish-VBRBackupContent -RestorePoint $pt -AllowedIps $IP -RunAsync } 2 { $pt = $points | Select-Object -Index 1 $pttime = $pt.CreationTime Write-Host \"已选择还原点 $pttime 。\" -ForegroundColor Green $ss = Publish-VBRBackupContent -RestorePoint $pt -AllowedIps $IP -RunAsync } 3 { $pt = $points | Select-Object -Index 2 $pttime = $pt.CreationTime Write-Host \"已选择还原点 $pttime 。\" -ForegroundColor Green $ss = Publish-VBRBackupContent -RestorePoint $pt -AllowedIps $IP -RunAsync } 4 { $pt = $points | Select-Object -Index 3 $pttime = $pt.CreationTime Write-Host \"已选择还原点 $pttime 。\" -ForegroundColor Green $ss = Publish-VBRBackupContent -RestorePoint $pt -AllowedIps $IP -RunAsync } 5 { $pt = $points | Select-Object -Index 4 $pttime = $pt.CreationTime Write-Host \"已选择还原点 $pttime 。\" -ForegroundColor Green $ss = Publish-VBRBackupContent -RestorePoint $pt -AllowedIps $IP -RunAsync } 6 { $pt = $points | Select-Object -Index 5 $pttime = $pt.CreationTime Write-Host \"已选择还原点 $pttime 。\" -ForegroundColor Green $ss = Publish-VBRBackupContent -RestorePoint $pt -AllowedIps $IP -RunAsync } 7 { $pt = $points | Select-Object -Index 6 $pttime = $pt.CreationTime Write-Host \"已选择还原点 $pttime 。\" -ForegroundColor Green $ss = Publish-VBRBackupContent -RestorePoint $pt -AllowedIps $IP -RunAsync } Default { Write-Error \"请输","date":"2020-07-13","objectID":"/2020/07/data-integration-api/:3:0","tags":["Automation Powershell"],"title":"数据集成 API 真的就只是 API？","uri":"/2020/07/data-integration-api/"},{"categories":[],"content":"为 Veeam 定制一个最小化的 vSphere 权限账号对于系统管理安全来说非常有必要，但是随着软件的升级功能的增强，对于 vSphere 上需要用到的权限也越来越多，Veeam 在官方的 UserGuide 中提到了详细的 细颗粒度权限要求，此时如果手工去逐个比对、选择，其实还是挺费时挺麻烦的一件事情。 最近我看到一个非常不错的 PowerCLI 脚本，使用这个脚本能够快速方便的创建这个 Veeam 专用角色，今天来和大家分享一下。 这个脚本的前提条件，是安装 vSphere PowerCLI，脚本是通过 VMware 自动化的 vSphere PowerCLI 管理工具来实现的。安装方法在 VMware 官网的 Blog 中有详细说明，我这里给个简化版的步骤： 首先下载安装 PowerShell Core 7，这是 PowerCLI 运行的必要条件。PowerShell Core 比 Windows PowerShell 更强大，不熟悉的朋友也可以通过下载链接进去了解详细。安装过程非常简单，如果是 Windows 下，.MSI 安装包双击后跟着向导就能装完。 打开 PowerShell 7 快捷方式后，运行以下命令来安装 vSphere PowerCLI。 Install-Module -Name VMware.PowerCLI -Scope CurrentUser 安装完成后输入以下命令，能够看到如下结果： Get-Module -Name VMware.* -ListAvailable 3. 运行这个 PS 脚本，运行过程中会提示输入 vCenter 的 IP 地址、用户名密码以及希望创建的角色名称，根据实际情况输入即可。运行结果如下图： 回到 vSphere Client，找到 Administration 下的 Access Control，在 Roles 下面，能够找到刚刚用脚本创建出来的 VBR Backup Admin 的角色。接下去就可以去创建 Veeam 专用用户了。 在 Administration 的最底部，找到 Single Sign On 下面的 Users and Groups，在 Users 下面，把 Domain 切换成 vSphere 登录的 Domain，然后 Add User 添加新用户。 添加完用户后，回到 vCenter 节点，授权这个新用户访问指定的 vCenter，并给予 VBR Backup Admin 的权限，如下图： 以上就是快速简单的添加备份角色的方法，安全又可靠，脚本链接如下： https://github.com/falkobanaszak/vCenter-role-for-Veeam/blob/master/New_vCenterRole_Veeam.ps1 ","date":"2020-06-05","objectID":"/2020/06/powercli-vsphere-permission/:0:0","tags":["Automation"],"title":"使用 vSphere PowerCLI 快速完成 Veeam 备份管理员角色创建","uri":"/2020/06/powercli-vsphere-permission/"},{"categories":[],"content":"Backup Copy 理论基础 Veeam 的 Backup Copy 是实现数据保护 3-2-1 黄金法则的基础，也是 VBR 的基础功能之一。它的功能非常简单，实现的效果就是将一个还原点（Restore Point）完完整整的拷贝一份，变成一个新的可以使用的还原点。什么是还原点？在 VBR 中它是某个 VM 或者 Server 某个时间点的记录，利用还原点，可以从 VBR 的存储库中将数据还原回该时间点的那份内容。对于还原点来说，它可能包含了一个文件，比如 vbk 全备份存档，也有可能包含了一组文件，一个 vbk 和一系列的 vib，这取决于备份作业或者备份拷贝作业如何创建他们。 Backup Copy 制作的备份链和普通的 Backup 作业制作的备份链略有不同，Backup Copy 通常制作的备份链是永久增量的模型，也就是说，第一次的传输，Backup Copy 会创建一个。vbk 的全备份存档，在第二次开始的后续传输中，Backup Copy 会基于第一次的。vbk 形成一份。vib 的增量存档，并且一直创建下去。 Backup Copy 默认使用合成全备份的技术生成并创建全备份存档，只是这个全备份存档必须是基于 GFS 策略来创建，举个例子来说，如下图所示： 这个 Backup Copy 作业设置了 14 个还原点（Restore Points），每天运行一次作业，那么实际上在运行了一个周期后，它将得到如下结果： 如果开启了 GFS 每周的全备份后，Weekly Backup 如果设置成 2 份，如下图设置。 那么这样的设置将得到如下结果，其中前两个全备份存档是根据 GFS 的策略要求，所创建出来的 Weekly Full 的存档。 ","date":"2020-06-02","objectID":"/2020/06/new-backup-copy/:1:0","tags":["VBR"],"title":"Backup Copy 新模式，让 3-2-1 的黄金法则覆盖更广","uri":"/2020/06/new-backup-copy/"},{"categories":[],"content":"V10 的新变化 在 V10 版本中，Veeam 的 Backup Copy 发生了一些变化，原来的 Backup Copy 模式继续保留，但是新增了一种全新的模式，因此这两种模式有了各自的名字：Immediate Copy 和 Periodic Copy。新增的模式叫做 Immediate Copy，老的模式赋予了新的名字 Periodic Copy。两种模式有一些区别，他们支持的内容会不一样，如下表所示。 支持的备份存档 Immediate Copy Periodic Copy vSphere 和 Hyper-V 虚拟机备份 支持 支持 VBR 集中管理的 Veeam Agent 支持 支持 SQL 和 Oracle 的日志备份 支持 不支持 非集中管理的 Veeam Agent 不支持 支持 Oracle RMAN 和 SAP HANA 支持 不支持 Nutanix AHV 不支持 支持 AWS EC2 不支持 支持 Microsoft Azure 虚拟机 不支持 支持 除此之外，这两种 Copy 模式，在备份存档的生成上，有一些区别，对于 Immediate Copy 而言，他会根据主备份任务的设定，当主备份任务执行完成后，立刻生成一份备份拷贝存档。Immediate Copy 是主备份任务的 1：1 的完全还原点镜像。但是需要特别注意的，它不是简单的备份文件的镜像，并不是 vbk、vib 的文件拷贝。举个例子来说，在主备份任务中如果设置了每个周六创建 Synthetic Full 的备份作业，会在周六生成全备份存档，而在这个备份存档生成后，Immediate Copy 作业会运行并创建对应的 Copy 存档，这个创建出来的存档和主备份任务创建出来的 vbk 全备份不一样，它创建出来的是一份 vib 的增量备份。由于 Immediate Copy 的特点，它适用于所有需要进行应用程序日志复制的备份作业，因此在异地容灾时，对于关键的数据库系统，通过 Immediate Copy 能提升 RPO 级别。 两种备份模式正常情况下无法切换，假如要使用全新的 Immediate Copy 功能，可以禁用老的 Backup Copy 任务，只需要简单的创建新的 Immediate Copy 勾选 Include database transaction log backups 即可。 以上就是今天的内容，为了数据更安全，赶紧把 Backup Copy 做起来吧。 ","date":"2020-06-02","objectID":"/2020/06/new-backup-copy/:2:0","tags":["VBR"],"title":"Backup Copy 新模式，让 3-2-1 的黄金法则覆盖更广","uri":"/2020/06/new-backup-copy/"},{"categories":[],"content":"VBR 升级到 v10 之后增加了很多全新的功能，也多了很多隐藏的快捷键，今天我就来说说这些隐藏的秘密。 ","date":"2020-05-13","objectID":"/2020/05/hidden-key-in-vbr/:0:0","tags":["VBR"],"title":"VBR 中的那些隐藏键","uri":"/2020/05/hidden-key-in-vbr/"},{"categories":[],"content":"[Ctrl]+鼠标右键 在不少操作中，可以用到这个 Ctrl+鼠标右键调出特别的菜单，一般来说，如果不按住 Ctrl 键，那么直接鼠标右键是看不见这些隐藏的菜单的。 NAS 备份中执行一次全新的作业 正常的 NAS 文件备份在 Veeam 中都是永久增量备份，然而还是有些用户会需要用到执行一次全新的全备份，在 NAS 备份中 Veeam 一样提供了这个功能，只需要选中需要执行的备份作业，按住 Ctrl 键后，再点击鼠标右键，那么这个全备份的按钮就会出现。 执行完这个全备份后，会出现一个和普通虚拟机全备份/合成全备份稍微不一样的情况，那就是之前的备份数据将会被移动到 Disk(Imported) 之中，新的备份链将会替代之前的，变成活跃的 NAS 永久增量备份链。 Oracle/SAP HANA Backup 作业 Force delete 当配置并运行了 Oracle 或者 SAP HANA 的 Backup 作业后，VBR 会出现类型为 Oracle Rman backup 或者 SAP Backup 的作业，右键点击这些作业会有 Delete 的选项，但是这个 Delete 必须要求首先将 RMAN 或者 SAP HANA 的备份存档删除掉。这时候如果不希望删除存档，但是只想删除备份作业，可以使用 Ctrl+鼠标右键，会出现 Force Delete 选项。 SOBR 的 Run tiering job now 我觉得不少朋友肯定会为 4 小时往云上传一次数据的死板设定犯愁，其实有个右键菜单藏起来了，对着 Scale-Out Backup Repository 按住 Ctrl 再点鼠标右键，你就会发现这个立即运行 Tiering 作业的按钮。 ","date":"2020-05-13","objectID":"/2020/05/hidden-key-in-vbr/:0:1","tags":["VBR"],"title":"VBR 中的那些隐藏键","uri":"/2020/05/hidden-key-in-vbr/"},{"categories":[],"content":"方向左右键 在 VBR 的 Jobs 中，双击每个备份作业，可以查看最新的备份作业执行详情，然而如果要去看一些更早的历史作业，可能就会迷失在 VBR 的控制台中了。稍微复杂一点的操作是，打开 History 面板，然后找希望查看的日期逐个查看，也可以通过搜索进行一些关键字的过滤。 其实我们完全不需要打开 History 面板，VBR 提供了在每个作业详情中查看历史作业的方法，只需要在详细任务信息界面按左右方向键，就能查看过往信息，虽然说不能像 History 中那样灵活选择，但是在快速排错时，是一个很不错的选择。 ","date":"2020-05-13","objectID":"/2020/05/hidden-key-in-vbr/:0:2","tags":["VBR"],"title":"VBR 中的那些隐藏键","uri":"/2020/05/hidden-key-in-vbr/"},{"categories":[],"content":"其他隐藏的鼠标右键 有些界面中，藏着一些鼠标右键可用的菜单，很不容易被发现，但是有时候却是很有用的，多数情况下，这些右键操作并不想干扰用户的正常操作，所以并没那么容易被发现。 SureBackup Statistics 窗口中的右键 双击一条 SureBackup Job，弹出 Statistics 窗口，能够看到上一次作业执行时上面的每一台 VM 的成功失败状态。除此之外，在这个静态的查看窗口，藏着一个 Start 按钮，选中 Statistics 窗口中的任意一台 VM，除了能够在下面的详细日志中查看执行情况外，还能右键再次 Start 这个 Datalab。 这个 Start 按钮主要是为我们在 SureBackup 失败时做一些 Troubleshooting 用途，点击 Start 之后，在 Session log 中会显示 SureBackup 切换进入了 Troubleshooting mode，在这个模式中，SureBackup Job 不会因为失败或者成功被立刻终止，它会保持运行状态，一直到我们手工终止结束它。这里请确保 Troubleshooting 或者使用结束后，执行 Stop 按钮。 存放于含有 Capacity Tier 的备份存档 通常在打开 Backups 的属性对话框右键点击备份存档时，普通的备份存档只有 copy path 的按钮，这是为了让我们快速的从文件系统中找到该 vbk、vib 文件。 但是有些时候，如果是 SOBR 中含有 Capacity Tier，条件满足的情况下，右键点这些备份存档，会出现新的右键菜单。 Ok，以上就是今天的一些隐藏按钮，如果觉得好用，赶紧点赞用起来哟。另外，如果您发现了更多的，也可以留言告诉我。 ","date":"2020-05-13","objectID":"/2020/05/hidden-key-in-vbr/:0:3","tags":["VBR"],"title":"VBR 中的那些隐藏键","uri":"/2020/05/hidden-key-in-vbr/"},{"categories":[],"content":"自加入 Veeam 起，一直不断有“什么时候才能有中文界面？”的呼声。只是这是一件非常困难的事情，我一向对这个事情的态度都很悲观。 不过，方法总比困难多，不是吗？今天就给大家带来个小福利，Web 界面的 Veeam Enterprise Manager 的汉化插件。 先放上界面样图： 插件下载地址： https://gitee.com/veeamchinadocs/veeam-webui-cn-plugin 使用方法很简单，只需要下载后把 Veeam-CN-WebUI-Beta-1.x.x 文件夹放到 Chrome 的机器上，注意不一定是 Enterprise Manager 的服务器，然后按照说明进行操作即可。 注意点： 这个插件是 Chrome 页面本地化插件，建议不在访问 Veeam Enterprise Manager 时务必记得关闭这个插件。 汉化完成度 95%，部分内容暂时还没找到汉化方法，但是不影响使用。 如果发现有些页面没有及时刷新成中文，或者变成了英文，只要刷新下页面或者点击下页面上的其他超链接，即可切换成中文。 这是个页面客户端插件，因此完全不影响 Veeam 软件使用，只需要关闭插件刷新页面或者换浏览器换电脑重新打开 EM 使用即可。 最后还需要感谢下 Veeam 日本的 SE 们，我只是在他们基础上将这个插件制作成了中文版。 ","date":"2020-03-13","objectID":"/2020/03/localized-web-ui/:0:0","tags":["Enterprise Manager"],"title":"自制 Chrome 浏览器插件 - 中文版 Enterprise Manager Beta 发布","uri":"/2020/03/localized-web-ui/"},{"categories":[],"content":"系列目录： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 本系列的最后一篇，我来介绍一下 VAO 的文档系统。 VAO 能够全自动的为管理员生成灾备需要的系统文档，文档的内容为 VAO 系统自动根据 Orchestration Plan 的设置和执行自动生成。VAO 文档系统的强大在于所有的内容系统根据配置和运行会全自动生成，因此管理员只需要专心关注自己的灾备即可，这些后续的基础保障，繁琐的文档制定，全部交给 VAO 来完成。 VAO 生成的每个文档会包含两部分，第一部分是灾备管理员定义的 Report Template；第二部分是系统根据 Report Type 生成的动态内容。无论什么类型的文档，在文档的开头部分都会使用 Report Template 中所定义的内容，而第二部分则根据 Report Type 不同自动填充相关内容。 我们先来看个实际的例子，了解一下什么是 Report Template 中的内容，什么是根据 Report Type 自动生成的，如下图： 左边是一个 VAO 最终生成的 Readiness Check 的 Report，右边是我们在编辑器中打开的 Report Template。可以看到红色框所示的内容就是来自于 Report Template 的，而图中左边文档的后半部分内容则是根据这个 Report Type，自动产生的内容。 ","date":"2020-03-02","objectID":"/2020/03/vao-guide-09/:1:0","tags":["VAO"],"title":"VAO 基础入门（九） -  文档模板解析","uri":"/2020/03/vao-guide-09/"},{"categories":[],"content":"Report Type 先来说说这个 Report Type，也许聪明的你，在前几篇介绍 Orchestration Plan 的时候已经有看到，在每个 Plan 的右键菜单或者工具栏上有一些 Report 可以生成，它们分别是： Report 类型 作用 Plan Definition Report 记录灾备计划设置详情 Readiness Check Report 灾备计划可用性检测报告，包含恢复目标位置和灾备中心的可用性检测 Datalab test Reort 数据实验室测试报告 Excution Report 灾备执行情况报告 这些 Report 就是 VAO 能够生成的所有 Report 文档，这些文档都会有一个 VAO 已经内置设计好的内容，能够和灾备管理员定义的 Report Template 组合起来，最终形成一份完整可以阅读的 Report。 这部分 VAO 已经内置的内容，我们无法做任何的更改，系统都会根据实际的报告类型、当前灾备计划的设定、灾备计划的运行和执行来自动生成这个内容，因此我们也不需要对这里的内容做更改设定。 所以，此部分的内容目前只包含英语版本，我们没有任何方法去修改其中相关信息，当然如果我们的 Plan 中如果包含中文的信息，VAO 还是能够正确的传递给 Report，生成相关内容。 ","date":"2020-03-02","objectID":"/2020/03/vao-guide-09/:2:0","tags":["VAO"],"title":"VAO 基础入门（九） -  文档模板解析","uri":"/2020/03/vao-guide-09/"},{"categories":[],"content":"Report Template Report Template 的内容是管理员可以根据自己需求进行定制每个文档的前半部分，在 VAO 出厂软件中，已经内置了 8 国语言的默认模版，需要注意的是，这些默认模版都是无法编辑的，但是是可以直接被 Report 系统调用在 Orchestration Plan 中使用的。如果需要编辑这些模版，或者创建自己的模版，需要首先从这些模版 Clone 一份自己的拷贝，然后在这个基础上进行修改。 修改这些文档需要用 Word，要求是 Word 2010 SP2 以上版本，也就是说，需要在当前打开 VAO 网页的电脑上，同时安装了 Word 2010 SP2 以上版本，才能正常的进行编辑。点击 VAO 界面中的 Edit 按钮后，系统会自动从网页浏览器切换至 Microsoft Word 中进行编辑。 和普通的 Word 编辑完全不一样的是，这个模板的编辑是个动态文档的编辑，可以加入很多 VAO 中的变量，让 VAO 系统在生成 Report 的时候自动填充。 ","date":"2020-03-02","objectID":"/2020/03/vao-guide-09/:3:0","tags":["VAO"],"title":"VAO 基础入门（九） -  文档模板解析","uri":"/2020/03/vao-guide-09/"},{"categories":[],"content":"如何使用 Word 编辑动态文档 首先需要选择一个内置的 Template 作为我们要编辑的对象，点击 Clone 按钮启动创建自己的 Template。比如我这里选择Veeam Default Template（ZH）。 在 Clone Template 对话框中，选择分配给自己名下的哪个 Scope，然后为这个 Template 起个响亮的名字，填写一段描述，就能完成模板创建。 创建完成后，在 Template 清单中就能看的这个模板，并且上面的工具栏按钮也可以对这个模板进行操作了，可以点击 Edit 进行内容编辑。在这里 VAO 并不提供内置的文档编辑器，这个 Edit 按钮会直接调用当前浏览器所在的计算机打开 Word 进行编辑，要求管理员必须已经正确安装了 Microsoft Word。 点击 Edit 之后，会切换到 Word 程序，需要注意的是，Word 不会立即打开文档，而是需要一个访问的权限，这里需要的权限必须是当前在浏览器中登入 VAO 的用户，否则这个 Word 将打不开该文档模板。 打开文档后，即可正常进行 Word 的编辑了。这个文档并不是全文档都可以编辑，您会发现很多区域被黄色的荧光标注了，这部分内容才是允许编辑的区域，在这里可以任意的加上需要的文字和图片内容。所以，可以看到，这个文档的标题、页眉和页脚是不可被修改的，而其他部分，都是可修改的。 因为这是个动态文档，所以在这里我们可以调用很多很多 VAO 的变量内容来取得数据，VAO 系统已经给我们做了一些示例，在 Clone 出来的这个文档中，仔细观察这些文字，会发现有一些文字内容被 [] 包围，这部分内容就是这个文档中动态的变量内容。这个编辑和我们正常的 Word 编辑稍微有些不同，我们来看看如何进行操作。 要编辑这个变量数据，首先我们可以按正常方式输入一段文字内容，为了区分和普通文字的不同，建议也和 VAO 默认文档一样，加上 []，比如：[Hi，我是变量]，在上方工具栏，找到开发工具，打开设计模式。 在打开设计模式后，会发现这个文档变得好奇怪，之前藏起来的很多内容显现出来了，这时候别被这些多出来的内容吓到，他们实际上并不存在，关掉设计模式后他们会自动藏回去，这只是我们的变量设置结果而已。 接下去，我们对[Hi, 我是变量]进行设置，选中这段文字，然后需要点击设计模式左边的第一个Aa按钮，就能将这段文字变成和模板中一样的变量了，然后再点击设计模式下方的属性，可以打开变量设定的对话框，它是使用 Word 的内容控件来实现的，设定这个内容控件的属性即可完成。 这个变量设置非常简单，只需要输入一个标题和一个标记，一般来说，这两个设置成一样的就行了，标题跟着标记的内容来填写。VAO 内置了以下可用的所有标记，所有标记都是以“~”开头，选择需要的标记填入到上面的这个属性框中点确定即可。 变量名 作用说明 ~Created Report 生成时间 ~TimeZone Report 生成时区 ~PlanType VAO 计划类型 ~PlanName VAO 计划名称 ~PlanDescription VAO 计划描述 ~PlanContactName 灾备计划联系人姓名 ~PlanContactEmail 灾备计划联系人邮箱 ~PlanContactTel 灾备计划联系人电话 ~Site 站点名称 ~SiteScopeName 站点范围名称 ~SiteDescription 站点描述 ~SiteContactName 站点联系人姓名 ~SiteContactEmail 站点联系人邮箱 ~SiteContactTel 站点联系人电话 ~ServerName 服务器名称 ~VmsInPlan 在该计划中的虚拟机 ~GroupsInPlan 在该计划中的虚拟机组 ~ReportType Report 类型 ~TargetRTO 该计划的目标期望 RTO ~TargetRPO 该计划的目标期望 RPO 在根据需要写完这个文档之后，只需要按照正常保存或者关闭这个文件就可以将文档提交至 VAO 服务器了，千万记得不要使用另存为，另存为之后，就不会更新至 VAO 服务器，这个编辑也就白搭了。 Report Template 编辑完成后，就可以回到 VAO 网页 UI 中查看修改结果了，管理员也可以根据不同的 Scope 的设置，为不同的 Orchestration Plan 选择并使用这个新创建的 Report Template。 以上就是 VAO 的所有内容，希望对大家了解 VAO 有帮助，感谢关注和阅读！ ","date":"2020-03-02","objectID":"/2020/03/vao-guide-09/:4:0","tags":["VAO"],"title":"VAO 基础入门（九） -  文档模板解析","uri":"/2020/03/vao-guide-09/"},{"categories":[],"content":"系列目录： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 上一篇，我介绍了 Plan Step 的基本概况，今天我来详细分解下在 Plan Step 中的自定义脚本，我会通过一个脚本使用例子，来带大家使用一下自定义脚本。 ","date":"2020-02-28","objectID":"/2020/02/vao-guide-08/:1:0","tags":["VAO"],"title":"VAO 基础入门（八） -  Plan Step · 下篇","uri":"/2020/02/vao-guide-08/"},{"categories":[],"content":"创建和设置 配置自定义的脚本需要使用隶属于 Administrators 组的账户登入 VAO 平台。进入 Administration 控制台后，可以在 Configuration 下面找到 Plan Steps，在这里可以管理所有的 Plan Steps，当然除了创建自定义的 Steps 之外，也可以在这里对 OOTB 的那些 Steps 进行一些个性化的配置。 点击 Add 按钮即可进入添加向导，过程也非常简单，为它起个响亮的名字，比如：远程的骚操作测试。在 File 栏，点击 Browse 从当前的客户端上去选择制作好的 powershell 脚本吧。 点击 Next 进入 Step Visibility 步骤，如果不希望所有的灾备管理员都看到这个骚脚本的话，可以不勾上这个界面的复选框。 最后还是老样子，Summary 总结一下，点 Finish 就创建完成了。但是，这只是创建完成，别想着就马上拿去用，这里特别敲黑板强调一下： Custom Script 可以有两种不同执行位置，一种是在灾备的机器上执行，另外一种是在 VBR 上执行。这个必须手工在创建完 Plan Step 之后点击这个 Step 名称，浏览到右边如图位置进行调整，默认值是在 VBR 上执行。比如我今天要做的这个测试就是需要调整一下，更改成 In-Guest OS。 需要注意的是，这个 Step 的设置是全局的，也就是说，如果将这个 Step 提供给所有的 Scope 使用，那么这项配置内容是所有的 Scope 共享的，不能做计划任务中做更改。因此管理员如果有必要，需要做这个 Plan Steps 的管理页面中根据实际需求逐个定义。 ","date":"2020-02-28","objectID":"/2020/02/vao-guide-08/:2:0","tags":["VAO"],"title":"VAO 基础入门（八） -  Plan Step · 下篇","uri":"/2020/02/vao-guide-08/"},{"categories":[],"content":"Hello！My Script 那么接下来，让我们来配置一个 Script 跑一把吧。来个简单的，内容如下： ########### #Lei Wei - 02/28/20 # # 这个脚本是骚操作的代表，请仔细往后看 # # v1.0 $S = Get-Date; Add-Content c:\\vao_log.txt \"$S - Recording date \" 如果一切正常，在 VAO 中将会看到如下信息： ","date":"2020-02-28","objectID":"/2020/02/vao-guide-08/:3:0","tags":["VAO"],"title":"VAO 基础入门（八） -  Plan Step · 下篇","uri":"/2020/02/vao-guide-08/"},{"categories":[],"content":"让我们变得更复杂一点 好在这个脚本实在太简单了，几乎不可能会出现报错，那么如果复杂一点，脚本成功或者报错，VAO 能否捕获这些错误让我们的管理员能够更方便的知道系统发生了什么问题呢？请看以下代码： ########### #Lei Wei - 02/27/20 # # 这个脚本是骚操作的代表，请仔细往后看 # # v1.1 try { $S = Get-Date; Add-Content c:\\vao_log.txt \"$S - Recording date. \" Write-Host \"准确计时，骚操作成功\" } Catch { Write-Error \" 不知道哪里坏了，失败了！\" Write-Error $_.Exception.Message } 在更换成这个 Powershell 执行之后，可以看到如下 VAO 界面中的执行成功记录，除了记录成功失败，还将我设置中脚本中的信息同时传递到了 VAO 界面之中。 ","date":"2020-02-28","objectID":"/2020/02/vao-guide-08/:4:0","tags":["VAO"],"title":"VAO 基础入门（八） -  Plan Step · 下篇","uri":"/2020/02/vao-guide-08/"},{"categories":[],"content":"更多参数传递 VAO 所使用的脚本还可以更复杂，比如说，可以通过 VAO 传递一些参数给脚本。我们来继续修改上面的脚本，如下： ########### #Lei Wei - 02/27/20 # # 这个脚本是骚操作的代表，请仔细往后看 # # v1.2 Param( [Parameter(Mandatory=$true)] [string]$planName, [string]$text ) try { $S = Get-Date; Add-Content c:\\vao_log.txt \"$S - Recording date. \" Write-Host \"准确计时，骚操作成功\" Write-Host \"准确计时，骚操作成功，$planName，$text !\" } Catch { Write-Error \" 不知道哪里坏了，失败了！\" Write-Error $_.Exception.Message } 这个脚本中，我们配置了两个参数，$planName 和$text，如果要在 VAO 中正确使用参数，并将相关参数传递给脚本，那么就需要我们为这个 Plan Step 加上额外的参数，这个可以通过 Plan Step 中右边的 Add 按钮来完成。 需要注意的是，我们 Add 的参数，它的名称必须和脚本中的参数名称保持一致，才能够被正确的传递，如下图，我们设置了 planName 和 text。 这里 planName 的 default 值设置为$plan_name$，这个内容是 VAO 中系统自带的一些变量，在我们的传递参数中，可以直接使用。具体列表在点击 Edit 按钮时会直接弹出供我们选择。 而$text，我们直接输入 Default Value，而不是使用 VAO 内置的系统变量，输入的内容为：完成参数传递。 最后让我们来看看这个脚本骚操作在 Orchestration Plan 中执行结果吧，我们的 Step Details 和 Report 中会出现什么： 感觉怎么样，是不是觉得 VAO 很棒？赶紧动手试一试吧。 ","date":"2020-02-28","objectID":"/2020/02/vao-guide-08/:5:0","tags":["VAO"],"title":"VAO 基础入门（八） -  Plan Step · 下篇","uri":"/2020/02/vao-guide-08/"},{"categories":[],"content":"系列目录： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 前一篇，我详细介绍了 Orchestration Plan，在我们设计灾备计划时，可以从某个 Application 入手，从简到繁循序渐进的规划整个数据中心的灾备。 创建 Orchestration Plan 时默认情况下，为每个灾备计划内置了最基础的 Step，而 VAO 的强大之处在于它能够添加各种 Step，系统内置了一些常用的 Step，管理员只需要根据自己实际的需求选择相应的 Step，然后配置相关参数即可使用。 ","date":"2020-02-27","objectID":"/2020/02/vao-guide-07/:1:0","tags":["VAO"],"title":"VAO 基础入门（七） -  Plan Step · 上篇","uri":"/2020/02/vao-guide-07/"},{"categories":[],"content":"Out-of-the-box 的 Plan Steps 这些出厂自带的 steps 一共 22 个，大概可以分为这么几类： 恢复操作 - 2 个 Datalab Lab 验证操作： - DataLab 准备操作 - 1 个 - 虚拟机基础验证 - 2 个 - 应用验证 - 12 个 通知操作 - 2 个 虚拟机电源操作 - 2 个 虚拟机服务启动操作 - 1 个 这些操作基本没什么特别需要注意的地方，所以的内容都已经固化内置在系统中了，根据系统的提示，填入相关的内容即可。本文不详细展开逐个讨论这里每一个 Step 的参数配置方法，具体大家可以根据实际情况选择逐个测试。 ","date":"2020-02-27","objectID":"/2020/02/vao-guide-07/:2:0","tags":["VAO"],"title":"VAO 基础入门（七） -  Plan Step · 上篇","uri":"/2020/02/vao-guide-07/"},{"categories":[],"content":"Plan Step 通用参数 在每个 Plan Step 中，都会包含一个最基础的Common Parameter，这是对于这个 Plan Step 执行的基本控制条件，包含以下内容： - Failback \u0026 Undo Failover Action : 决定在 Failback 和 Undo Failover 操作时是否执行脚本 - Test Action : 决定在 Datalab 测试中是否使用脚本 - Critical step : 定义这个 Step 对于整个 Plan 是否重要，如果是，则失败后立刻停止计划 - Timeout : 定义整个 Step 执行超时时间 - Retries : 定义失败重试次数 这个 Parameter 可以在每个 Orchestration Plan 中为每个 step 单独调整。 ","date":"2020-02-27","objectID":"/2020/02/vao-guide-07/:3:0","tags":["VAO"],"title":"VAO 基础入门（七） -  Plan Step · 上篇","uri":"/2020/02/vao-guide-07/"},{"categories":[],"content":"更强的自定义脚本 除此之外，VAO 还提供了额外的自定义脚本功能，管理员可以在 VBR 服务器或者恢复后的系统上直接调用使用 Powershell 脚本，完成各种骚操作。 举个例子，数据中心某应用架构如下： 典型的三层架构，Oracle 数据库在 AIX 小机上，中间件和应用服务器跑在 VMware vSphere 上面。灾备系统设计之初，Oracle 数据库通过 OGG 做了复制，实现了数据级同步。 这样的架构，通常 Veeam 使用 VBR 的时候会建议用户对虚拟化平台也做一个保护，确保在主数据中心出现故障的时候能够应用系统和数据库都切换至灾备中心。而在使用了 Veeam 的解决方案后，通常我们的用户都会发现，VBR 不仅能够很好的完成虚拟化平台的灾备复制任务，同时他的灾备演练能力也极其强大，系统会真实的被恢复出来并且提供恢复后的演练访问，真枪实弹的完成整个演习过程，并且还是全自动的。 但是，管理员很快会发现，很尴尬的一点是，应用系统没有数据库的数据支持，就算恢复了，也没办法正常工作，这样的测试还是无法最终等效于实际灾备场景。 ","date":"2020-02-27","objectID":"/2020/02/vao-guide-07/:4:0","tags":["VAO"],"title":"VAO 基础入门（七） -  Plan Step · 上篇","uri":"/2020/02/vao-guide-07/"},{"categories":[],"content":"VAO 来帮忙 这事情借助 VAO，可以完美的解决。整个过程会是这样： 启动应用系统的 Failover / Restore Plan，可以在真正的恢复过程前的 Step 中，加入 Powershell 脚本，和灾备站点的 AIX 进行通讯。 AIX 上脚本执行后，新的 LPAR 部署出来。 再来一个脚本，将一个虚拟网卡 attach 到新部署出来的 LPAR 上，并让这个网卡和我们在虚拟化环境中创建出来的沙盒隔离网络相连，隔离网络无法直接路由访问到生产，所以是相对隔离的环境。 第三个脚本搞起，让最新的一份 Oracle 数据库运行在这个新的 LPAR 上。 一切准备结束，启动虚拟化灾备平台中的应用和中间件副本，这样在这个隔离环境中，起来的应用和中间件就可以访问 AIX 数据库了。 到这里还没完工，系统都跑起来了，让这套系统别停下，飞一会儿吧，可以在上面做一系列测试、开发等等操作。 经过一段漫长的测试，系统使用完毕，灾备管理员被通知可以回收了。灾备管理员操作 VAO，让系统进入下一步流程。 vSphere 上的虚拟机被 Undo Failover 到演练之前的状态，这个非常简单，和 VBR 上几乎没差别 一个新的脚本被触发，通知 AIX，请删除这个 LPAR 和他上面的数据库，确保测试的数据不会被复制回生产中。 以上这个过程，是不是很不错？这样的过程不仅可以是加入和 AIX 的配合，同样各种系统不管是 HPUX 还是 Oracle Exadata 都可以搞一搞。对了，还有公有云，一起加入到这个灾备 Party 中吧，有了 VAO，这都不是事。 所以，有了自定义的 Script、计划任务的调度，VAO 神通广大，几乎能做任何由 Powershell 可以实现的事情。在下一篇，我会来详细介绍如何玩转这个自定义 Script。 ","date":"2020-02-27","objectID":"/2020/02/vao-guide-07/:5:0","tags":["VAO"],"title":"VAO 基础入门（七） -  Plan Step · 上篇","uri":"/2020/02/vao-guide-07/"},{"categories":[],"content":"系列目录： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 通过之前的配置，我们的 VAO 就可以开始正常使用了，我们可以用 Plan Authors 角色的用户登入到 VAO 控制台上，在控制台中，将看到被授权允许能访问的 Scopes，并且可以对这些 Scopes 中的对象进行操作，包括 Orchestration Plan、DataLabs 和 Report。 要成功实现企业的灾备计划，达成企业的 RPO 和 RTO，除了需要超级强大的计算资源和工具软件之外，对于这个灾备工具的了解和熟悉程度也是非常重要的一部分。对于 VAO 来说，本身是一款非常强大的软件，但是需要灾备管理员非常清楚的了解灾备计划的每一部分以及它的操作的预期结果。所以成功的灾备计划第一步，我们先来看看 VAO 是如何工作的。 在这里我先使用user1@sedemolab.local这个 Plan Authors 角色的账号登入 VAO 系统中。它将看到房间 Scope A和房间 Scope B ","date":"2020-02-25","objectID":"/2020/02/vao-guide-06/:1:0","tags":["VAO"],"title":"VAO 基础入门（六） -  成功灾备计划的第一步","uri":"/2020/02/vao-guide-06/"},{"categories":[],"content":"Orchestration Plan VAO 中可以设定两类 Orchestration Plan，分别是恢复计划和故障切换计划，分别对应 VBR 中的 Backup 和 Replication 功能。这两个计划是整个灾备和恢复的基础，所有自动化的操作过程都将会通过这个 Plan 加入到灾备中去。在这里，我建议首先第一步，尽可能的不要加入太复杂的自动化脚本，而是用系统自带的 Plan Steps，用最少的流程来测试两类 Plan，等到熟悉了系统的工作机制后，再来逐步逐步添加适合的自定义脚本。 创建 Orchestration Plan，进入左边的 Orchestration Plans，在右边内容显示区域，会看到顶部的一排 4 个按钮，其中在 Manage 按钮所在的下拉菜单中，可以找到 New 的按钮。通过这个按钮可以启动 Orchestration Plan 的创建向导。 2. 打开向导后，首先需要选取使用哪个 Scope 来创建这个 Orchestration Plan，就像前几篇中提到，每个 Scope 中包含了灾备的一系列元素，而 Orchestration Plan 则是把这些元素组合起来，形成一个可执行的计划。所以每个 Orchestration Plan 是属于某个特定的 Scope 下的 Plan。 选择房间（Scope A）后，点击下一步。 设定 Plan Info，此处的内容一般来说按照实际的情况填写，这些都会在 Report 中被使用到。 选择 Plan Type，即决定这将是个 Restore 操作还是 Failover 操作，两者的唯一区别是，如果是 Restore Plan 那么将会增加一个 Recovery Location 的选项，选择我们这 Plan Components 之前设置好的 Location 即可。 选择 VM Groups，在当前 Scope 下能看到的所有可用 VM Groups 都会列在 Available Group 中，通过 Add 按钮将需要的 Group 添加至右边的 Plan Groups 窗格中。也可以通过 View VMs 来详细查看当前选定的 VM Groups 中所包含的 VM。 在 VM Recovery Options 中，需要设置 3 个内容： If any VM recovery fails then：如果 Plan 中有多台 VM 需要恢复，假如其中有一台 VM 恢复失败，此选项决定了后续的 Plan 如何操作，可以继续执行计划恢复其他 VM 或者是直接停止计划。 Recover the VMs in each Group: 按顺序恢复还是同时恢复。如果选择 Simultaneously 是同时进行，如果是选择 In Sequence 则是按顺序执行。 Recover simultaneously max of VMs：选择合适的数量，默认是 10 个，一般来说，管理员需要根据自己的计算资源情况，合理选择，最好执行一些测试后最后决定这里的数量。 Restore VM Tags：这个复选框下有个⚠️，一般来说恢复至新位置成为一个新 VM 则大多是不会选择这个恢复 Tags，避免和生产的 VM 混起来。 在 VM Steps 中，可以选择很多恢复过程中的可以用到的 Steps，默认情况下，系统自动会选上 Restore VM 和 Check VM Heartbeat 这两个 Step。我建议刚开始熟悉 VAO 的管理员逐项逐项的添加各种 Step，以测试每一种操作的功能，确定了某个需要的 Step 之后，再将其设计到自己的最终 Plan 之中。 在 VM 被恢复之后，为了确保系统的可靠性，VAO 还提供了立刻继续将恢复出来的 VM 备份起来的功能，在 Protect VM Groups 中勾选 Protect VM Groups after restore 并且选择合适的 Template Job 就行了。这里面的 Template Job 都是在 Plan Component 中所选择的。 对于灾备来说，非常非常重要的一个指标就是 RTO 和 RPO 了，通常在备份或者容灾软件中很少有看到这两个数值的设定，而在 VAO 中，灾备管理员可以为每个 Plan 来制定相应的 RTO 和 RPO 目标，如果达成这个目标，系统会显示绿色的状态，而如果无法达成这个目标，则会发出相应警告⚠️。 此项的设置，具体数值可以精细到分钟级别。 管理员还能在 VAO 中定义 Orchestration Plan 的报表，在 Plan 中只需要选择相关的模版即可，可以选择 pdf 或者 word 格式的报表。关于报表模版的设计，我将会在本系列的最后一节详细介绍。 选择完报表模版后，可以设定报表计划任务，个人感觉都是报表的内容，实际上没必要分成 2 个页面来设置，但是不管怎么样，根据 VAO 产品的设计，我们可以在这里设置每天报表的计划任务，需要注意的是，报表更新的任务是每天为频率的，只能选择每天的时间，不能有其他更多选择。 又是一个复选框占用一个页面，勾选之后，VAO 会在 Plan 创建完成后立刻进行灾备资源的可用性检查，根据实际情况选择即可。 以上就是所有设定步骤，在 Summary 中查看详细设置后点击 Finish 就能完成创建。创建完成后，这个 Plan 将会出现在 Orchestration Plan 的页面中。 对于创建好的 Plan，管理员可以对它做以下操作： Launch ：Run 和 Schedule Manage：Enable、Disable、New、Edit、Reset、Delete Verity：Datalab test 和 Readiness check Report 操作 一般来说，新创建的 Orchestration Plan 是处于 Disable 状态，也就是前面的图标是灰色的，需要点击 Manage-\u003eEnable 选项来激活它才能正常工作。 做了恢复或者故障切换操作之后，管理员需要通过 Manage-\u003eReset 按钮来重制这个 Plan 使其能继续工作，或者管理员还可以删除之前已经完成的 Plan，重新定义新的 Plan。 ","date":"2020-02-25","objectID":"/2020/02/vao-guide-06/:2:0","tags":["VAO"],"title":"VAO 基础入门（六） -  成功灾备计划的第一步","uri":"/2020/02/vao-guide-06/"},{"categories":[],"content":"Datalab 测试 在 Orchestration Plan 的 Verity 按钮下，可以找到 Run Datalab test 的按钮，点击这个按钮后，会启动一个 DataLab test 的向导，通过这个向导中选择一些合适的选项，可以对于整个灾备计划做一次近乎真实的演练，整个演练过程甚至会 100%模拟实际的 Restore Plan 和 Failover Plan 执行，包括了其中所有设置的自定义脚本，只是在分配网络的时候会选择 Datalab 的隔离网络。因此管理员能从这样的演练过程中清楚的掌握实际灾备环境中恢复的状况以及需要的恢复时间。 对于 Restore Plan 和 Failover Plan，Datalab test 会略微有些不同。 Restore Plan 选择 Restore Plan 后执行 打开向导后，首先需要选择在哪个 Datalab 中执行这个测试，在 Scope 下设定的所有可用 Datalab 都能够在这里找到。 选择快速测试还是完整测试，如果是快速测试，VAO 仅仅是通过即时虚拟机发布的方式执行这个测试，不执行后续的迁移操作，整个过程完成的相对比较快。 选择 Recovery Location，这和恢复步骤中的完全一致，只是在 Orchestration Plan 中已经选择过位置的，依然需要在此处再进行选择，此处的选择是为 Datalab test 专用的。 在自动测试完成后，选择是否要继续使用这些机器用于更多的测试，或者其他使用场景。在这里可以选择测试完成后立刻关机，也可以选择在测试后继续运行这个 Datalab 多少小时。 选择必要的 Lab Groups，和 VBR 中的 Application Group 一样，在这里可以按需选择，当然也可以不选择 Lab Group。 在 Summary 界面中查看当前的设置后，点击 Finish 就可以开始 Datalab 的测试了。 Failover Plan 选择 Failover Plan 后点击 Run Datalab test，选项就相对来说比较少了。这里不需要选择 test option 和 Recovery Location，直接进入 Power Options 和 Choose Lab Groups 的选择。 Schedule Datalabs Test 除了可以手工执行 Datalab test 之外，VAO 也可以全自动执行 Datalabs Test，以此来确保灾备的自动验证。在 VAO 的仪表盘中，找到 Datalab Calendar 部分，在这里可以看到 Create Schedule 按钮，就是用来设置全自动的 Datalab test 计划任务。同时，这个仪表盘也能过查看到已经设置的计划任务，来确认整个灾备的实施情况。 这个 Schedule 的设置向导和单次的 Run Datalabs test 大同小异，其中两个不一样的内容是，需要定制一个计划任务的时间，如下图： 选择哪几个 Plan 在这个 Lab 中测试。 以上这些就是最基础的 Orchestration Plan 和 Datalabs 测试的设置方式，成功设置并执行以上内容后，将为灾备成功迈出第一步打好基础。 更多内容欢迎关注本人公众号， ","date":"2020-02-25","objectID":"/2020/02/vao-guide-06/:3:0","tags":["VAO"],"title":"VAO 基础入门（六） -  成功灾备计划的第一步","uri":"/2020/02/vao-guide-06/"},{"categories":[],"content":"系列目录： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 在前几篇中，我们把 VAO 的基本架构、基本组件都盘点了一遍，所涉及到的内容都是在 Administration 中的设置，也就是具有 VAO 管理员权限的账户所能进行的操作。VAO 的管理员可以在这里为每组应用分别设定不同的 Scope，同时将这些 Scope 分派给相关的人员进行使用，利用这一特性，可以有效的进行分组和隔离，是不是有点类似多租户或者多用户？但是又有很大差异。 本篇内容针对之前所提到的这些配置，说明一些可能需要注意的地方。 ","date":"2020-02-21","objectID":"/2020/02/vao-guide-05/:1:0","tags":["VAO"],"title":"VAO 基础入门（五） -  基础配置要点","uri":"/2020/02/vao-guide-05/"},{"categories":[],"content":"基础架构 vCenter 添加 在安装和初始化配置过程中，我们把 vCenter 添加入 VAO 了，这时候之前的帖子如果大家有印象，可能会留意到我都没有提到过内嵌的 VBR 和 Veeam ONE 的配置，实际上在初始化配置完成之后，VAO 非常智能的将我们在初始化阶段填写的 vCenter 的信息写入到了 VBR 和 Veeam ONE 之中，因此我们不需要再次在 VBR 和 Veeam ONE 里面重新添加了。 VBR 添加 在 VAO 中，可以管理多个 VBR 或 Enterprise Manager 副本，在管理非内嵌的 VBR 时，需要做的只是通过推送的方式在 VAO 的控制台上，将 VAO Agent 推送到 VBR 上即可接管该 VBR。这个操作也相当简单，通过这样的方式，可以很方便的管理到一个大规模的备份/灾备环境。 Active Directory 在项目实施中，往往很多用户环境没有 Active Directory，而 VAO 又必须要有 AD 才能工作，这时候特别头疼，但是回过来其实这事情却又很简单。大家可以想想 VDI 的项目，也都是必须 AD 才能工作的，那他们那些项目不都得急死了？那倒不会的，因为很简单，没有 AD 我们就造个 AD 嘛，为了项目成功，没有条件创造个条件呗，这事完全难不倒我们这些攻城狮。 ","date":"2020-02-21","objectID":"/2020/02/vao-guide-05/:2:0","tags":["VAO"],"title":"VAO 基础入门（五） -  基础配置要点","uri":"/2020/02/vao-guide-05/"},{"categories":[],"content":"Scope Scope 特别难理解，但是想通了又特别简单，因此这个配置要点说明，我强烈建议大家回过去到我的第三篇，加强理解下 Scope 的概念，并且通过实战，到 VAO 中设置一些复杂的场景来理解这个 Scope。只有真枪实弹动过手，才能把这个 Scope 吃透，才能用好 VAO，这是最最关键的一个组件。 另外，对于 Scope，不能仅仅从 Users and Scopes 中去看这个 Scopes，需要从 Scopes 的 2 个维度结合起来看，这样这个概念才会生动的显现在我们面前： 授权使用这个 Scope 的用户； Scope 包含的 5 大 Components 和对应的 DataLabs； ","date":"2020-02-21","objectID":"/2020/02/vao-guide-05/:3:0","tags":["VAO"],"title":"VAO 基础入门（五） -  基础配置要点","uri":"/2020/02/vao-guide-05/"},{"categories":[],"content":"Datalabs 请先理解 VBR 中所有 DataLab 的配置，如果还不会配置 VBR 中的 DataLab，那么将会玩不转 VAO，因为这是 VAO 的必要组件和必要条件。 DataLabs 的配置在 VAO 中几乎没有任何操作，只是通过 Assign 的动作分配给对应的 Scope，在 VAO 中想知道自己的 DataLabs 是如何配置是件非常困难的事情，假如我们需要用到大量的 DataLabs，这时候可能只能回到 VBR 中逐个逐个点开配置去查看，这个非常不科学。那么我在这里有个很不错的小技巧可以提供给大家，在 VAO 的 DataLabs 信息中，会从 VBR 上取得这个 DataLabs 的 Name、Description、Platform 和 VBR Server Name，这时候大家完全可以利用好这个 Description，只需要在 VBR 中创建 DataLabs 时，将 Virtual Lab Summary 的内容 Copy 出来，贴到这个 Virtual Lab 的 Description 中，这样这段关于该 DataLabs 的详细配置情况就会被读取到 VAO 中，那么我们也就能够很清楚的知道这个 DataLabs 的具体配置了。如下图，最终我的效果。 ","date":"2020-02-21","objectID":"/2020/02/vao-guide-05/:4:0","tags":["VAO"],"title":"VAO 基础入门（五） -  基础配置要点","uri":"/2020/02/vao-guide-05/"},{"categories":[],"content":"Recovery Locations 设置相对复杂，而且设置完成后就固化下来了，然而这个只是一个计算资源的逻辑组合，他实际上只存在于 VAO 之中，不管在 vCenter、VBR 还是 VeeamONE 之中都不会有这个 Recovery Locations 存在。因此这也是一个非常好的消息，这个 Recovery Locations 无论设置成什么样子，他都不会影响除了 VAO 之外的其他任何组件的正常运行。 小小的 Tips 给到大家，那就是任性的去设置 Recovery Locations 吧，放肆的组合吧，就算不会被实际的 Orchestration Plan 使用到，放在那边又何妨？难说哪天有需要就用到了呢？ 当然，最终回归回来，在这里还是需要合理，合理的按需配置才能降低这套系统的复杂程度，最终实现为我们的高效的灾备服务。 以上就是 VAO 中 Administration 部分的配置要点，从下一篇开始，将进入真正的使用环节，谢谢大家关注本系列。 ","date":"2020-02-21","objectID":"/2020/02/vao-guide-05/:5:0","tags":["VAO"],"title":"VAO 基础入门（五） -  基础配置要点","uri":"/2020/02/vao-guide-05/"},{"categories":[],"content":"系列目录： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 ","date":"2020-02-20","objectID":"/2020/02/vao-guide-04/:1:0","tags":["VAO"],"title":"VAO 基础入门（四） -  基本组件 · 下篇","uri":"/2020/02/vao-guide-04/"},{"categories":[],"content":"Plan Components 以下这些组件，需要针对每个 Scope 进行设置，上一篇中已经介绍了具体设置位置，接下来我们来看看这些 Components 都有些什么以及他们的设置方法。 VM Groups VM Groups 定义了在这个 Scope 下面，能管理哪些虚拟机，简单来说就是圈一个范围，哪些虚拟机是属于这个 Scope 可以操作的，我们的 Orchestration Plan 针对哪些生产的 VM 进行操作。 和简单的 VM 勾选不一样的是，在 VAO 中，我们没办法很自由的去随意选择哪台 VM 属于哪个 Scope，在 VAO 中我们只能选择所谓的 VM Groups。 然而很尴尬的是，VAO 本身并不能创建任何的 VM Groups，这些 Groups 是通过 VAO 内嵌的 Veeam ONE 中的 Business View 引擎来获取的。Business View 的系统分组引擎是 VAO 中非常重要的一个组成部分，它的具体内容可以参考官网手册： https://helpcenter.veeam.com/docs/vao/categorization/about.html?ver=20 https://helpcenter.veeam.com/docs/one/monitor/bv_categorization_model.html?ver=100 在 Business View 的分组引擎中有 3 种使用方式： 1. vSphere Tags 2. 通过。CSV 文件导入 3. 通过 VeeamONE 的自定义分组策略 这 3 种方式并没有天然的特殊优劣，还是取决于 IT 管理员对哪种更熟悉，使用更便捷。 vSphere Tags 这个分组方式需要在 vSphere 上面进行，通过为不同的 VM 打入不同的 Tags 来实现分组，相同 Tags 名称的虚拟机会被归入同一个 VM Groups 中，而这个 VM Groups 的名称就是在 vSphere 中的 Tags 的名称。 这种分组方式无法在 Veeam 系统中做任何修改，只需要在 vSphere 上操作即可，操作完成后 VAO 中稍等一小段时间即可收到操作结果，这个操作是全自动的同步。 通过。CSV 文件导入 可以手工或者自动进行，这个操作需要在 VAO 内嵌的 VeeamONE 上进行，打开 VeeamONE Monitor 的控制台，在 Server Setting 中可以找到 Business View 的标签卡，在这里分别有自动从。CSV 文件同步的选项和手工立刻从。CSV 文件做单次导入的选项。 需要注意的是，这种方式导入的分组方式需要合理的组织。CSV 文件的结构，如下表所示： Server ObjectType MoRef Category1 server.local VirtualMachine vm-01 Group1 server.local VirtualMachine vm-02 Excluded 这个。CSV 文件可以是手工创建更新，也可以是第三方系统生成。 个人认为，这种方式比较呆，不那么容易使用。 通过 VeeamONE 的自定义分组策略 在 VeeamONE 的 Business View 视图下，右键菜单中会有 Add Category 菜单，这里可以打开 Category 的创建向导，这也是一种分组方式，可以根据一些特定的属性匹配来全自动实现分组，但是实际上使用过程中会发现这里的分组条件并不是那么的灵活，相比。CSV 会更加不容易使用。 因此，我还是推荐大家使用 vSphere Tags 来进行分组，在 vSphere 中操作完成后，只需要等待一段时间后，即可在 VAO 中出现相关 VM Groups。如下图所示： 这里面，VM Groups 的名称组合方式为 vSphere Tags Category Name - vSphere Tag Name ，因此我们看到 vSphere 上 VAO Backup 这个 Tag 到 VAO 中的 VM Groups 中显示为：VAO Tags Group - VAO Backup。选中这个 VM Group 后，在画面右边，可以看到该 VM Group 中包含的虚拟机列表，点击上方 Include 按钮，就可以把这个 VM Group 加入到当前选择的 Scope 下面。 Recovery Locations Recovery Locations 是我们的 Orchestration Plan 恢复时所要使用的物理计算资源，它包括了 Compute、Storage、Network 三大核心资源。转换成 vSphere 上，分别有如下的对应关系： VAO Recovery Locations 名称 vSphere 资源 Compute ESXi、Cluster Storage Datastore Network 虚拟交换机上的端口组名称 在 VAO 中，和选择 VM Group 一样，我们并不能直接选择某个 ESXi、Datastore 作为我们的 Recovery Location，只能通过 VAO 内嵌的 Veeam ONE 中的 Business View 引擎来获取的。和上的 VM Group 设置一样，我们可以通过 vSphere Tags 将 ESXi 或者 Cluster、Datastore 进行分组，分组完成后 VAO 就能读取到这些信息。稍微复杂一定，这些信息还需要通过 Recovery Locations 的添加向导进行一定顺序的编排，确保 ESXi、Datastore 和虚拟交换机上的端口组的对应关系。 Recovery Locations 是在 Administration 中 Configuration 下的 Recovery Locations 中设置的，进入这个设置界面后，会看到 VAO 已经内置了一个默认的 Recovery Location，这是还原到虚拟机的原始所在位置，对于这个默认的 Recovery Location，我们只能对他做编辑操作，并不能删除它，而编辑操作可调整的内容也非常少。 我们可以新建新的 Recovery Location 用于还原到一个新的位置。我们可以在这里创建多个 Recovery Location。通过 Add 按钮，我们可以打开添加向导： Location Info 中，只需要填入名称和描述即可。 Compute Resources 选择步骤中，将合适的 ESXi 或者 Cluster 对应的 Tags 选中点 Add 添加至这个 Recovery Location 中。当然这里的内容显示也不是那么的直观，VAO 提供了一个查看的按钮，点击右边的 View Resource 按钮，就可以看到这个 Tags 下面包含的 ESXi 或者 Cluster。如果此处的 Tags 是分配给某个 Cluster 的，那么在 View Resources 中只能看到 Cluster 的名称，并且在实际执行 plan 的时候 VAO 需要 Cluster 的 DRS 策略来决定将恢复出来的 VM 放置到哪个 ESXi Host 上。 Storage Resources 选择步骤中，请务必小心选择，在 VAO 中很弱智的一点是，即使这个页面上已经提示了 Only Storage resources available to the previously selected Compute resources are shown here，Storage Resources 依然会将部分无关的 Storage Group 罗列进来，只是在左边显示的时候并没有显示绿色的勾子，而是显示成绿色半圆加上白色半圆，这是对于以上的 Compute Resource 部分可用的意思，我们需要做的是确保选择的 Storage Group 是显示绿色勾子的，也就是必须对于我们上一层选择的 Compute Resources 是完全可用的，才能避免在后续的 Orchestration Plan 中出现各种告警和失败。 Resource Usage，设定存储资源的使用上限，确保存储资源不会被耗尽。 Instant VM Recovery，选择是否启用 IVR。 Re-IP Rules，在 VAO 中内置了灾备恢复或者切换后修改 IP 地址的功能，当我们需要对恢复的系统更换 IP 时，可以用这里的 Re-IP Rules 进行修改。根据这里设置的规则，VAO 自动对符合条件的系统应用这个规则。这个规则的设定也非常简单，它可以是 IP 子网的一一对应关系，换句话说，就是他只更换对应系统的子网，而最后一位的地址则不更换。比如，源虚拟机的地址是 10.10.1.25，对应规则是从 10.10.1.x 更换成 10.10.3.x，那么这个更换结果是 10.10.3.25。 当然这里也可以是单个 IP 地址 Re-Mapping。 Network Mapping 中，可以设定源 VM 的端口组至灾备端切换需要使用的端口组。这里会将源 vCenter 和目标 vCenter 中的所有端口组都罗列出来，我们只需要去选择一一对应关系即可，而不像前面的 Compute 和 Storage 那样在 vSphere 中设定 Tags 来实现。 在 Configuration 下面创建完 Recovery Locations 之后，我们需要在 Plan Components 中，为某个 S","date":"2020-02-20","objectID":"/2020/02/vao-guide-04/:2:0","tags":["VAO"],"title":"VAO 基础入门（四） -  基本组件 · 下篇","uri":"/2020/02/vao-guide-04/"},{"categories":[],"content":"系列目录： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 VAO 引入了一套非常特殊的概念，它为该产品中使用的组件定义了一系列名称，随着版本的更新和迭代，这里的组件和名称可能会发生一些变化。目前 VAO 的版本是 v2.0，因此本文所述内容仅适用于 v2.0 之后的版本，而后续版本中如果有新的变化，我会在后续的更新中说明。 ","date":"2020-02-19","objectID":"/2020/02/vao-guide-03/:1:0","tags":["VAO"],"title":"VAO 基础入门（三） -  基本组件 · 上篇","uri":"/2020/02/vao-guide-03/"},{"categories":[],"content":"Scope 定义和用途 Scope 是 VAO 的最核心的概念，在 v2.0 中首次引入了这个概念。每个 Scope 中包含了灾备中需要一系列元素，VAO 把这些元素称为 Plan Components： - VM Groups - Recovery Locations - Plan Steps - Credentials - Template Jobs 打个比方，Scope 是一间房间，那么在这个房间中所放置的各种家具就是以上这些 Plan Components。对于灾备来说，以上这些 Plan Components 将会在 Orchestration Plan 中被具体使用到。可以说 Orchestration Plan 是将这些 Plan Components 有序的组合起来，最终可以让我们实现一键的灾备恢复。 另外，Scope 中还有个非常特殊的 Component – Datalab，每一个 Datalab 对应某个 Scope 中，也就是说，每个 Scope 都有一个或多个独立的属于自己的 DataLab。 关于 Plan Components 和 DataLab，将在 VAO 基础入门（四）- 基本组件 · 下篇 中详细介绍。 分类和创建方式 VAO 中的 Scope 可以大致分为两类，一类是系统内置的名称叫Default的 Scope，这个 Scope 无法删除，无法修改名称，并且 Administrator 的 Role 会被包含在这个 Scope 中，在 VAO 的其他 Scope 中是无法选择添加 Administrators Role。当您要授予任何用户执行Administration配置操作时，您就需要将该用户添加至Default Scope 下的 Administrators Role。还记不记得在前一篇推送中提到的初始化步骤，在初始化过程中所添加的用户，默认就会被添加到这个 Administrators Role 下面。当然我们可以来添加更多的用户到 Administrator Role 中。 第二类是除了 Default 之外增加的 Scope，对于每一个 Scope，可以修改名称，可以删除。而这些 Scope 的 Roles 仅限于 Plan Authors。在每个 Scope 下的 Plan Authors Role 中，我们可以为这个 Scope 加入不同的用户。如下图所示。 在 VAO 中，这个 Scope 非常难理解，不过没关系，我还是来继续打这个比方： 我们可以把 Scope 想象成一个一个的房间，每个房间都会有把锁，而这把锁配了多把钥匙，我们现在把这些钥匙分给不同的用户，那么这些用户都能通过 A 钥匙进入房间（Scope A），通过 B 钥匙进入房间（Scope B），通过 C 钥匙进入房间（Scope C）。这样，就形成了 VAO 中特殊的一种权限的管理： 当前有房间（Scope）：A、B、C、D 用户 1：拥有房间 A、B 的钥匙。 用户 2：拥有房间 B、C、D 的钥匙。 用户 3：拥有房间 D 的钥匙。 转换成 VAO 中的 Scope 管理： 房间（Scope A）：用户 1 房间（Scope B）：用户 1、用户 2 房间（Scope C）：用户 2 房间（Scope D）：用户 2、用户 3 而分钥匙的方法，就是在 VAO 中设置User and Scopes，在 VAO 中，通过拥有 Administrator Role 的 User 登录后，可以至Administration界面下面，找到Permission-\u003eUsers and Scope来设定以上的管理权限，如下图： 按照这样设定完成后，我们用 User 1 再次登入 VAO 的系统后，我们可以看到 Dashborad 上显示的当前用户的 Scope 如下图所示： 类似的，User 2 登入系统后，将会看到房间 B、C、D，而 User 3 登入系统后，将只会看到房间 D。 配置 Scope 中的 Plan Components 进入Administration界面，在Permissions下，可以找到Plan Components，在这个界面上，可以为每个Scope设定每种 Components。如下图，可以在红框位置选择 Scope 来切换并且设定。 这里面大家可以注意到这是一个复选框，也就是说，可以同时选择多个 Scope 进行相关设定，但是为了更准确的设置相关内容，我还是建议大家逐个勾选设定会比较好。 ","date":"2020-02-19","objectID":"/2020/02/vao-guide-03/:2:0","tags":["VAO"],"title":"VAO 基础入门（三） -  基本组件 · 上篇","uri":"/2020/02/vao-guide-03/"},{"categories":[],"content":"Datalabs VAO 的 Datalab 其实就是 VBR 中的 Virtual Lab，只要在 VBR 中配置了 Virtual Lab 后，VAO 就能直接识别到。在识别到这些 Virtual Labs 之后，VAO 需要做一个分配的动作，将这些 Virtual Lab 按照实际使用的需求分配给不同的 Scope。特别注意，每一个 Virtual Lab 只能分配给一个指定的 Scope。 要分配 Datalab，可以使用 Administrator 账号进入Administration界面，找到Permission下面的Datalab Assignment，在这个页面下，勾选中间 VAO 扫描到的 Virtual Lab 名称，然后点击 Assign 按钮。 当点击了 Assign 按钮后会弹出 Assign Datalab to Scope 的对话框，在这里选择需要分配给哪个 Scope 即可。如下图所示。 如果需要调整或者重新分配 Datalab，可以勾选 Virtual Lab 名称，然后点击 Unassign 按钮，稍等片刻之后就可以重新分配给其他的 Scope 了。 Lab Groups 我相信熟悉 DataLabs 的同学一定会好奇，我们 VBR 上的 Datalabs 的功能包含三个核心组件：Virtual Lab、Application Group 和 Surebackup Job。那么在 VAO 中我们将 DataLab 和 VBR 的 Virtual Lab 做了一一的对应，剩下的 Application Group 和 Surebackup Job 去哪里了？ 在 VAO 中，也有一个和 VBR 中的 Application Group 一一对应的组件，那就是 Lab Groups。在 Administration 控制台中并没有这个 Lab Groups 的设定，这个 Lab Groups 需要使用每个用户的账号登入自己的 VAO 控制台中，用各自的账号进入 DataLabs 主页面进行设置。和 Virtual Lab 不同的是，Lab Groups 并不是从 VBR 的 Application Group 中继承，在 VAO 中，这个 Lab Group 是全新创建的，需要用 VAO 中的对象来创建。 一般来说，Lab Group 可以保持空的状态，这和我们之前在 Application Group 的说明中提到的完全一致，除非是业务有依赖关系，必须依赖某个系统才能运行，那么此时，我们需要将这个被其他系统依赖的系统放入 Lab Group 之中。 而 Surebackup Job，在 VAO 中就不需要用到了，这个 Job 会自动集成入 Orchestration Plan 之中，这里就不展开讨论，在后面的章节会详细介绍。 以上就是本章节的主要内容，谢谢关注。 ","date":"2020-02-19","objectID":"/2020/02/vao-guide-03/:3:0","tags":["VAO"],"title":"VAO 基础入门（三） -  基本组件 · 上篇","uri":"/2020/02/vao-guide-03/"},{"categories":[],"content":"系列目录： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 ","date":"2020-02-18","objectID":"/2020/02/vao-guide-02/:1:0","tags":["VAO"],"title":"VAO 基础入门（二） -  安装与部署","uri":"/2020/02/vao-guide-02/"},{"categories":[],"content":"VAO 安装包获取 Veeam 官网可以直接下载 VAO，直达电梯 这个安装包是一套完整的 VAO 套件，其中包括 VAO 主程序、内嵌的 VBR 以及内嵌的 VeeamONE，需要注意的是，这个安装包虽然包含了内嵌的 VBR和内嵌的 VeeamONE但是这两个软件都无法被提取出来单独安装，这两个内嵌的软件都是 VAO 工作的必要组件，它们是跟着 VAO 一起工作的。 这两个内嵌的 VBR 和 VeeamONE 和正常的软件没有任何区别，在安装完 VAO 后可以以常规的访问方式访问使用，目前在这个安装包中包含的 VBR 是 9.5U4 版本，VeeamONE 是 9.5U4 版本；在 VAO 安装完成后，使用 VBR 和 VeeamONE 的正常升级方式将这两个组件升级至 9.5U4a 或者 4b 的版本。 ","date":"2020-02-18","objectID":"/2020/02/vao-guide-02/:2:0","tags":["VAO"],"title":"VAO 基础入门（二） -  安装与部署","uri":"/2020/02/vao-guide-02/"},{"categories":[],"content":"安装前提条件 非常重要的两点提示： 请不要在已经安装了 VBR 或者 VeeamONE 的服务器上安装 VAO 软件包。 请不要在域控制器上安装 VAO 软件包。 一般来说，我们建议不管您是否已经安装了 VBR，如果是进行 VAO 的安装，都应该准备一台全新的 Windows 服务器来安装 VAO 的安装包。 安装完成后，您可以将您原来的 VBR 加入到 VAO 环境中来由 VAO 纳管，也可以使用 VAO 内嵌的 VBR 来进行常规的备份和复制任务。 其他更多的安装前提条件，请参考官网的 前提条件说明。 ","date":"2020-02-18","objectID":"/2020/02/vao-guide-02/:3:0","tags":["VAO"],"title":"VAO 基础入门（二） -  安装与部署","uri":"/2020/02/vao-guide-02/"},{"categories":[],"content":"安装过程 安装包是个 ISO 文件，通过挂载 ISO 的方式打开这个镜像后自动运行，可以找到 VAO 的安装按钮： 整个安装过程非常简单，和 Veeam 其他产品的安装一样，跟着向导无脑点完下一步就能做完最基础的安装，安装完成后，请务必将 VBR 9.5U4a 和 VeeamONE 9.5U4a 的补丁打上，这一步千万不要忘了，因为 9.5U4a 这个补丁修复了很多 VAO 碰到的问题。 关于 VBR 9.5U4a 的升级，同样也可以参考我之前的 博文。 需要注意的是，在安装过程中会要求输入用户名密码，此处的用户名密码为 VAO、VBR、VeeamONE 的服务和它们的数据库需要使用的用户名密码，因此此密码要求的最小权限为这台 VAO Server 的 Windows 本地管理员权限，隶属于本地 Administrators 组即可。 这个账号虽然和后续灾备所使用的灾备管理员的账号没有任何关系，但是在后续的初始化配置的第一步需要输入此账号来登入 VAO 的 UI 界面。 ","date":"2020-02-18","objectID":"/2020/02/vao-guide-02/:4:0","tags":["VAO"],"title":"VAO 基础入门（二） -  安装与部署","uri":"/2020/02/vao-guide-02/"},{"categories":[],"content":"初始化配置 安装结束后，请不要去打开内置的 VBR 和 VeeamONE 的控制台，请立刻开始初始化配置，系统只有在初始化配置完成后才能够正常工作，进入初始化配置的界面请访问：https://VAOIP:9898/ 这时候浏览器会提示输入用户名密码，请使用上图安装时所用到的用户名密码作为初始化登入使用的用户名密码。特别注意，这个密码只在初始化配置时使用 1 次，在初始化配置完成后，将会使用初始化配置过程中设定的 VAO 灾备管理员的用户名密码。 登入账号后，系统进入初始化向导，Welcome 页面中有些信息，有兴趣的话可以阅读一下，这页很简单，只需读完后点击 Next。 输入一些 VAO 服务器的基础管理信息，这些信息在后续的文档模板中都会有用到。当然这些信息在配置完成后都能在 Configuration 中进行修改，不用担心填错。 此处需要填入 VAO 灾备管理员的账号，需要注意的是，此处的账号为初始化配置结束后登入 VAO UI 的灾备管理员的账号，此账号需要属于域账号，因此在整个 VAO 的部署中，Active Directory 是必要条件，如果环境中没有 AD 域，那就创建一个 VAO 专用的 AD 域吧。 请一定记住此处填入的灾备管理员的账号，在这个向导结束后，安装阶段使用的本地管理员账号将再也无法登入系统进行初始化配置，替代的是此处填入的账号。 接下来进入 VBR 的配置界面，假如您的系统中已经有 VBR 在工作了，您希望新部署的 VAO 和之前已经在使用的 VBR 一起工作，那么请在这一页中填入已有的 VBR 系统或者 Enterprise Manager 的服务器地址。 否则，请点击 Skip 跳过此页配置，使用 VAO 内嵌的 VBR 来作为主备份服务器。 对于很多全新的环境来说，一般部署的时候都可以选择 Skip 跳过此页，而使用内嵌在 VAO 系统中的 VBR 进行备份和复制作业。 本文将不讨论和已部署 VBR 的环境混合使用，因此后面的文章只限于讨论不输入 VBR 地址，直接点击 Skip 跳过 VBR 的配置。 在跳过 VBR 配置后，进入 vCenter 的配置，这里我们可以将生产站点的 vCenter 管理员账户填入到此处，为了方便配置，我们建议配置一个专用于 VAO 的账户，且该账户隶属于 vCenter 权限中的管理员权限组。 此步骤也是在这个向导中的非必要步骤，但是需要注意的是，vCenter 为 VAO 工作是必须连接的组件，即使在此处点击 Skip 跳过后，依然需要在后续的 Configuration 中将 vCenter 配置上去，并且需要在 Configuration 中将每一个会使用到的 vCenter 注册到 VAO 中。 另外，VAO 不支持 ESXi 直连方式工作，因此没有 vCenter 的环境将无法使用 VAO。 配置完以上步骤后，点击 Finish 就能完成所有的初始化配置。在点击完 Finish 后，网页将会重新刷新回到最开始的 VAO UI 登入界面，使用上面第四步中设定的账号密码就能登入 VAO 正式的 UI 界面了。 欢迎各位来到 VAO！接下去就可以正式开始使用 VAO 了。在下一篇中，我会详细介绍 VAO 的各个组件。 ","date":"2020-02-18","objectID":"/2020/02/vao-guide-02/:5:0","tags":["VAO"],"title":"VAO 基础入门（二） -  安装与部署","uri":"/2020/02/vao-guide-02/"},{"categories":[],"content":"随着 Veeam 旗舰产品 Veeam Availability Suite v10 的发布，Veeam Availability Orchestrator（以下简称 VAO) 也会在不久更新为 v3.0 版本，目前来说 VAO 产品还是处于 v2.0 版本。对于绝大多数同学来说，可能这个产品非常神秘，看似功能非常高大上，但是也不知道如何使用，我的这个基础入门系列将会和大家分享一些本人对于 VAO 的一些研究。 ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:0:0","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"什么是 VAO？ 简单来说，他是 VAS 加强版。它需要和 VAS 一起工作，离不开 VAS；VAO 还需要和 VMware vSphere 一起工作，它仅限于支持 VMware 的虚拟化环境。 能够通过软件的设置，来保证企业实施的灾备基础架构的满足所要求的 RPO 和 RTO； 能够尽可能自动化的完成灾备的切换过程，该操作同时支持备份存档和复制存档； 能够通过数据实验室，来确保灾备的精准可靠，所有灾备演练将在数据实验室中 1:1 的完整演练。 VAO 替代了 VBR 中 Recovery、Failover 以及 Surebackup 的操作，可以说是对于这 3 个关键操作的进一步加强，在这些关键操作中，可以加入各种自定义的步骤和脚本，使之能够更加接近实际业务场景中的使用。对于管理员来说，合理的设计这 3 个操作中的额外步骤能极大程度的降低 IT 运维中灾备流程的复杂度。 ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:1:0","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"VAO 支持哪些场景使用？ VAO 支持的数据中心从简单到复杂，都可以使用，以下仅简单从最基本的架构举两个例子： ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:2:0","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"单个数据中心 单个数据中心内，加入 VAO 的组件后，和原有 VAS 的架构几乎没有太大差别，所有 VBR 上的操作不会有任何改变，常规的所有备份恢复操作都在 VBR 上可以完成，而 VAO 则在这里开始担当关键业务的 RPO 和 RTO 的确保任务。通常来说关键业务出现宕机后，都会在原始位置实现恢复，因此也没有特别的专用资源用于恢复准备。 因此，在这种场景下，唯一需要改变的是选择一些关键的 VM，由 VAO 来接管这些 VM 的 RPO 和 RTO。 ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:2:1","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"一主一备数据中心 稍微复杂点，也是很典型的场景，就是跨区域的主备数据中心，主中心承担生成业务，而备中心承担灾备业务。我们通常 VAS 的设计会将备份存档拷贝到灾备中心进行存放，也可能会将一些关键的 VM 直接 1:1 的复制到灾备中心。而这时候，在灾备中心的数据恢复流程都将可以被编制到 VAO 的 Failover Plan 或 Recovery Plan 中，同时这些 Plan 也将会被在相应的 Datalabs 中做完整的恢复演练。 这种场景下，原先 VAS 的架构也没有太大变化，和单数据中心非常相似，只是我们可以规划一部分资源专用于灾备恢复。 ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:2:2","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"VAO 支持的两种 Plan VAO 本身并不提供备份和复制功能，所有对于源数据的提取功能，都会在 VAS/VBR 中完成。VAO 中提供了两种 Plan：Restore Plan 和 Failover Plan。 ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:3:0","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"Restore Plan 这是对应 VBR 中的 Backup \u0026 Restore 功能，所有对备份存档（.vbk，.vib，.vrb 等）的恢复，都归为这一类。 ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:3:1","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"Failover Plan 这是对应 VBR 中的 Replication \u0026 Failover 功能，所有对于 Replicas 的故障切换，都归为这一类。 这两种 Plan 支持的操作： - DataLabs 测试 - 资源可用性测试 - 完整报告自动生成 - 一键式全自动恢复、故障切换 ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:3:2","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"VAO 额外支持的 DataLabs 功能 作为 Veeam 产品看家本领，DataLabs 功能在 VAO 中也是极大增强，在 VAO 中不仅能将 DataLabs 用于以上两种 Plan 的测试，还能利用 VAO 中强大的脚本和步骤添加功能，自动化的生成各种复杂的用于测试的环境。通过这种增强，复杂的测试用例，复杂的环境部署工作将会被简化成一键式的按钮，极大提升 DataLabs 的使用效率。 以上就是 VAO 的简介，欢迎关注 VAO 基础入门系列，在最近一段时间我会陆续更新以下内容： VAO 基础入门（一）- 简介 VAO 基础入门（二）- 安装与部署 VAO 基础入门（三）- 基本组件 · 上篇 VAO 基础入门（四）- 基本组件 · 下篇 VAO 基础入门（五）- 基础配置要点 VAO 基础入门（六）- 成功灾备计划的第一步 VAO 基础入门（七）- Plan Step · 上篇 VAO 基础入门（八）- Plan Step · 下篇 VAO 基础入门（九）- 文档模板解析 ","date":"2020-02-17","objectID":"/2020/02/vao-guide-01/:4:0","tags":["VRO"],"title":"VRO v6 基础入门（一） -  简介","uri":"/2020/02/vao-guide-01/"},{"categories":[],"content":"前言 Veeam 即将推出全新的 v10 版本，在这个版本中，Veeam 支持从以前的 VBR 升级至 v10 版本，整个平滑升级过程不算复杂，和以往的 VBR 升级一样，当然也有一些细节需要注意。 ","date":"2020-02-13","objectID":"/2020/02/how-to-upgrade-vbr/:1:0","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2020/02/how-to-upgrade-vbr/"},{"categories":[],"content":"升级前 请按照下面的流程图检查当前环境，在升级 VBR 之前确保其他组件已经正常升级。 由于 v10 开始，Veeam 将使用全新的 Veeam Universal License（VUL），所以请提前登陆 My.veeam.com 获取更新后的 License，在升级过程中将会提示使用新的 License 激活产品。 ","date":"2020-02-13","objectID":"/2020/02/how-to-upgrade-vbr/:1:1","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2020/02/how-to-upgrade-vbr/"},{"categories":[],"content":"升级方式 可以采用两种方式升级，没有太大区别。 在原 VBR 服务器上原地升级； 全新安装一台 VBR 服务器，然后将 Configuration Backup File 还原至这台全新安装的 VBR 中。 由于第二种方式和全新安装几乎没有任何区别，因此本文不详细展开讨论，而只讨论第一种原地升级方式。 ","date":"2020-02-13","objectID":"/2020/02/how-to-upgrade-vbr/:1:2","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2020/02/how-to-upgrade-vbr/"},{"categories":[],"content":"升级准备 准备好 Veeam 升级介质，Veeam 的产品非常简单，升级介质和全新安装使用同一个介质包，只需要把产品包挂载到 VBR 服务器上即可。在执行 Upgrade 之前，需要做一系列准备工作： 仔细阅读 Release Notes，检查自己环境，看看是否有不支持的系统。 - VMware vSphere 5.1 以及之前的版本 - Windows 2003 和 XP - Microsoft SQL Server 2005 使用 Veeam Configuration Backup 功能，将 VBR 的配置做一个备份，这个备份请确保是用 Encrypted 模式，这样所有在 VBR 中使用的用户名和密码将会妥善的被保存在。bco 文件中。 检查 VBR 上面的所有备份作业，确保没有任何作业正在运行，这里要特别注意如下作业，需要手工点击 Disable 来停止： - Backup Copy Job - SQL、Oracle 的日志备份作业 ​ 看看是否有 Instant VM Recovery 正在运行； ​ 看看是否有 Veeam Explorer 正处于打开并在执行恢复； ​ 看看是否有 Surebackup/Virtual Lab 正在运行。 最终，所有任务都停止后，会是如下图状态： ","date":"2020-02-13","objectID":"/2020/02/how-to-upgrade-vbr/:1:3","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2020/02/how-to-upgrade-vbr/"},{"categories":[],"content":"升级过程 整个升级过程非常简单，只需要按照向导点击几下鼠标，然后静静的等待 30 分钟以后，软件就能升级完成，因此在这里我就不详细去一步一步说明这个过程了。 ","date":"2020-02-13","objectID":"/2020/02/how-to-upgrade-vbr/:1:4","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2020/02/how-to-upgrade-vbr/"},{"categories":[],"content":"可能碰到的问题 升级过程中，升级包会首先停止 VBR 的所有服务，有可能碰到停止服务超时或者失败，导致升级过程中断，建议碰到失败后首先检查下 Services.msc 中 veeam 开头的服务是否被正常停止。 服务都正常停止后，原地升级如果还报错，建议可以把 VBR 服务器重启一下后，再尝试升级，这里特别注意一下，在 VBR 重启后，需要重新检查所有 VBR 的作业，确保没有作业在自动运行。 如果尝试多次都无法进行正常升级，建议使用上面提到的方法二，全新安装一台 VBR，然后将 Configuration backup 文件导入。 如果以上方法全部失败，请及时联系 Veeam Support 团队，我们的攻城狮将会及时为您提供升级支持。 以上就是升级的一些小提示，感谢阅读！ ","date":"2020-02-13","objectID":"/2020/02/how-to-upgrade-vbr/:1:5","tags":["VBR"],"title":"Veeam 备份服务器升级指南","uri":"/2020/02/how-to-upgrade-vbr/"},{"categories":["黑科技"],"content":"好久好久没更新这个黑科技系列了，今天带来一篇想写了很久的功能。 这项创造性科技我认为是可以在 Veeam 功能实用性排行榜上排上前三的。而绝大多数 Veeam 使用者我相信也几乎不知道有这个科技的存在。它就像个默默无闻的老黄牛，出现在每一个 Backup/Replication 的作业中，为每一台 VM 保驾护航。 ","date":"2019-07-24","objectID":"/2019/07/snapshot-hunter/:0:0","tags":["VMware"],"title":"黑科技 | 激活隐藏在 VBR 中的快照猎手","uri":"/2019/07/snapshot-hunter/"},{"categories":["黑科技"],"content":"Snapshot 基础知识 VMware 的 Snapshot，自从有了虚拟化技术之后，可以说是虚拟化领域最具争议的技术。很多人因为喜欢快照技术开始入门虚拟化，很多人因为痛恨快照技术弃用一些解决方案和功能。而对于备份软件来说，想做好虚拟化的备份，不得不面对快照技术，修炼快照基本功是一门必修课！ Veeam 产品中大量使用 VMware 快照技术，在任务发起时，会通过 API 接口发送快照指令给 vSphere，这时候有个名叫***“VEEAM BACKUP TEMPORARY SNAPSHOT”***会出现在虚拟机的快照管理器中。而任务结束时，Veeam 会再一次发送指令要求 VMware 删除该快照。 这时候，因为涉及到基础架构中多个产品之间的互相通讯，往往会出现一个结果，就是这个临时快照并没有被删除，甚至是出现一些“假删除”的情况。也就是说，表面上从快照管理器中看到已经不存在快照了，而实际上在 vSphere Datastore 中，依旧存在 00001.vmdk 这样的快照差异磁盘文件。VMware 中，这种快照文件一般被称为孤立的快照（Orphaned snapshot），通常这种快照如果存在，后续的正常的快照都会受影响，而 VMware 的快照管理器中也会提供相应的“整合快照选项”。 然而情况往往并没有那么乐观，这个问题不那么容易被发现，而这个整合也不那么顺利能进行。在有些时候往往就会碰到报错而进行不下去的状况，这种情况我们统称为** Snapshot issue**。而出现这种情况多数是因为没有及时去处理这个潜在的 Orphaned Snapshot。 我这里提供几个 VMware 官网的 KB，算是小福利哦，能够帮大家更快处理这类 issue。 https://kb.vmware.com/s/article/1005049 https://kb.vmware.com/s/article/1006847 https://kb.vmware.com/s/article/1038963 https://kb.vmware.com/s/article/2003638 ","date":"2019-07-24","objectID":"/2019/07/snapshot-hunter/:0:1","tags":["VMware"],"title":"黑科技 | 激活隐藏在 VBR 中的快照猎手","uri":"/2019/07/snapshot-hunter/"},{"categories":["黑科技"],"content":"快照猎手 如果不想那么麻烦，手工去做这么复杂的快照整合操作，那么可以试试 Veeam Backup \u0026 Replication。在 VBR 中，有个特殊功能，能够全自动处理这些 Snapshot issue，我们称他为“快照猎手”。 通常这个功能会在每个备份和复制的 Job 中自动执行，因此对于一般用户而言，这个功能在后台全自动的进行。Veeam 会全自动处理可能碰到的一切快照 Issue。它的处理过程分为两大类： 检测是否有上次备份后残留的 Veeam 辅助快照“VEEAM BACKUP TEMPORARY SNAPSHOT”，如果有，将会在备份之前提前删除该快照。这个过程确保历史任务中遗留的 Veeam 快照会被处理干净。 检测是否存在孤立的快照，如果有，尝试将它整合。这个过程确保除了上一种情况之外的所有情况都会被政策修复。 而对于第二步过程，Veeam 又会采用一组复杂的整合算法，这个算法是综合了上文提到的 4 个 VMware 官方 KB 的精华。 普通的 VMware 快照整合方法 这个和 VMware 菜单上的 Consolidation 按钮功能完全相同，如果正常能用 VMware 菜单上 Consolidation 按钮整合完成的，那么事情非常简单，Veeam 会用这个功能立刻完成整合。 强制整合，不带静默 如果上一种方式失败，Veeam 就会执行第二种方法，这种方法 Veeam 会借助快照技术，创建一个新的快照，然后调用 VMware 的*** Delete all snapshot***命令，通过这种方式一把移除所有孤立快照，恢复磁盘状态。 强制整合，带静默 如果上一种方式还是失败，Veeam 会执行第三种方法，这种方法会创建 VMware 静默快照，然后再次使用*** Delete all snapshot ***命令。 如果以上 3 种方法都失败 Veeam 会发失败警告给用户，建议手工处理孤立快照，避免生产存储被撑爆。 最后，我还会有个视频，来给大家 Demo 一下快照猎手，近距离感受下快照猎手的强大。 好了，感谢收看今天的内容，下期再会！ ","date":"2019-07-24","objectID":"/2019/07/snapshot-hunter/:0:2","tags":["VMware"],"title":"黑科技 | 激活隐藏在 VBR 中的快照猎手","uri":"/2019/07/snapshot-hunter/"},{"categories":["数据恢复"],"content":"安全和备份是 IT 架构中两大重要的基础组件，通常情况下无论是个人家用和企业商用，都是必不可少的。然而很尴尬的是，作为安全类的杀毒软件，需要面对各种病毒和木马以及他们的变种，甚至是不断出现的新型病毒。有些病毒软件还具备了反杀毒功能，可以反向击杀杀毒软件，令人防不胜防。 传统 IT 中，为每一台操作系统安装杀毒软件的方法显然不足以做到全面的防护，甚至是很容易被病毒软件破坏。而结合虚拟化技术之后，杀毒引擎被整合入虚拟化层，利用虚拟化的技术可以避免很多传统杀毒软件植入式安装带来的问题。 然而这依旧无法解决一个重要问题，就是每款杀毒软件都有自己的强项，再优秀的杀毒软件都有需要更新病毒库的时候，总有那么一些病毒，是无法被某个软件杀死的。根据 AV-Test 的报告，市面上的杀毒软件种类几十种，查杀能力在不同版本时各不相同。 前些天，在设计一个分布式的备份架构设计时，突然想到 Veeam 的 Mount Server 的特殊作用：可以在不同的 Mount Server 上安装不同的杀毒软件，形成多套不同杀毒引擎。使用 Secure Restore 时，只需要合理选择 Mount Server 即可实现使用不同的引擎进行病毒查杀。 ","date":"2019-07-18","objectID":"/2019/07/secure-restore/:0:0","tags":["VMware"],"title":"恢复 | 让那些病毒木马无所遁形","uri":"/2019/07/secure-restore/"},{"categories":["数据恢复"],"content":"操作方法 ","date":"2019-07-18","objectID":"/2019/07/secure-restore/:1:0","tags":["VMware"],"title":"恢复 | 让那些病毒木马无所遁形","uri":"/2019/07/secure-restore/"},{"categories":["数据恢复"],"content":"配置 Mount Server 在 VBR 中，Mount Server 是个很基本的组件，没有太多要求，只需要是一台 Windows Server，并且是 Veeam Managed Server，即可成为 Mount Server。如果说一定得有个前提条件，我觉得应该是网络上，作为 Mount Server，这个 Windows 就必须要能够和 VBR 通讯，也必须要和 Repository 通讯。具体通讯端口要求，可参看官网手册。 https://helpcenter.veeam.com/docs/backup/vsphere/used_ports.html?ver=95u4#mount 进入 VBR console 后，只要找到 Backup Infrastructure 下面的 Managed Servers 节点，在其中将希望添加的 Windows Server 添加进去即可。 添加方式是经典的 Veeam 向导模式： 首先填入 Mount Server 的 FQDN 或者 IP 地址，描述中可以填入杀毒软件名称用以识别。 下一步后填入管理员用户名密码，用于推送安装 Mount Server 的组件。 预览需要安装的组件，并完成添加。 ​ ","date":"2019-07-18","objectID":"/2019/07/secure-restore/:1:1","tags":["VMware"],"title":"恢复 | 让那些病毒木马无所遁形","uri":"/2019/07/secure-restore/"},{"categories":["数据恢复"],"content":"为 Repository 选择 Mount Server 由于每个 Repository 都有其一一对应的 Mount Server，因此当我们要用到某个特殊的杀毒软件时，我们只需要编辑 Repository 的设定，选择对应的 Mount Server 即可。 剩下步骤，就是进入各种支持 Secure Restore 的恢复操作中，执行正常的恢复步骤。 以上就是今天的内容，不是很复杂，但是很有意思，希望能帮助到被病毒困扰的管理员们。 ","date":"2019-07-18","objectID":"/2019/07/secure-restore/:1:2","tags":["VMware"],"title":"恢复 | 让那些病毒木马无所遁形","uri":"/2019/07/secure-restore/"},{"categories":["数据恢复"],"content":"昨天的推送中，介绍了《备份软件的安装和备份方法》。不讲一下恢复，我觉得大家一定会认为我在耍流氓。那么今天的这篇，我就来详解下 Veeam Agent for Microsoft Windows 免费版的数据恢复方法。 ","date":"2019-07-03","objectID":"/2019/07/agent-backup-and-restore/:0:0","tags":["Agent"],"title":"送 | 从送你的备份中恢复数据方法详解","uri":"/2019/07/agent-backup-and-restore/"},{"categories":["数据恢复"],"content":"三大恢复场景 备份方法只有一种，但是做完备份后，Veeam 最擅长是给你无数种恢复方法，让你用最短的时间恢复你想要的数据。 ","date":"2019-07-03","objectID":"/2019/07/agent-backup-and-restore/:1:0","tags":["Agent"],"title":"送 | 从送你的备份中恢复数据方法详解","uri":"/2019/07/agent-backup-and-restore/"},{"categories":["数据恢复"],"content":"1. 文件还原 最方便的是打开 Veeam Control panel，点击任何一个柱状条，每一个柱状条就是一个还原点。 点击进去后，能够看到增量备份的详细日志，而在窗口最下方，可以看到两个按钮，其中一个是还原单个文件，另外一个则是整卷还原。 点击 Restore Files，可以打开文件级还原的浏览器。这个窗口和我们常用的 Windows 资源管理器非常相似，在这里我们可以浏览到备份存档中的所有文件，提取里面的单个文件进行恢复。Veeam 提供了还原、覆盖、复制和查看属性等一系列丰富的操作，完成数据恢复。 如果觉得这个还不够，点击 Open in Explorer 按钮还能直接在 Windows 资源管理器中打开，那么这时候，你可以查看备份存档中的任意格式的文件，找到需要的内容进行恢复。 ","date":"2019-07-03","objectID":"/2019/07/agent-backup-and-restore/:1:1","tags":["Agent"],"title":"送 | 从送你的备份中恢复数据方法详解","uri":"/2019/07/agent-backup-and-restore/"},{"categories":["数据恢复"],"content":"2. 整卷还原 文件还原隔壁的按钮就是整卷还原了。 点开来以后依旧是 Veeam 向导，用来做整卷恢复，由于是直接从备份作业中点开的向导，所以可以省去备份存档的选择步骤，直接进入还原点选择。 点击 Next 以后进入磁盘分区的映射 映射完成后就进入恢复了。 因为操作系统运行的关系，整卷还原需要非常小心，有一些需要注意的地方： 不能将操作系统所在的卷还原到正在运行中的原系统。 不能将操作系统卷还原至有 windows swap 文件所在的卷 不能将卷还原至存放着 vbk 文件的磁盘分区中。 ","date":"2019-07-03","objectID":"/2019/07/agent-backup-and-restore/:1:2","tags":["Agent"],"title":"送 | 从送你的备份中恢复数据方法详解","uri":"/2019/07/agent-backup-and-restore/"},{"categories":["数据恢复"],"content":"3. 整机还原 当你的整个系统崩溃以后，可以进行整机恢复。使用之前配置的 ISO，最方便的方法是刻录成一个可引导的 U 盘，用该 U 盘来启动系统。这时候系统会进入一个 Windows PE 恢复界面。 这是 Veeam 免费提供的非常强大的恢复套件，除了整合了 Veeam BMR 之外，还会有一些系统急救修复工具，就算不是用 Veeam BMR 功能，这个急救包也能在关键时刻起作用。 如果 U 盘引导的系统就是原来的电脑，这时候网卡驱动会自动被识别出来。 对于 BMR，恢复方式也是经典的 Veeam 向导方式。点击 Bare Metal Recovery 就可以进入向导。 进入向导后，如果找不到本地磁盘驱动器，还可以加载磁盘驱动，来识别磁盘内的备份数据，当然比较简单的方式就是直接使用 Network Storage，找 NAS 中的数据。 选择 Share Folder 后，点击 Next，可以进行 NAS 的一些简单配置，依旧是 CIFS 的的 UNC 路径，必要的情况下需要输入用户名和密码。 如果配置文件夹路径正确，点击 Next 之后，就可以读取到文件夹中的所有备份存档。 选择合适的备份存档之后，点击 Next 进入还原点的选择。 点击 Next 选择还原模式。可以进行整机还原，也可以只还原系统卷，最强大的是可以支持定制手工还原的高级模式，进行分区的重新构建和映射。 设置完磁盘映射后，就能开始还原过程，经过一段时间的等待，系统将会被恢复出来。 这么好的免费产品还有技术支持？ 这是真的，如果你碰到问题，你的英语足够好，你可以在 Veeam Control Panel 中找到 Support 界面 这里你可以通过在线文档和在线论坛来查找资料和提交反馈意见，更重要的是，还有原厂的技术支持，通过 Technical Support 来提交一个 case。 如果是免费用户，那么当我们的技术支持工程师空闲的时候，我们会尽量通过邮件的方式来回复你碰到的问题。 今天的内容看上去比昨天的备份还要短，还要简单，如果昨天还没用上 Veeam 的，今天赶紧装一套吧，数据备份永远不会晚，快点备份起来吧。 更多内容，可以关注我的公众号，下一期我会来介绍一些备份的场景，可以更近距离来接触这套优秀的个人备份软件。 ","date":"2019-07-03","objectID":"/2019/07/agent-backup-and-restore/:1:3","tags":["Agent"],"title":"送 | 从送你的备份中恢复数据方法详解","uri":"/2019/07/agent-backup-and-restore/"},{"categories":["数据保护"],"content":"上一个时代的 Norton Ghost 不知道有多少人还记得 Norton Ghost，我对于 Ghost 的记忆要追溯到刚接触到 PC 那段时间，差不多 20 年前吧，那是在电脑城装完组装机，第一件事情就是使用 Ghost 做一个系统备份。 而也是从那时起，Ghost 成为每一个电脑的标配。一直到 10 年前的 Win7 时代甚至是今天的 Win10，很多个人电脑的启动项中还保留着两项，其中第二项就是，“使用一键 Ghost 恢复系统”。可以说，Ghost 在那时，几乎是人手一个。 确实，Ghost 非常好用，但是这已经是上一个时代的工具了，Symantec 旗下 Norton Ghost 团队也早在 2013 年 3 月底就停止更新和支持这款工具了。流传在民间的这一工具仅剩可用的版本也一直停留在 v11 版本，实在是有点可惜。 不过没关系，虽然 Ghost 没了，但是我们现在有了一个完美的替代品，这就是 Veeam Agent for Microsoft Windows 免费版！ 今天的主题，我思考了许久，开始一直担心大家对免费软件的看法。通常我们大多数会想到的是，残缺的功能，黑心厂商为了赚钱挖了好多坑，使用中还会不断来一些广告和提醒，告诉你得赶紧付费了。这样的使用体验太崩溃，一般碰到这样的软件，我的大多数选择是卸载！ 而 Ghost 的好用之处其实很大原因是当时的互联网并不发达，而这个软件本身也没有太多商业因素的考虑，很纯粹的软件，零广告零捆绑。我今天要安利的 Veeam 免费工具，在这点上和 Ghost 及其相似！ ","date":"2019-07-02","objectID":"/2019/07/agent-backup/:0:1","tags":["Agent"],"title":"送 | 为裸奔中的电脑送一个备份保护","uri":"/2019/07/agent-backup/"},{"categories":["数据保护"],"content":"Veeam Agent for Microsoft Windows 免费版 同样是零广告零捆绑，下载安装即可使用，且功能全面。唯一缺点，我觉得就是暂时只有英文版了。不过问题不大，我今天就带大家 Step by Step 来一遍，保证你能用上它。 下载安装 下载安装非常简单，到 Veeam 官网 https://www.veeam.com 注册账号，进入下载页面，就能找到这个免费的软件下载。拿到最新版本 VeeamAgentWindows_3.0.1.1039.exe 后，双击就可以进入安装向导，整个安装过程只需要 4 步即可完成。 Step 1：有个简单的介绍，以及同意使用协议，有兴趣的朋友可以详细阅读，当然不想读也没问题，打钩 2 个\"I accept\" 就能激活 Install 按钮。 **Step 2：**自动安装，注意这里不能更改安装路径，软件会自动装入 Windows 的默认软件安装目录中。 **Step 3：**大约几分钟后，安装完成，如果有在电脑上插入了 usb 外置驱动器设备，会自动发现外置 usb 驱动器设备，并提示配置备份作业。我们可以跳过这个步骤不配置。 **Step 4：**在最后一步，会提示软件已经安装成功，并且会提示创建还原用的 Recovery Media。这个还原介质非常重要，它将能够在你的系统全部崩溃后帮你恢复你的系统和数据。 安装完成后的第一件事：恢复盘创建 这个步骤也非常简单，标准的 Veeam 式向导会带大家完成创建过程。 Step 1: 点击 Finish 按钮之后，就会进入 Recovery Media 创建向导，过程也非常简单，首先选择可启动的介质类型，这里可以是 ISO 镜像也可以是 U 盘，如果有插入恢复用 U 盘的话，可以直接选择该 U 盘，在我的这个介绍中，我们选择 ISO 镜像，其过程和 U 盘大同小异，并且未来 ISO 镜像也可以通过其他途径做成 U 盘。 Step 2: 这里默认 Veeam 会提供两个非常有用的选项，就是网卡驱动和网络配置，这对于从网络上恢复数据非常有帮助，减少了恢复时的一些配置步骤。选择 ISO image file 之后点击 next 进入下一步，会提示 ISO 文件的存放路径，这里可以是本地路径，也可以是网络 UNC 路径，如果是 CIFS 共享的 UNC 路径，可能需要提供用户名密码。 Step 3: 点击下一步，是一个 Summary 界面，告诉您刚刚配了些什么。 Step 4: 点击 Create 就能创建这个 ISO 镜像了。几分钟之后，这个恢复盘就创建好了，做恢复的时候用它引导启动就对了，当然这个 ISO 中并不完全包含数据。 ","date":"2019-07-02","objectID":"/2019/07/agent-backup/:0:2","tags":["Agent"],"title":"送 | 为裸奔中的电脑送一个备份保护","uri":"/2019/07/agent-backup/"},{"categories":["数据保护"],"content":"备份作业配置 打开 Veeam Control Panel，软件会提示一下，是否在免费版模式运行，还是输入一个商业版授权，这也是这个软件仅有的唯一一次提示，只需要点击否，继续运行免费版即可。 点击右上角的三条线图标后打开主菜单，点击加号 Add New Job 开始创建备份作业。 备份作业创建过程也非常简单，依旧是经典的 Veeam 式向导。 Step 1： 定义一个备份作业名称，写上一些描述说明。 Step 2： 选择备份模式，对于免费版来说，可以选择备份完整计算机以及外置 USB 驱动器，也可以选择备份某个磁盘卷，还能够备份部分文件。我们选择备份完整计算机。 Step 3： 选择备份目的地，这时候可以是 USB、火线、eSATA 等等各种连接方式的硬盘，也可以是网络上共享的 NAS 卷还可以是 Veeam 集中管理的备份存储等等。因为是个人用途，我们一般会选择备份至移动硬盘，或者是家用 NAS 中，本例子中，我选择将数据备份至家里的群晖 NAS 上。 **Step 4：**共享文件夹位置设置，选择了 Share folder 选项后，点击下一步，进入 Share Folder 设定，信息也很简单，输入 UNC 路径、用户名密码后就能读到信息，包括 NAS 卷的剩余容量等等。在这个页面上，同时可以设置备份数据保留 的份数、压缩重删技术的使用、加密方式等等。那如果是非常重要的数据，加密会是一个好选择。 Step 5： 点击下一步后，可以做一些备份计划任务的设定，这套备份软件是自动运行的，也就是设定完这些内容后，它会在后台自动运行，无需人工干预每天自动备份，这是非常省心的一件事情，不会因为不记得备份而丢失数据。这个计划作业提供了相当丰富的选项，我觉得甚至是可以为这个计划任务的设定专门写一篇推送来介绍，此处我就暂时不详细展开说明了。 Step 6： 点击 Apply，备份作业就创建好了。依旧会进入 summary 界面告诉你上面的步骤配置了 一些什么内容。点击 finish，就能完成备份作业的配置，也可以把“Run the job when I click finish”的复选框打上勾。 ","date":"2019-07-02","objectID":"/2019/07/agent-backup/:0:3","tags":["Agent"],"title":"送 | 为裸奔中的电脑送一个备份保护","uri":"/2019/07/agent-backup/"},{"categories":["数据保护"],"content":"备份作业运行 作业配置完成后，根据计划任务的设定，备份会自动在设定的时间或者设定的场景中进行，一般来说第一次会进行全备份，而在之后，则会进行永久增量备份。 我的电脑在配置完成后做完一次全备份，然后又做了一次增量备份，这个备份情况如下： 备份下来的存档，我们可以在 Windows 资源管理器内查看到，他们分别是一些 vbm 文件、vbk 文件和 vib 文件。其中 vbm 是备份作业元数据文件，记录着备份链的信息，vbk 文件是全备份存档，而 vib 是增量备份存档，增量备份文件是依附于全备份的。 以上，就是一个最最简单的 Veeam Agent 个人电脑备份方法，你学会了吗？如果觉得不错的话，赶紧去 Veeam 官网下载一份安装上使用起来吧。下一期，我将会介绍从 Veeam 备份存档中恢复数据的方法，帮助大家更深入的使用 Veeam Agent for Microsoft Windows 免费版。 更多内容，可以关注本人的公众号收听更多推送。 ","date":"2019-07-02","objectID":"/2019/07/agent-backup/:0:4","tags":["Agent"],"title":"送 | 为裸奔中的电脑送一个备份保护","uri":"/2019/07/agent-backup/"},{"categories":["数据保护"],"content":"勒索病毒个话题，貌似近一两年是一如既往的火热，还记得一年多前刚刚爆发的时候的那些停止服务的图片吧，相信绝大多数没中招的同学都是以一份看热闹的心态去看这些图片。我也不能免俗，借了一些来晒在当时的推送中。热点蹭一下，算是也涨了点粉丝量。 原本以为，这一话题早应该结束了，随着安全补丁的修复和安全防护的加强，勒索病毒不会太长命。而事实上并非如此，勒索病毒也不断演进，看上去这一来一回的攻防战，打的越来越有意思。 勒索病毒基础小课堂 我相信，大家都已经非常清楚所谓的勒索病毒是一类什么样的病毒，它的攻击流程无非就是： 加密一切被感染的文件； 通过各种方式联系文件的主人，要求支付赎金； 通常和碰到勒索病毒的同学的对话，就往往变成了如下： 倒霉的管理员：我丢，中招了，我的所有的资料全部被锁了，它们要我付 10 个比特币，怎么办？ 石头哥：备份了没？ 倒霉的管理员：没！ 石头哥：嗯，去付钱吧，祝你好运！ 没有备份的情况下，在这之后，会发生什么事情，我觉得真不好说，这两年的各种调查报告也很多，事实上真正能付了钱拿回数据的人，占总人数的 1/4 不到。 勒索病毒的进化 最近，看到一些评论，都在讨论现在的勒索病毒是越来越智能，以至于它们能够深入到用户的环境中自我复制、自我传播，同时它们还会去禁用一些主流的杀毒软件、备份软件、防火墙以及数据库，来确保达成勒索的目的。其中有些凶残的病毒甚至还带破坏和删除功能，对于主流已知的备份软件 Catalog 库进行深度分析，破坏发起后，为了达到勒索的目的，除了破坏生产数据，还同时去破坏备份数据。 这时候，碰到勒索病毒的同学的对话会这样： 倒霉的管理员：我丢，中招了，我的所有的资料全部被锁了，它们要我付 20 个比特币，怎么办？ 石头哥：备份了没？ 倒霉的管理员：备了，但是它们太聪明了，把我的备份服务器感染了，禁止了我感染那天以后的所有备份作业，同时删除了我的备份 catalog 文件。 石头哥：还有数据可以恢复吗？ 倒霉的管理员：数据放在 EMC DataDomain 中，通过最新的文件锁协议（File Locking protocols），倒是挺安全，但是 catalog 没了，再安全的备份存档数据块都无法恢复了。 石头哥：好吧，去付钱解锁吧！ 虽然用备份软件做了备份，但是水平还是没高过勒索软件，没有充分考虑到备份软件也会被勒索软件破坏，备份形同虚设。 下图是某勒索病毒的样本分析中找到的，它能禁用的一系列常见服务。它能做到破坏数据之前，先处理那些干扰他搞破坏的元素。可以看到市场上常见的杀毒软件和备份软件的服务都在这个清单上。 备份/灾备的应对策略建议 有了备份，也不安心，所以，在设计备份/灾备架构的时候，需要考虑很多因素： 备份存档的独立性和可移动性。 越来越多的客户开始意识到这一点的重要性，如果现在的备份存档，还无法做到自我恢复，完全依赖于备份软件所建立的 Catalog，那么破坏了 Catalog 就相当于破坏了一切。 相反，对于一个没有 Catalog 的使用 Veeam 备份的环境，这事情就简单太多了，每份存档就相当于一个个体，勒索病毒需要个个击破才能达到它勒索的目的，我相信，聪明的你肯定能把你最重要的数据存放中最安全的地方，而避免受到勒索病毒的感染。 那么这时候，假设很不幸，你的备份服务器被感染了，狠一点的勒索病毒直接破坏磁盘 MBR 记录，在启动的时候就拒绝你进入系统。这时候你需要做的事情很简单： 清理恢复完你的环境，确保已经杀干净勒索病毒。 安装一套全新的 VBR。 只需要从你最安全的磁带中，拿出之前备份下来的 VBK 文件。 导入到新的 VBR 中，veeam 不需要任何集中管理的 catalog 数据库或者重删库，就能识别每个备份存档内容。 使用各种恢复方式，和正常的 Veeam 恢复方式完全一致，包括 Instant VM Recovery 和 Instant File Recovery。 多份备份数据的安全隔离性。 存放数据的时候，千万记得别用同步功能，企业数据和个人数据一样。拿个人数据举例，如果你有个百度盘，或者 Onedrive，这时候你要把你的数据备份到云上。偷懒的做法是后台开启自动同步，一旦数据写入你的磁盘，这些网盘工具会做一个自动同步，近乎实时的把数据同步到云端。而试想一下，这个数据写入磁盘的动作假如是由勒索病毒发起的，那么你的云端的所有数据也将会被你的这个自动同步操作的给感染。这样你设置的所有备份防御措施都将失效。 同理，在企业数据中心，偷懒的存储级同步方法，甚至是某些厂商宣称的字节级同步方法，在勒索病毒看来，这是多好的手段，让攻击范围自动蔓延，自动传播啊。 所以，我强烈建议，把自动挡改成半自动挡，拥有自动挡的技术没有问题，但是在必要的情况下，调整成定期数据的复制，会大大降低数据感染的风险。 数据多存放几份，多存几种介质都是很好的方法，来避免被全方位攻陷。对于勒索病毒来说，本身它是一种自动执行的计算机软件，全自动化的进行攻击，很少会有人工手工干预的攻击，因此改变正常的数据存放规则和套路是一个好方法。当然这个前提是，备份软件足够灵活，能够支持各种各样的存储设备。 备份存档的定期验证和自动化恢复演练。 这又是一个很有意思的话题，可恢复性验证，这备份和灾备环境中，要去做这个验证通常都只能手工去做，这会消耗大量时间和资源。在没有勒索病毒出现的时候，这个验证仅仅是为了对付下领导，对付下监管，这也许交一份书面报告也就过去了。然后勒索病毒横行的今天，我们真的得好好想一想，要是哪天勒索病毒把我的环境破坏了，那我的哪些备份存档是没有勒索病毒感染的，能够正常恢复的干净系统？ 全自动的备份存档验证在这样的场景下，能够帮助备份管理员省下不少时间和资源。而加入了更多自动化校验逻辑的 Veeam Availability Orchestrator 2.0 则是这方面的小能手。 来吧，和勒索病毒斗智斗勇吧。 没有任何一个软件可以做到没有漏洞，没有任何一个软件可以做到完全免疫任何攻击。我认为只有更好更合理的去存放数据，并且持续的去检查数据，才能够在这场勒索病毒持久战中坚持到最后。 ","date":"2019-06-10","objectID":"/2019/06/ransomeware-attack/:0:0","tags":["VMware"],"title":"不知勒索病毒的攻击原理，怎知如何防御？","uri":"/2019/06/ransomeware-attack/"},{"categories":["数据保护"],"content":"最近有很多 Veeam 今年新版本特性的系列文章，包括很多云端数据管理的话题，有兴趣的朋友可以参考 Veeam 云架构师 Mars Zhang 的系列推文： Veeam 9.5 U4 新功能，利用 Cloud Mobility 实现迁移即服务 Veeam 云端数据管理新功能，打造 BaaS 备份即服务 （一） 回归到 Veeam 最原始的功能，最近开始回过来做做基础知识普及，本系列内容较长，因此分多期推送，这里内容来自于 Veeam 官方论坛置顶帖，如果有想看原版的，可以直接通过原文链接跳转。 本文纯技术内容，纯纯的干货，就不开篇废话了，直接进入主题： Architecture 问：请问 Veeam 备份数据流的流向顺序？ 答：磁盘\u003e Backup proxy \u003e 网络\u003e Backup repository \u003e 磁盘 Backup Proxies 问：什么是 Backup Proxy Server？ 答：Backup Proxy 从生产存储中提取虚拟机数据（配置文件和虚拟磁盘），通过应用重复数据删除和压缩来处理数据以减小虚拟机数据的大小，并将虚拟机数据发送到 Backup Repository（在备份的情况下）或其他 Backup Proxy （在复制的情况下）。 Backup Proxy 还用于在还原虚拟机时将虚拟机数据（配置文件和虚拟磁盘）写回 VMware 的生产存储，以及用于虚拟机的复制。 问：为什么最好在物理机上安装 Backup Proxy？ 答：由于大量数据流（高达每秒几千兆字节）的即时处理（重复数据删除和压缩）需要大量的 CPU，内存和 I / O 资源，物理 Backup Proxy 最适合 24/7 虚拟化环境，具有高整合率。否则，您可能会发现备份过程会影响生产。 问：我可以在什么操作系统上安装 Backup Proxy？ 答：Microsoft Windows 7 SP1 / Server 2008 SP2 64 位操作系统或更新版本。 问：我是否必须设置 Backup Proxy 才能开始使用产品？ 答：不，因为安装程序会自动部署默认 Backup Proxy。 但是，我们建议您添加额外的 Backup Proxy 以实现冗余和负载平衡。 有关最佳部署额外 Backup Proxy 的建议，将会在后续章节中详细说明。 问：Backup Proxy 可以备份自己吗？ 答：是的，Backup Proxy 可以备份自己和任何其他 Veeam Backup \u0026 Replication 组件。 Synthetic Backup 问：增量永久备份方法有什么好处？ 答：因为无需保留多个完整备份（反向增量备份，永久正向增量备份和带转换的正向增量备份），所以可以减少对生产环境的压力，提高完整备份性能，减少备份存储空间，。 问：我正在使用重复数据删除存储设备。合成完全备份对我有好处吗？ 答：根据存储实现重复数据删除的方式（Inline，后处理或与 DDboost 或 Catalyst 集成），您可以通过使用 Active Full Backup 而不是合成备份来获得更好的性能。 问：我们企业有一项数据保护合规性要求，需要执行真正的完整备份。我是否被强制使用 Veeam 的合成全备份？ 答：不，您可以将作业配置为执行 Active Full Backup。 此外，您可以安排 Active Full Backup，例如，每月一次（或每季度一次），同时在其余时间进行合成完全备份。 Veeam 在安排 Active Full Backup 方面提供了极大的灵活性。 问：反向增量备份模式究竟如何工作？ 答：Veeam 在备份作业进行中，从源端提取变化的数据量，然后将其注入到之前的一份全备份文件中（.VBK），同时将被注入过的数据块重新写入到一个新的文件（.VRB）中。这样 VBK 文件永远包含了一份最新的虚拟机备份存档。详细信息请参阅： https://www.veeam.com/blog/veeam-synthetic-backup-explained.html 问：增量备份的转换选项与反向增量备份模式有何不同？ 答：转换的最终结果是相同的 - 包含最新 VM 状态的单个完整备份，以及早期还原点（VRB 文件）。 不同之处在于，如果使用反向增量备份模式，每次运行备份时都会发生合成全备份数据注入；而使用带转换选项的增量备份时，仅在合成全备份当天发生数据注入。这可以加快每日增量的备份速度，但会在减慢合成全备份当天的备份速度。 Backup Repositories 问：什么是 Backup Repository？ 答：Backup Repository 是存储备份的位置。每个 Backup Repository 都具有本地代理，可在 Backup Proxy 和 Backup Repository 通过局域网或广域网进行通信时实现增量数据的高效本地处理。 问：Veeam 支持什么样的设备作为 Backup Repository？ 答：以下几种设备是可以被支持的： 任何直连至 Windows 服务器的磁盘。可以是本地磁盘、直连的任何磁盘存储（包括 U 盘）、iSCSI 或者 FC LUN。 任何直连或者挂载到 Linux 服务器（需要安装 bash shell、SSH 和 Perl）的磁盘，可以是本地磁盘、直连的任何磁盘存储（包括 U 盘）、NFS 共享、iSCSI 或者 FC LUN。 SMB （CIFS）共享，支持用户名密码验证。数据支持从 Proxy Server 直接写入到 SMB 共享文件夹，也可以通过 Gateway 写入（对于远程服务器非常有用）。 基于磁盘的重复数据删除设备，包括 Dell/EMC 的 DataDomain、HPE StoreOnce、ExaGrid、QuantumDXI。 问：我可以使用虚拟机作为 Backup Repository 吗？ 答：是的，但是请务必想清楚在发生灾难情况下的恢复计划。但请记住，如果将备份文件存储在虚拟机且位于生产存储中，发生灾难时可能会影响您检索备份文件的能力，虽然实际上该虚拟机不一定需要保持运行状态，因为您始终可以在 Veeam 中直接导入备份存档所在的磁盘文件。 问：您推荐为备份存储选择什么 Raid 级别？ 答：我们建议使用 Raid 6（或者其他同类双奇偶校验技术）来最优化冗余级别。而 Raid 10 则能为合成全备份的提供更好的 I/O 性能。 磁带和异地 问：Veeam 支持将备份写入磁带吗？ 答：是的，Veeam 支持源生的 LTO-3 以上的磁带写入。详细内容将会在后续磁带 FAQ 中说明。 问：如何才是最佳的异地备份存放方式？ 答：使用 Backup copy job 将备份存档复制到异地的 Backup Repository，如果链路带宽较小，可以考虑使用广域网加速器。 Backup 模式 问：我应该选用什么样的备份模式？ 答：请参考下图。 备份作业类型 问：什么是 Backup Jobs? 答：Backup Jobs 使用生产的虚拟机数据生成的高度压缩和重删的备份文件，从而可以节省大量托管备份所需的空间。但是由于需要从备份中提取并解压拷贝完整的虚拟机映像回生产存储，因此从备份存档还原完整的虚拟机通常需要很长时间。另外，Veeam 也提供立即恢复少量虚拟机的方式（请参阅即时虚拟机恢复相关内容）。 问：什么是 Backup Copy Jobs？ 答：Backup Copy Job 可以有效的在本地（通常用于存档目的）和异地（以满足异地备份存储要求）创建备份存档的副本。 维护备份存档的多个副本是行业的最佳实践（称为 3-2-1 备份黄金法则）：至少 3 个数据副本（1 个生产和 2 个备份），备份存储在 2 种不同的介质中，其中 1 份存放在异地。 问：什么是 SureBackup Jobs？ 答：SureBackup Jobs 通过在隔离环境中启动一个或多个虚拟机来执行全仿真的恢复验证，该验证通过检查虚拟机是否已启动，操作系统是否已启动，虚拟机的 ping 包响应以及虚拟机应用程序是否正常运行来验证恢复是否成功。 SureBackup Jobs 也是 U-AIR 和按需沙盒功能的关键组件。 问：什么是 Replication Jobs？ 答：Replication Jobs 使用生产的虚拟机在备用主机上生成精准的虚拟机副本。当生产环境宕机后这些虚拟机副本能够立刻被启动起来并拥有完整的 I/O 性能，这不需要依赖 Veeam Backup \u0026 Replication 服务器进行工作。然而，这样的虚拟机副本相比备份存档还会需要备用的主机、需要更多的磁盘容量，因为这个虚拟机副本是以未压缩重删的虚拟化平台的源生格式进行存放。所以，虚拟机副本通常是用于最关键的那些应用系统，对于恢复时间要求极高的系统。 问：什么是 VM Copy Jobs？ 答：VM Copy Jobs 使用生产的虚拟机在指定的存储上生成精准的拷贝，比较适合用于数据中心迁移，创建测试实验室以及临时发起的数据备份。VM Copy Jobs 支持处理运行中的虚拟机。和 Backup Jobs 不同的是，VM Copy 不支持增量。 VM Copy Jobs 仅支持 VMware 虚拟机。 问：什么是 File Copy Jobs？ 答：File Copy Jobs 可以在任何被 Veeam 管理的服务器（Windows、Linux 或者虚拟化平台）之间进行常规的文件拷贝，能够执行各种各样的管理类的操作。File Copy Job","date":"2019-03-21","objectID":"/2019/03/veeam-faq/:0:0","tags":["VMware"],"title":"Veeam FAQ 系列转载","uri":"/2019/03/veeam-faq/"},{"categories":["数据保护"],"content":"上期介绍了 Veeam 云对象存储使用的基本方法，但是文中有些内容略微有些小错误，在此不再放入该推送的链接，如有需要，请大家后台回复：Cloud 或者云调取阅读更新后的版本。本期内容给那些想更深入了解该技术的朋友们。 或许已经有人注意到，在使用 Veeam 云对象存储以后，不管备份存档是位于本地数据中心还是位于云上对象存储中，Veeam 均提供各种丰富的还原手段，其中包括最重要的 Veeam 于 2010 年首创的经典技术 – Instant VM Recovery，关于这个技术的详细使用，可以参考之前的推送： Veeam 黑科技之 vPower NFS。 云对象存储特殊属性，各家云厂商在定价上几乎无一例外的采用 4 个维度来制定收费策略，分别是：容量、读写请求次数、读取数据量、订阅服务时间，这和传统存储设备一次性买断投资的特性完全不同，因此对于长期不使用的数据，存放在云端时，读写请求和读取的费用会变得非常的低，这也是对象存储作为归档异地存放的最佳属性。 但是，这并不意味着备份厂商可以无责任的随意使用对象存储，如果把对象存储当做和传统本地存储一致的属性来对待时，对于传统设备的随意读写的这些操作，特别是做数据校验、数据整理、恢复校验、定时重删任务等读写操作，会给用户带来额外巨大的 I/O 和读取费用。因此 Veeam 为存放到对象存储上的数据做了重新打散处理，并且定义了一系列的存取规则，以确保数据可用性的前提下，尽可能少的使用读写 I/O 和读取数据量，降低云端对象存储的使用成本。 元数据（Metadata）和数据块（Block） 每个 Veeam 的备份存档（.vbk、.vib、.vrb）都会由** Metadata 和 Block **组成，在每个本地存储的存档中，Metadata 和 Block 是密不可分的，通常就存在于同一个文件中。而数据被传送到云端对象存储时，Veeam 会将两者拆分开来，在各自的目录中，单独存放相关数据。而本地磁盘上，Veeam 会保留 Metadata，以便能够在恢复时快速找到对应的 Block。 索引（Index） 索引通常在 SOBR Offload Job 启动时生成，其内容包含了。vbk、.vib、.vrb 这些文件中，各切片数据块的哈希值（Hash），Veeam 从备份存档的 Metadata 中提取这些 Block 的哈希值。生成这些哈希值后，Veeam 会首先把这些内容存放在 Scale Out Backup Repository 下该 backup job 对应的 Extents 目录下的 ArchiveIndex 目录中。在以后的任何一次数据传输中，如果有数据块的哈希值和已有的哈希值相同，那么 Veeam 将会重复利用这些已经传输的数据块，而不会再进行传输，避免浪费带宽。 需要注意的是，这个索引是基于完整备份链（Backup Chain）生成的，也就是说，对于两个不同的 Backup Job，即使对于同一台 VM 做了 Backup，实际上在上传到对象存储的时候，就算数据块拥有相同哈希，也会被重复上传。由于这是整个备份链中的数据块信息，因此，每次的备份链发生变化，那么在下一次执行 SOBR Offload Job 时都会重新生成这个索引。 这个索引中的内容，同时包含了某一数据块在云端对象存储中和在本地磁盘存储中的位置信息，如果某一数据块同时存在于 3 份不同的全备份存档中，其中两份位于本地磁盘中，一份位于云端对象存储上，那么索引会将这些信息都记录下来。当需要执行 SOBR Offload Job 进行新数据上传时，VBR 如果发现新的上传数据中需要上传这份云端已有数据，那么 VBR 会跳过该数据块的上传，同时在本地和云端更新相应记录，以此来节省上传带宽和节省上传时间。 当需要还原时，同样的，VBR 会判断被还原的数据块中的哈希值，如果发现索引中有提到本地磁盘中还存放着这些数据块，那么 VBR 会优先选用本地磁盘上的数据作为还原读取的源，从而大大节省从云端对象存储中读取的数据量。 而正是这个原因，也使得选用云端对象存储上的数据执行 Instant VM Recovery 变得可行。 备份链的活跃部分和非活跃部分 只有备份链的非活跃部分，才能被上传至云对象存储中。无论是手工操作还是自动任务，处于备份链活跃部分的还原点，无论如何都将不会被上传至云对象存储上。 这也是本次更新后 Veeam 对于备份链新引入的两个概念，这是在了解云端对象存储数据上传任务中非常重要的两个概念。介绍这两个概念之前，我们来复习下备份链（Backup Chain）的定义：在 Veeam 的备份存档中，存放在存储介质中的数据以备份链的形式存放，以普通增量备份为例，一般存放结构如下图所示，那么对于一个 Backup Job 而言，这一组文件的集合，被称之为备份链（Backup Chain）。 而备份链的活跃部分和非活跃部分则是以最后一次全备份为分界线，在最后一次全备份之前的部分，我们称之为备份链的非活跃部分，而在最后一次全备份之后的所有增量备份和该全备份，被称之为备份链的活跃部分。如下图所示： 当然这依然是以普通增量备份为例，对于反向增量备份、永久增量备份、Backup Copy，情况会略有不同，但是基本规则也和上面提到的一致。 随着时间的推移，作业的进行，早期的还原点（Restore Point）将会因为新的全备份的产生而被转换为非活跃，从而实现 Offload 操作。 总结一下，哪些数据将会被上传至云对象存储中： 属于备份链的非活跃部分的数据； 早于 Capacity Tier 中设定的日期的数据； 这个 Block 是否之前没有在这个 Backup Job 中被上传过。 这个 3 个条件验证完后，数据将会被决定是否会上传。 以上就是本期对 Veeam Cloud Tier 的深入分析。 ","date":"2019-03-04","objectID":"/2019/03/cloud-tier-02/:0:0","tags":["VMware"],"title":"Veeam Cloud Tier – 云对象存储使用详解（二）","uri":"/2019/03/cloud-tier-02/"},{"categories":["数据保护"],"content":"2019 年 1 月 23 日 Veeam 发布了其产品历史上功能最多的一次 Update 包 VBR 9.5U4，其中包含了一系列和云相关的功能模块，本文将会详细讨论其中最主要的一个特性：云对象存储。 在 VBR 9.5U4 中，可以使用 Amazon S3、Microsoft Azure Blob、IBM Cloud Object Storage 以及其他各种兼容 S3 协议的对象存储，因此，对于我们国内用户 AliCloud OSS 和 Tencent Cloud COS 也能够完美支持。 ","date":"2019-02-21","objectID":"/2019/02/cloud-tier-01/:0:0","tags":["对象存储"],"title":"Veeam Cloud Tier – 云对象存储使用详解（一）","uri":"/2019/02/cloud-tier-01/"},{"categories":["数据保护"],"content":"云对象存储的定位 在 VBR 中有三大类 Repository，分别是 Backup Repository、External Repository 和 Scale-Out Backup Repository（SOBR）。我相信对于绝大多数 Veeam 使用者，Backup Repository 是再熟悉不过了，那是 Veeam 存放备份数据的磁盘位置，也是以往被使用最多的数据存放方式。External Repository 是 VBR 9.5U4 新增的，这个并不是本文云对象存储涉及到的部分，本文暂且不讨论。而 SOBR，在以前的 VBR 版本中，可能鲜有提及，而在未来，这将可能成为 Veeam 最主要的数据存储方式。 在了解云对象存储之前，我觉得有必要来回顾一下 SOBR 的组成，每个 SOBR 都会由 1 个以上的 Extents 组成，每个 Extents 其实就是一个常规的 Backup Repository，也就是说，SOBR 就是一个 Backup Repository 的集合，这是以往 SOBR 的基本组成。 在这个全新的 SOBR 中，Veeam 把它分成两个层级，分别是 Performance Tier 和 Capacity Tier，所有本地磁盘组成的 Extend 都被归类为 Performance Tier，而云对象存储组成的 Extents 则被归类为 Capacity Tier。 ","date":"2019-02-21","objectID":"/2019/02/cloud-tier-01/:1:0","tags":["对象存储"],"title":"Veeam Cloud Tier – 云对象存储使用详解（一）","uri":"/2019/02/cloud-tier-01/"},{"categories":["数据保护"],"content":"工作原理 简单来说，含有云对象存储的 SOBR 必须由 1 个以上的 Extents 组成，然后必须包含 1 个云对象存储。 每隔 4 小时，Veeam 会根据 SOBR 中的保留策略设定自动运行 SOBR Offload 任务，将本地需要上传至云端的数据上传至云端的对象存储中。 相对的，SOBR Download 任务则对应可以将云对象存储中的数据取回本地 Extents 之中。 而在还原过程中，云对象存储可以说是近乎于透明状态的存在，它和以往任何的存储解决方案都会不一样，在 Veeam 中，云对象存储上的还原点，可以保留其原有的任何还原能力，以完全源生平滑的方式来进行数据还原。 我们来看一个实际的例子：当进行数据还原时，选择的还原点位于云对象存储上时，Veeam 首先会去读取本地的数据索引（Index），这个 Index 会告诉 Veeam，哪些数据同时存在于云上和本地，那么在读写数据时，Veeam 将会优先去使用本地的数据作为数据源，而只会从云中获取那些本地不存在的数据。这将大大减少云对象存储的使用费用，因为绝大多数的云对象存储的使用计费会更多的按照请求和回流来计算。 ","date":"2019-02-21","objectID":"/2019/02/cloud-tier-01/:2:0","tags":["对象存储"],"title":"Veeam Cloud Tier – 云对象存储使用详解（一）","uri":"/2019/02/cloud-tier-01/"},{"categories":["数据保护"],"content":"管理和操作 添加云对象存储 上文提到过，云对象存储也是属于 SOBR 的一个 Extents，而 Extents 则是一个 Backup repository，因此添加云对象存储的入口就是 Add Repository。 在 Add Backup Repository 中会新增一个向导 Object Storage，这就是添加云对象存储，其中包含了上文提到的 4 种不同的协议。 添加过程非常简单，如同任何 Veeam 功能一样，以交互的方式填入合适的信息即可完成配置，本文就不做官方 User Guide 的复读机了，可以根据实际使用的云对象存储选择合适的存储类型进行添加。 https://helpcenter.veeam.com/docs/backup/vsphere/new_object_storage.html?ver=95u4 配置 SOBR 和 Capacity Tier 在 Backup Infrastructure 中找到 Scale-Out Backup Repository，然后点击 Add 来新增，这时候需要首先配置 Performance Tier。关于 Performance Tier 的配置详细选项，本文就不展开进行详细讨论，有需要的可以查看官方 User Guide 中的相关章节。 https://helpcenter.veeam.com/docs/backup/vsphere/sorb_add_extents.html?ver=95u4 选择默认的 Placement Policy 后，就可以进入 Capacity Tier 的配置，这时，在上一步中配置的云对象存储库就会出现在下图的 List 中，同时在这个页面上我们也可以配置如何去进行 SOBR Offload 任务，也就是我们前面提到的 SOBR 的保留策略。 设置完本页内容之后，云对象存储的配置就完成了。 使用操作 日常备份中，我们不需要过多的操作，系统后台会定时 4 小时去检查是否有数据需要 Offload，如果没有数据需要 Offload，或者说没有数据满足 Offload 条件，那么这个 SOBR Offload task 会迅速完成。 当然我们有手工进行数据传输的方式，可以按需进行数据的 Offload 和 Download。 举个例子，如图我们已经有一组备份存档，部分位于云对象存储中，部分位于本地磁盘上。 这时候，对于云上的数据，我们可以做 Copy to Performance Tier 操作，这个操作就是 SOBR Download 任务。在 Download 过程中，Veeam 依旧是通过 Index 最优化取回数据，可以通过本地磁盘中重组的数据，就不会从线上取回。 以上就是今天的内容，下一期我们会更深入的探讨 Veeam 云对象存储使用。 ","date":"2019-02-21","objectID":"/2019/02/cloud-tier-01/:3:0","tags":["对象存储"],"title":"Veeam Cloud Tier – 云对象存储使用详解（一）","uri":"/2019/02/cloud-tier-01/"},{"categories":["数据保护"],"content":"上一期介绍了 《Veeam Availability for Nutanix AHV 的安装和配置》，本期来说说 VAN 的备份和恢复。 备份 AHV 的虚拟机 VAN 的所有备份操作依旧是以备份作业方式，但是和 VMware/Hyper-V 不同的是，Nutanix AHV 的 VM 备份作业都会在 VAN Console 中进行，而不是 VBR 上。 进入 VAN Console 中，上面的菜单非常简单，顶部从左向右分别是仪表盘、备份作业、已保护的虚拟机、事件这 4 个页面。 备份作业可以进入 Backup Jobs 中设定，同时在这里也能查看到备份作业的运行状态。 备份作业设定步骤 在 Backup Jobs 页面中，点击 Add 按钮就可以新增备份作业。设置过程还是 Veeam 经典的向导模式，5 个步骤就能完成所有设定操作，非常简洁。 第一步，和 VBR 中的设定一样，是 Job Name 和 Job Description，根据实际情况输入信息即可。 选择备份哪些 VM，这里和 vSphere/Hyper-V 还是非常像，可以选择非 VM 的对象，比如一个 Host 或者一个 Cluster。 点击 Add 即可打开 Nutanix AHV 的对象选择，和 vSphere/Hyper-V 不一样的是，这里会提示哪些 VM 处于 Unprotected 状态，这能很好的避免重复备份，也能快速定位哪些 VM 没有备份。 选择备份至什么位置，这里会列出 VBR 中已经设定了 Allow 权限的 Repository，可以选择普通的 Repository，也可以选择 Scale-out Repository。 设定计划任务，此处的界面会稍微有点不同，个人认为这一新的 Web 界面让 Schedule 选择变得更加美观，而计划任务的逻辑则和原来的 VBR 是完全一致。 最后一步 review 一下以上设定后，备份作业就设定完了。备份作业会在指定的时间自动开始运行。 查看备份状态 而备份作业运行后，我们可以在 VAN Console 或者 VBR 中查看到备份状况，而 VBR 中并不能做任何的编辑，仅能查看状态。 还原 AHV 的虚拟机 VAN 的还原可以在 VAN Console 中操作，也可以在 VBR Console 中进行。但是在这两个控制台中能做的操作会有些差别。 VAN Console 还原 在 VAN Console 中，Veeam 提供完整虚拟机还原和虚拟磁盘还原。 完整虚拟机还原 点击 Restore 按钮，会打开还原向导。 点击 Add 添加需要还原的虚拟机。 点击 Point 按钮，可以选择适合的还原点进行恢复。 进入下一步后，可以选择还原位置。对于原始位置，没有太多选项，是对原有虚拟机的直接覆盖，而选择恢复到新位置时，可以输入更多配置，变成一台新的虚拟机。 设定新的 VM name，和原始 VM 名称不同。 选择合适 VM Container，默认这里是原始的位置，可以根据实际情况选择新的节点和新的 Container。 输入合适的还原理由后，可以开始 VM 的完整还原。 部分 Disk 还原 点击 Disk Restore，可以启动单个 virtual disk 的还原向导，选择需要还原的 VM 选择合适的还原点。 设定 Disk 映射关系。 设定完 Restore Reason 后，点击 Finish 即可进入恢复过程。 VBR Console 还原 在 VBR Console 中，VAN 存档支持标准的 Veeam Agent 还原方式，即：Instant Recovery to Hyper-V、Export to Virtual Disk（VMDK/VHD/VHDX）、Guest File Restore、Application Item Restore 以及 Direct Restore to Microsoft Azure。 此处操作就和 Agent 完全一致了，其中对于 Linux VM 的文件级恢复，依旧需要借助一台 Hyper-V 或者 vSphere 上的 Help Appliance 才可以完成。本文就不再详细展开介绍 VBR Console 中的恢复方式，具体可参看 VBR 中 Agent 的恢复。 ","date":"2018-07-30","objectID":"/2018/07/van-02/:0:0","tags":["Nutanix AHV"],"title":"Veeam Availability for Nutanix AHV 配置和使用系列（二）","uri":"/2018/07/van-02/"},{"categories":["数据保护"],"content":"Veeam Availability for Nutanix AHV（下文简称 VAN）正式发布了，本文详细介绍下这一新工具的使用方法。 此次的软件发布以 Proxy Appliance 形式，到 Veeam 官网直接下载 Zip 包解压即可得到一个 Disk Image，这是一个 vmdk 文件。和其他 Veeam 软件一样，这里官网依旧能够申请到一个 30 天的试用许可。 VAN 的架构解析： 由于 VAN 的特殊性，这个下载得到的 Appliance 并不能直接使用工作，它是 Veeam Backup \u0026 Replication 的一部分，需要依赖 Veeam Backup \u0026 Replication 一起才能实现 Nutanix AHV 的数据保护。其架构如下图： 所以，如果是一个单一的 AHV 环境，我们还是首先需要部署一套 VBR，完了之后再开始 VAN 的部署，而 VBR 中也需要激活相应的 Zero-Socket VBR ENT+的许可，才能完全发挥 VAN 的所有功能。本文对于 VBR 部分就不详细展开说明，请参考官网手册。 VAN 部署方法： 上传镜像至 Nutanix 镜像库中，在 Prism 上选择配置镜像。 打开配置镜像对话框，选择上传镜像。 为新的镜像输入名称、备注，选择镜像类型为 Disk，选择合适的 Storage Container，然后指定刚刚解压开来的这个 vmdk 的路径后，点击保存。 等待一段时间，AHV 系统经过上传、初始化之后，任务栏在完成所有任务后，我们再次打开配置镜像对话框后，会发现我们上传的 VeeamProxy 这个镜像意见处于 Active 的状态了。 接下去我们开始利用这个 Image 来创建 VM，这个 VM 就是 Nutanix 中用来提取数据的引擎，它和 VMware 环境的中的 Proxy 非常相似，只是这个是 Veeam 封装起来的一个 Linux。 创建 VM 过程也是非常简单，按照手册中的建议配置填即可，2vCPU/2Core/4GB Memory，新增一块磁盘，选择镜像库中的源作为磁盘，然后指定一个网络地址用于初始化访问。 这样，VeeamProxy for AHV 就创建好了。在 AHV 上开启这个虚拟机，经过简单的初始化后，即可进入系统，系统命令行提示，可以通过一个 https 的地址访问到 VAN 并进行初始化配置。到这个步骤，其实 Nutanix 上的所有操作已经完成，接下去就是进入 VAN 界面进行 Veeam Proxy 的初始化配置了。 浏览器打开 Proxy Appliance 地址，纯黑的界面，配上绿色的 Veeam Logo。输入默认的 Admin 后即可进入 Proxy Appliance 首次配置向导。 新的 Proxy Appliance 第一次进入可以选择是全新安装或者从配置文件进行恢复，这里我先选择了全新 Install。 进入安装向导后，首先需要接受一个最终用户许可协议（End User License Agreement），勾选 Accept 之后点击下一步。 重新设定 Admin 的密码，进入下一步网络设定。 为 Proxy 设定主机名以及 ip 地址。 回顾一下设定内容后，点击 Finish 后系统会进行一轮重启，然后初始化配置就完成了。 接下去再次进入 Proxy Appliance 的 web console，会提示输入 License，所有 Nutanix 的许可都会在 Proxy Appliance 上直接管理。从这步开始，需要对这个 Proxy Appliance 进行三项基础配置设定，使其能够进入正常工作状态。 点击右上角齿轮配置图标，进入配置界面，在这里分别激活 License、配置 VBR Server 以及添加 Nutanix Cluster。操作交互方式也非常简单，一些基础信息足够完成配置。 首先是 License，和其他 Veeam 的 License 一样，导入。lic 文件即可。 VBR 的配置也非常简单，IP 地址、默认端口、用户名密码即可完成 最后就是 Nutanix Cluster，填入 CVM 地址用户名密码即可配置完成。 以上就是 VAN 的初始化配置，在做完这些配置以后，我们就可以开始对 AHV 中的 VM 进行数据保护了。 关于 AHV 的备份和恢复，我会在下一期中详细介绍。 ","date":"2018-07-28","objectID":"/2018/07/van-01/:0:0","tags":["Nutanix AHV"],"title":"Veeam Availability for Nutanix AHV 配置和使用系列（一）","uri":"/2018/07/van-01/"},{"categories":["数据保护"],"content":"常常被问及 Veeam 是否支持某某数据库/应用程序的对象恢复，其实这个问题的答案和问题中提到的 某某数据库/应用程序 完全没有关系，这类问题的答案永远是肯定的。因为 Veeam 有一个超强的恢复工具：U-AIR（Universal Application-Item Recovery） 今天我就以 MySQL 为例，给大家详解一下这个恢复工具。 先来看看今天的备份存档，这是一个安装在 CentOS 上的 MySQL 5.1.7，我使用 Veeam Backup \u0026 Replication 对其进行备份，备份过程中执行了 Pre-freezing 和 Post-freezing 脚本确保其数据一致性，关于此脚本，大家可以参考 Veeam 官网的白皮书，因为 Veeam 白皮书实在太详尽，我就不在此处担当复读机啦。 具体链接如下： https://www.veeam.com/wp-consistent-protection-mysql-mariadb.html 对于源虚拟机上，我的 MySQL 中有以下这些测试数据： 然后这个状态的这台 MySQL 虚拟机我做了一次备份，这时候因为一些意外原因，我的 veeamlab 这个 database 被破坏了，我需要通过备份，将这个 veeamlab database 还原出来。此时，坏了的 veeamlab 将会被我弃用，而我会新建一个空的 veeamlab_recovered 作为新的目标还原库，而这时 MySQL 则是一切正常状态。 接下去，我的还原过程开始了，启动 Universal Lab Request Wizard 来申请一个之前的备份存档，用于还原，申请过程非常简单。 给出需要申请的 VM Name，这里完全支持模糊名称。 还原点我选择最新一份。 完成之后提交申请。 至此，U-AIR 恢复申请提交完成，须等待备份管理员审核还原申请。 我接下去通过 Veeam Enterprise Manager 来到备份管理员视图，进行此次还原申请的审核。 Approve 过程也非常简单，在这里完全用到 Veeam SureBackup/Virtual Lab 的功能，具体 SureBackup/Virtual Lab 的配置可参考之前的推文 。《备份存档能不能被恢复，这件事情上只有真正做过才知道。》 这个审批过程，Veeam 会自动找到合适的虚拟机备份存档： 会选择合适 Virtual Lab 和 SureBackup Job 作为还原的临时环境： 如此，审批过程就结束了，接下去，在数据库管理员这端，等待一小段时间后，将会获得临时还原环境的访问信息。 通过 172.20.1.139，我 ssh 到这台还原环境中，而此时我原来的 10.10.1.139 还是处于正常运行状态。检查临时的还原环境中的数据库情况如下： 数据一切正常，接下去，我需要做一件事情，就是将这里的数据提取出来，然后传输至原来的 10.10.1.139 中，进行还原。我使用 mysqldump 命令来提取数据。 提取完后，数据存放至/tmp/mysql/veeamlab.sql 文件中。 然后我们回到原机器 10.10.1.139 中，使用 Virtual Lab 中 Static IP Mapping 技术，我设定了能够让所有机器通过 10.10.1.138 这个地址访问到虚拟实验室中的临时还原环境，这时候，我可以从 10.10.1.138 中抽取这个 dump 进行还原。 还原命令依旧非常简单： 至此，所有数据还原工作完成，我们看到我们希望还原的数据已经全部找回。数据库管理员可以提前终止 UAIR 环境，也可以让它在使用时间到期后自动回收。 好了，今天恢复 MySQL 的样例就是这些，这个恢复没有太多前提条件，唯一的条件就是使用 Veeam Backup \u0026 Replication，有了 Veeam 您就能和我一样进行如此轻松的进行任何数据库/应用程序对象的恢复了。 ","date":"2018-04-10","objectID":"/2018/04/uair/:0:0","tags":["VMware"],"title":"利用 Veeam U-Air 恢复 MySQL 数据库","uri":"/2018/04/uair/"},{"categories":["黑科技"],"content":"什么是 vPower？ 这是 Veeam 的突破性科技，可以说是创造了一个时代，引领了当今虚拟化数据保护新的技术潮流。这项科技彻底颠覆了原有传统 IT 环境数据保护过程中恢复数据的流程，将漫长的恢复数据过程提升至分钟级，让超大容量的数据恢复变得不再那么可怕。 Veeam 的 vPower 技术不仅仅支持 VMware vSphere，同时能够支持 Microsoft Hyper-V 平台，并且两者实现的效果几乎完全一致。本文仅以 VMware vSphere 为例介绍 vPower 的原理。 这项科技的核心内容其实非常非常的简单，我认为这也是 Veeam 的科学家太聪明了，简单但是及其巧妙的运用虚拟化的手段直接让常规磁盘存储设备中存放的被压缩和重删后的数据能够模拟成前端 Hypervisor 程序可以识别的文件格式，然后运行起来。从技术上说，这是一个非常简单的架构，ESXi 主机直接访问 vPower NFS Server，实现虚拟机恢复运行。 这里面有个非常核心的角色，那就是有一台 Windows Server，上面启动 vPower NFS 服务，来充当一台 NFS Server。那么相信熟悉 VMware 的各位一定能想到，VMware 在使用 Datastore 时，除了常规的 VMFS 这样的 Block Level 的使用方式外，还可以使用 NFS 作为 Datastore。Veeam 正是用这种方式让 ESXi 能够访问到备份文件并直接启动。ESXi 在访问 Veeam 搭建的这台 vPower NFS Server 的时候，能够透过 Veeam 的专利技术协议 vPower 识别到在这个 Datastore 中模拟出来的 VMDK，看上去这些 VMDK 和正常的 VM 所使用的完全一样，Veeam 的这个模拟技术骗过了 ESXi。而事实上，这个 NFS Datastore 上的 VMDK 却是 Veeam 通过数据块指向技术，将 ESXi 需要访问的数据块再次定向到压缩重删后的备份文件中。 通常的这类访问，是一个单向重定向技术，也就是说在备份存档中的数据块只负责提供被读取的权限，而当有交互数据需要写入时，Veeam 的 vPower 技术又能很好的屏蔽这些写请求，使之写入至其他位置，确保备份存档的完整性和有效性。 哪里用的了 vPower 技术？ Instant VM Recovery – 直接恢复备份存档时，使用了 vPower。 SureBackup – 《全自动验证备份存档》，此功能可以查看之前的推送了解详细原理。 U-AIR – 恢复任意的应用程序的对象。 On-demand Sandbox – 隔离的沙盒用于测试开发等等各种场景。 Instant File level recovery – 任何操作系统的文件级别恢复。 以上这 5 种 Veeam 技术中，都会使用到 vPower NFS Service，也就是说，vPower NFS Service 如果出现故障，那将直接影响以上这 5 个 Veeam 的重要功能，当然这个故障基本不可能发生。 限制条件？ 目前只要是存放在磁盘上的 VM 存档都支持使用 vPower NFS Service。而存放在磁带以及 Cloud Repository 中的 VM 存档因为离线和异地等性能问题，无法支持这个操作。 vPower 写请求位置 对于不同的技术中使用 vPower，其实这点上会有一些不一样。在 Instant VM Recovery 和 SureBackup 中，Veeam 使用了两种不同的技术去处理虚拟机运行产生的变化数据块，以应对对于 Instant VM Recovery 和 SureBackup 的不同用途。 SureBackup 中，vPower 处理临时产生的数据变化量会存放于 Virtual Lab 所指定的 Datastore 的 VMDK redo log 中，因此通常的虚拟机 VMDK 都会被修改为 non-persistent 磁盘。 而对于 Instant VM Recovery 的特点是，虚拟机启动后，通常管理员会进行下一步的迁移回生产主机/存储的操作，因此无法使用 SureBackup 中这种 non-persistent 磁盘和 redo log 的存储机制，而是使用 Veeam 自己特有的 vPower NFS 缓存技术来存储新增的数据变化量，这个缓存技术的使用使得 VMware 层面上来看挂载起来的虚拟机时，是一个完整合规的可以使用 vMotion 技术的 VM。 vPower 技术配置要点 配置入口：在配置 Repository 的位置，每个 Repository 都会有它独立对应的 vPower NFS Server。 必要端口： 以上 2049+和 1058+这两个端口系统会自动侦测，如果不可用会自动增加探测更新成可用端口，而 6161 和 111 则不会自动更改，如有必要可以手动更改。 特别注意点：因为在 vPower NFS Server 之中引入了 vPower NFS 缓存技术，因此在实际使用中需要特别注意这个缓存容量的预留和变化。默认情况下，这个缓存位于 C:\\Programdata\\Veeam\\Backup\\NFSdatastore 目录下，我们一般会预留至少 100GB 的剩余空间给这个目录，当然这个目录也可以被定为到其他目录中。 而在执行 Instant VM recovery 的任务过程中，Veeam 也同样提供了修改 vPower NFS Cache 目录的功能，可以将 Cache 重定向至有足够空间的生产存储上。 对于 SureBackup，VMDK 的 redo log 则会被存放在 VirtualLab 所指定的 ESXi Datastore 中，完全不用担心以上这一 Cache 目录容量。 Instant VM Recovery 的扩展用法 使用 Instant VM Recovery 其实远不止虚拟机立刻开机这样简单的功能，在此我仅以一些特殊的例子来说明一下。 使用 IR 进行恢复磁盘 HotAdd 操作 不连接网络，不开机的情况下，启动 Instant VM Recovery； 注册完虚拟机后，将 IR 出来的虚拟机中的虚拟磁盘 Attach 到生产环境的 VM 中； 把挂载的磁盘在操作系统内联机； 在操作系统内拷贝还原数据； 卸载磁盘； 取消 IR 操作。 利用空 VMDK 恢复非标文件系统数据 不连接网络，恢复后开机，启动 Instant VM Recovery； 创建一个新的 VMDK 将这个 VMDK Attach 到 IR 出来的 VM 中 登入系统，按照特殊需求格式化 VMDK 磁盘并拷贝数据 从 IR 出来的 VM 中移除新 VMDK 并投入生产系统使用 停止 IR 虚拟机。 ","date":"2018-03-05","objectID":"/2018/03/vpower-nfs/:0:0","tags":["VMware 黑科技"],"title":"Veeam 黑科技之 vPower NFS","uri":"/2018/03/vpower-nfs/"},{"categories":["数据保护"],"content":"Veeam 有一个非常特别的功能，它能够全自动的在线验证备份存档的可用性，确保备份下来的内容是能够被正常恢复的。 该功能之所以能够确保恢复，是因为它会将备份存档在一个隔离的环境中以一个正常的虚拟机的形态启动起来，然后通过一系列的仿真测试去全自动的测试这个虚拟机的状态，包括了虚拟机的心跳、虚拟机网络的连通性甚至是虚拟机内应用程序和服务的运行状况，在测试完成之后，它还会生成一份验证报告，给出该备份存档可恢复性的相关结论。 Veeam SureBackup 适用于 VMware 和 Hyper-V 的备份，本文仅以 VMware 环境为例说明 SureBackup 的技术原理以及使用方法。 ","date":"2018-03-05","objectID":"/2018/03/surebackup/:0:0","tags":["VMware"],"title":"备份存档能不能被恢复，这件事情上只有真正做过才知道。","uri":"/2018/03/surebackup/"},{"categories":["数据保护"],"content":"如何工作？ Veeam SureBackup 在工作时，会依次执行以下步骤完成整个验证过程： Veeam Backup \u0026 Replication 会将 Application Group 和被验证的虚拟机发布到一个隔离的沙盒环境中，通常我们称作为“数据实验室（DataLab.）”。这些虚拟机是直接从备份存储库的被压缩重删后的备份文件中启动，而不需要被预先还原至 VMware 的 Datastore 中。实现这一功能需要依赖 Veeam 的 Instant VM Recovery 和 vPower NFS Service。 Veeam Backup \u0026 Replication 对 Application Group 和被验证的虚拟机执行一系列的自动化校验测试，通常包含虚拟机心跳、网络 ping 和应用程序脚本测试，其中应用程序脚本可以通过自定义的方式加入。 在基础验证完成后，还可以选择让 Veeam SureBackup 对备份存档从文件层面执行一次 CRC 校验，确保在执行任务的过程中未修改原始备份存档。 在 SureBackup 任务结束后，Veeam Backup \u0026 Replication 对这些虚拟机执行“Unpublish“动作，并且生成一份测试报告，此报告会通过 Email 的方式发送给指定的管理员。 在整个验证过程中，Veeam 会保证所有虚拟机的备份存档处于只读状态，所有因虚拟机运行产生的数据会存放在虚拟机 Redo Log 中，这些 Redo Log 通常会存放于 VMware 的生成存储上，而当验证过程结束时，Veeam 会删除这些 Redo Log，释放临时空间。 ","date":"2018-03-05","objectID":"/2018/03/surebackup/:0:1","tags":["VMware"],"title":"备份存档能不能被恢复，这件事情上只有真正做过才知道。","uri":"/2018/03/surebackup/"},{"categories":["数据保护"],"content":"验证过程中的组件 和通常备份的基础架构不一样的是，执行 Veeam SureBackup 时，会需要用到几个 SureBackup 专用的对象。 Application Group - 在验证某些虚拟机时，这些虚拟机需要依赖一些其他的虚拟机才能正常启动和工作，Application Group 就是为这些虚拟机正常工作提供所需的其他依赖应用程序和服务。通常我们会将运行这些应用程序和服务的虚拟机放入应用组，为验证提供依赖条件。举例来说，当我们需要去验证一台 Exchange 服务器时，该 Exchange 服务的启动需要有 AD 和 DNS 服务，因此，我们可以在 Application Group 中加入提供 AD 和 DNS 服务的虚拟机，用来为 Exchange 提供启动依赖。 Virtual Lab - 这是一个隔离的虚拟化沙盒环境，Application Group 中的虚拟机和被验证的虚拟机都会在这个沙盒中启动起来。 SureBackup Job - 这是来自动或者手动执行验证备份存档的任务。它能够定时定期执行，也能够手动执行。 ","date":"2018-03-05","objectID":"/2018/03/surebackup/:0:2","tags":["VMware"],"title":"备份存档能不能被恢复，这件事情上只有真正做过才知道。","uri":"/2018/03/surebackup/"},{"categories":["数据保护"],"content":"SureBackup 实战 如上面提到的，SureBackup 有 3 个专用对象，因此在使用和配置 SureBackup 过程中显然需要进行这 3 个对象的设置。 Application Group 这也是整个生产环境基础架构中最最重要的服务之一，其他应用程序的启动和运行都依赖这些机器。简单来说，Application Group 就是定义一组虚拟机，这组虚拟机非常重要，其他被验证的虚拟机没有这组虚拟机无法工作。也就是当我们的环境中存在这样的虚拟机，那我们就需要将他定义为 Application Group，以便其他机器在被校验时能够访问到这些虚拟机和服务。 当然，Application Group 中的这些虚拟机也是从备份镜像中启动起来，需要预先被备份，而不是直接使用生产环境的虚拟机。SureBackup 对于 Application Group 中的虚拟机，也会定义一系列的校验和检测，确保 Application Group 中的虚拟机首先正常工作，然后才开始后续的其他虚拟机验证。当 Application Group 中的虚拟机验证失败的情况下，SureBackup 将会中止工作，不会继续后续的虚拟机验证，这是因为 SureBackup 默认 Application Group 无法正常工作的情况下其他被验证的虚拟机也无法正常启动。因此，请不要在 Application Group 中放置非必要的虚拟机；如果被验证的虚拟机无需其他应用程序和服务依赖，则请不要在 Application Group 中放置虚拟机。 配置方法 Application Group 的创建非常简单，将 Veeam Backup \u0026Replication 主界面切换到 Backup Infrastructure 下，在清单面板中选择 SureBackup 节点，这时候在右边的内容显示区域，可以找到 Add Application Group。 点击这个链接会弹出 Veeam 经典的向导设置界面。 首先是设定 Application Group Name 和 Description，这个可以根据需要设定，没什么特别要求，方便识别和符合企业/组织的命名规范即可。 接下来是设定这个 Application Group 中有哪些虚拟机，这就如上文解释的，我们可以将备份存档、复制存档或存储快照存档中的 VM 加入到 Application Group 中，这 3 种添加模式分别对应了 Veeam SureBackup 的 3 种分支功能：SureBackup/SureReplica/Ondemand Sandbox for StorageSnapshot。此处暂且不详细展开去讨论这 3 种分支功能的具体使用。我们就是用通常备份验证中用的最多的 From Backup。这也是上文中提到，Application Group 中的虚拟机也必须是预先被备份，而不能是直接选择生产环境中的相关虚拟机。 选择完虚拟机后，可以为这些选择的虚拟机设定一些验证选项，这也是上文提到的，Application Group 中的虚拟机必须首先被验证能正常工作，才能进行后续操作。这里的验证选项包括内置的一些服务器角色，比如 DNS Server、Domain Controller、Global Catalog、Mail Server、SQL Server、Web Server 等，选中这些服务器角色时，Veeam 会自动使用适合这些角色的预定义脚本验证这些角色服务器。（关于 Domain Controller 的 Authoritative Restore 和 Non-Authoritative Restore 知识点，本文不详细阐述，读者可自行百度。） 在这个验证选项中还有启动选项、测试脚本和账户凭据设置，在此就不一一详述，这些都是对应验证过程中一些详细的设定选项，对于特别的应用程序在测试中有帮助，具体可以参考 Veeam 官网手册说明。 这样，一个 Application Group 就基本设置完成了，可以通过最后一个 Summary 页面回顾下设定的内容。 Virtual Lab 这是被验证的虚拟机所运行的隔离环境，在这个环境中 Veeam Backup \u0026 Replication 将会逐个启动 Application Group 中的虚拟机，然后再启动需要被验证的虚拟机。 Virtual Lab 本身其实几乎不消耗任何资源，它可以在任意的 ESXi 主机上被部署，当需要被验证的虚拟机启动的时候，Virtual Lab 才会请求计算资源分配给这些虚拟机。Virtual Lab 会在隔离环境中创造出一套网络，它将生产环境中的网络完整的镜像至 Virtual Lab 创造出来的这套网络中，在 Virtual Lab 中启动的虚拟机和原虚拟机拥有一模一样的 IP 地址配置，因此在 Virtual Lab 中启动的这些虚拟机能够和生产环境一样正常的工作。 在 Virtual Lab 之中，有非常重要的概念，分别是：Proxy Appliance、IP Masquerading、Static IP Mapping。 Proxy Appliance 为了和生产网络能够通讯，Veeam Backup \u0026 Replication 又使用了一个 Proxy appliance。这个 Proxy Appliance 是一个基于 Linux 的轻量级虚拟机，它会被创建在每一个 Virtual Lab 中，通过这个 Proxy Appliance 的多个网卡将 Virtual Lab 中的虚拟机和生产环境进行连通。 IP Masquerading Veeam 建立起一套规则，让生产网络能够通过特定的 IP 地址访问隔离网络，同时又不用修改隔离网络内的 IP 地址配置，那么这套重要规则就是 IP Masquerading。 每一个生产网络中的 IP 地址，在隔离网络中，都会通过 IP Masquerading 建立起一个一一对应的地址，比如生产网络中的地址是 172.16.10.10，IP Masquerading 规则是 172.16.10.X/24 对应 172.18.10.X/24，那么这台虚拟机的备份存档在 Virtual Lab 中启动起来后的 Masquerade IP 地址会自动被分配为 172.18.10.10。 这个规则会通过静态路由的形式被添加至 VBR 备份服务器和 Virtual Lab Client 的所运行的桌面上。当有网络访问 172.18.10.10 时，Proxy Appliance 会充当一个 NAT 服务器的角色，将访问转发至 Virtual Lab 内的这台虚拟机上。而实际上 Virtual Lab 内的这台虚拟机此时启动后的 IP 地址本身并没有发生变化。 Static IP Mapping 上面提到这样的静态路由仅会被添加至 VBR 备份服务器和 Virtual Lab Client，那么当有很多客户端的都需要访问这个 Virtual Lab 中的虚拟机时，手动逐台添加静态路由会很不方便。 这时候，在这种场景下 Veeam 提供 Static IP Mapping 为更多的虚拟机的访问提供方便快速的设置方法。我们可以利用 172.16.10.X 网络中其中一个空闲的 IP：172.16.10.99 做一个静态映射，将其映射给 172.18.10.10，这时候网络上的所有客户的都可以通过 172.16.10.99 这个 IP 地址访问到 Virtual Lab 中的这台虚拟机，而不用逐台添加 172.18.10.X 的静态路由。 配置 Virtual Lab 因为 Virtual Lab 的配置有 3 种不同模式，本文不详细讨论 3 种模式的区别，仅以最常用的 Advanced Single-Host Virtual Lab 为例介绍配置方法。 将 Veeam Backup \u0026Replication 主界面切换到 Backup Infrastructure 下，在清单面板中选择 SureBackup 节点，这时候在右边的内容显示区域，可以找到 Add Virtual Lab。 点击这个链接会弹出 Veeam 经典的向导设置界面。 首先是设定 Virtual Lab Name 和 Description，这个可以根据需要设定，没什么特别要求，方便识别和符合企业/组织的命名规范即可。 选择主机，选择此 Virtual Lab 是运行哪一个 ESXi 主机上，每一个 Virtual Lab 仅允许运行在一个 ESXi 主机上。 选择数据存储，Virtual Lab 中产生的临时数据和 Virtual Lab 必要的一些运行文件会存放在这个 Datastore 中，包括临时的虚拟机 Redo log 也会存放在这个 Datastore 中。它的容量主要还是取决于 Virtual Lab 开启后数据的改变情况，在一般没有太多改变的时候，这个容量要求并不太高。 设置 Proxy Appliance，这一步需要设置是否使用 Proxy Appliance 以及如何将 Proxy Appliance 连接到生产网络。一般来说，全自动的验证和数据实验室都是需要 Proxy Appliance 的，因此默认都会启用 Proxy Appliance。而在不选择使用 Proxy Appliance 的场景中，则所有的验证都需要通过手工进入虚拟机内控制台去操作实现。在启用 Proxy Appliance 后，","date":"2018-03-05","objectID":"/2018/03/surebackup/:0:3","tags":["VMware"],"title":"备份存档能不能被恢复，这件事情上只有真正做过才知道。","uri":"/2018/03/surebackup/"},{"categories":["数据保护"],"content":"VBR 中的 Agent 集中管理 本次更新加入了 Agent 的集中管理，界面上发生了很大变化，原有的 Backup \u0026 Replication 更名成为 Home，而原有的 Virtual Machine 更名为 Inventory。Agent 的管理功能都会搬到 Inventory 下面的 Physical \u0026 Cloud Infrastructure 下。 Veeam 管理 Agent 的方式还是和其他 Veeam 的功能非常类似，非常简单的 3 部曲方式： 创建 Protection Group – 定义并自动发现需要保护的对象。 创建 Job 或者 Policy – 定义备份任务或者备份策略实现备份。 执行 Restore – 通过多种还原手段实现数据还原。 我们先来一起熟悉下 Physical \u0026 Cloud Infrastructure 界面。 在这个节点中会出现一些类似文件夹的图标，在软件升级完成后，会立刻出现 Manually Added、Unmanaged 这两个系统内置文件夹，而在我们开始创建新的 Protection Group 后，又会出现一些我们创建的文件夹，每一个文件夹就是一个 Protection Group，里面会包含一组需要保护的服务器或者工作站。 创建 Protection Group 又是老套路，Veeam 经典的向导式操作方式，创建 Protection Group 支持 3 种添加 Protection Group 的方式，其实也就是 3 种不同的服务器/工作站添加模式 Individual computers 这种方式可以手工逐台 Computers 添加，支持 Host Name 或者 IP address，然后 Credentials 中输入合适的账号密码即可。 Microsoft Active Directory objects 这种方式需要先点击 Change 按钮设定 AD 相关信息，包括 AD 的域名和域管理员账号，然后就可以找到 AD 中的所有对象，按照对象的方式动态添加被保护的服务器/工作站。 自动排除不需要使用 Agent 进行保护的对象，特别是虚拟机。 Computers from CSV files 这种模式只需手工编辑 host name 或者 ip 地址到一个 CSV 文件，然后指定从这个文件读取 host 列表即可。 为不同的 Host 分别指定合适的管理员账号。 设定自动发现和扫描的间隔，在扫描完成后是否进行 Agent 和 Windows CBT 驱动的自动推送安装，安装完成后如果有需要重新启动，是否自动启动。 检测推送分发 Agent 的服务器的状态，检测完成后，Protection Group 就创建完成了。 Veeam Agent for Windows 和 Veeam Agent for Linux 略有不同，我们先看看 Windows 的。 ","date":"2018-01-01","objectID":"/2018/01/centrilized-agent-management/:0:0","tags":["Agent"],"title":"新年第一篇 - Veeam 9.5U3 集中管理 Agent 详解","uri":"/2018/01/centrilized-agent-management/"},{"categories":["数据保护"],"content":"Veeam Agent for Windows 的集中管理 在自动发现了一组机器后，Protection Group 中会罗列出所有自动扫描到的机器，在这个 Protection Group 中，我设定了不自动安装 Agent，这时候对于需要安装 Agent 的机器，我可以通过屏幕上方的工具栏进行 Agent 的安装和卸载工作，同时我还能完成该服务器/工作站的重启、恢复介质的创建工作，在原先，这些工作都能够在 Veeam Agent for Windows 的客户端上完成，现在已经全部集成到了 VBR 上。 对于 Windows 服务器，创建备份任务也非常的简单，只要点击 Add to Backup 即可，还是经典的向导界面： 在这里我不详细展开介绍 Workstation 和 Managed by Agent 内容，这些选项能够为我们在远程站点备份数据的时候带来帮助，功能和之前的 2.0 版本中非常相似，我们重点来看看 Managed by backup server 这个选项的功能。 设定备份任务名字 选择被保护的服务器，在这里还能定义保护的服务器的顺序。 选择保护模式，还是和之前的完全一样。 选择备份至哪个存储库，一样可以在高级选项中设定 Synthetic full 和 Active full 的时间。 应用感知，也是 Veeam 经典模式。 依旧是经典的计划任务设定。这样就完成了一个 Windows Agent 的备份任务设置。 任务执行情况，在执行过程中会截断日志并且收集 Windows 的驱动程序，用于后续的恢复。 在 Home 界面中，能够找到备份下来的存档，选中备份存档，可以执行一系列 Veeam 支持的恢复操作，依旧还是 Veeam 经典的管理方式，和虚拟化的恢复完全一致。 而物理机的裸机恢复则是由 Recovery Media 来完成，向导式的 Recovery Media 生成界面也从客户端搬迁至 VBR 中。 ","date":"2018-01-01","objectID":"/2018/01/centrilized-agent-management/:1:0","tags":["Agent"],"title":"新年第一篇 - Veeam 9.5U3 集中管理 Agent 详解","uri":"/2018/01/centrilized-agent-management/"},{"categories":["数据保护"],"content":"Veeam Agent for Linux 的集中管理 和 Windows 不一样，Linux Agent 少了 Recovery Media 创建、CBT 驱动安装以及 Reboot 按钮。 创建备份任务，也是向导模式，只是没有了 Cluster 支持，暂时 Linux 平台无法支持 Cluster 模式。 备份任务名称和描述设定 选择被保护的服务器/工作站。 选择备份模式 选择备份存储库和还原点数量。 设定 Linux 的应用感知，主要通过 Script 来实现，同样文件系统的索引也是在这一步来进行。 经典的计划任务界面，设定时间后，就创建好 Linux 备份任务了。 备份任务执行也是经典 Veeam 界面，相信大家都很熟悉了。 对于 Linux 存档的恢复，在 VBR 中操作相对来说较少，仅支持文件级恢复、还原至 Azure 以及导出成虚拟磁盘这几项，而如果需要进行裸机还原，则需要在 Veeam 官网下载 Linux 专用的 Recovery Media。 电梯直达链接：https://download2.veeam.com/veeam-recovery-media-2.0.0.400_x86_64.iso 另外，如果需要查看更详细的 Release Notes 和下载更新包，可以点击阅读原文。 ","date":"2018-01-01","objectID":"/2018/01/centrilized-agent-management/:2:0","tags":["Agent"],"title":"新年第一篇 - Veeam 9.5U3 集中管理 Agent 详解","uri":"/2018/01/centrilized-agent-management/"},{"categories":[],"content":"上周 VeeamON 上海站，我最大的收获可能就是看到同事的 LAB 环境了，很诧异的发现，他的笔记本竟然装上 ESXi 了，按照我以往的认知，笔记本上安装 ESXi 会是一件挺麻烦的事情，特别是找驱动。不得不感叹，同学们勇于尝试的精神，这里的 Key Point 是使用 Dell 定制的 ESXi ISO 来安装，这样什么驱动都不需要考虑，硬盘、网卡全部含在内，一键安装一键启动，实在太方便了。遂回家决定在周末也来一次改造。 不过犹豫再三，觉得平时 LAB 里面还是需要保留一套 Hyper-V，公司配备的 Dell M4800 工作站内置的硬盘做成 VMFS 有点可惜了，正巧手边有一块退休的 USB3.0 移动硬盘，萌生了 1 套 LAB 硬件同时做 Hyper-V 和 VMware 的念头。Google 一小会儿，把自己的想法验证下，看看是否有一些素材能够支持这样的做法，一点不意外，完全可行。 M4800 配置： CPU：i7-4710MQ@ 2.5GHz MEM：32GB Disk（internal）：SAMSUNG SSD 500G ​ Seagate SATA 500G Network：Intel i217-LM 外置设备： USB Stick：U 盘 8GB，用于启动系统 USB HDD：WD 2TB SATA，通过 USB3.0 接入至 M4800，用于 local datastore DELL customized ESXi：可以至 Dell 官网查找下载，阅读原文可以快速跳转 动手开干！ 部署 ESXi 过程非常简单，顺利的引导，识别出 8GB 的 U 盘，5 分钟后安装完成。进系统配 IP、主机名等一系列初始化工作，完成之后加入到现有的 VC 中。 接下去要解决重头戏，添加 External USB HDD，事实上在 VMware 官方来说，是并不支持使用 USB HDD 作为 datastore 用于生产环境，但是作为 Home LAB 来说，这可是一个好功能啊~ 添加过程如下（注意以下过程仅适合 ESXi 6.0）： 打开 ESXi 的 SSH，并连接上。 [root@esxim4800:~] ls /dev/disks ​ 找到输出中有相应的 usb hdd 信息： mpx.vmhba38:C0:T0:L0 mpx.vmhba38:C0:T0:L0:1 mpx.vmhba38:C0:T0:L0:2 [root@esxim4800:~] partedUtil mklabel/dev/disks/mpx.vmhba38\\:C0\\:T0\\:L0 gpt 计算 vmfs 卷的 end sector [root@esxim4800:~] eval expr $(partedUtilgetptbl /dev/disks/mpx.vmhba38\\:C0\\:T0\\:L0 | tail -1 | awk '{print $1 \"\\\\* \" $2 \" \\\\* \" $3}') – 13907024064 [root@esxim4800:~] partedUtil setptbl/dev/disks/mpx.vmhba38\\:C0\\:T0\\:L0 gpt \"12048 3907024064 AA31E02A400F11DB9590000C2911D1B8 [root@esxim4800:~] vmkfstools -C vmfs5 -SUSB-LOCAL /dev/disks/mpx.vmhba38\\:C0\\:T0\\:L0:1 至此，回到 vSphere Client 中就能看的已经添加的名字叫 USB-LOCAL 的 datastore 了。 双系统改造完成，只要选择从本地硬盘启动即可回到 Windows2016 的 Hyper-V，而平时将会一直运行 ESXi。 ","date":"2017-08-27","objectID":"/2017/08/esxi-in-m4800/:0:0","tags":["VMware"],"title":"改造 HOME LAB 之把 ESXi 装进 M6400","uri":"/2017/08/esxi-in-m4800/"},{"categories":["数据保护"],"content":"上一期，我们讨论了 备份引擎的加速，这对尽可能快的完成备份提升 RPO 有着极其重要的意义。然而除了这个数据传输引擎之外，在备份时还有一个加速器，那就是 vSphere 通讯加速技术。 Broker Service 这是 Veeam9.5 中新增加的一个特性，简单来说这项科技给备份带来的帮助是在 Veeam 和 VMware vCenter 之间加入了一个过渡服务，当 Veeam 每次发起任务时，需要查询 vSphere 信息时，可以替代性的去查询 BrokerService 而不用直接去找 vSphere。 如下图，这是有无 BrokerService 的一个直观对比，没有 Broker 时，每次备份任务都会去直接和 vCenter 通讯，其获取返回结果的耗时完全取决于 vCenter 性能和网络状况。而在有了 Broker 之后，Veeam 则会去查询 Broker 中缓存的信息，而由 Broker 保持和 vCenter 处于 update 状态。 那么这个 Broker 事实上在 Veeam 软件中是以一个服务的形式存在，因此我们在 Services.msc 中可以查看到这个 Service: 这个 Broker 在工作的时候，VMwarevCenter 中清单基础架构的任何变化都会实时的被推送至 Broker 的缓存中，而如果 Veeam 未收到任何推送变化的情况下，默认 Veeam 会每 15 分钟（900 秒）进行一次强制更新缓存，确保缓存内容的准确性。 所以，这带来的好处显而易见，以下是一组软件中截图的对比，在无 Broker 的情况下，Veeam 备份任务通过查询 vCenter 来创建备份虚拟机列表，消耗了 40 秒时间： 而在有了 Broker 之后，Veeam 备份任务查询 Broker 来创建备份虚拟机列表，仅需要耗时 1 秒： 这可以说效率提升了 40 倍以上！！ 好吧，为了让你的备份速度飞起来，升级到 Veeam 9.5Update2 吧。 下期预告： 备份速度快不算啥，这都不是啥大事，划重点的来了，真正要快的还原技术，而 Veeam 除了有 Instant VM Recovery 之外，其他的那些还原技术会不会也很快？下期为你揭晓答案。 ","date":"2017-08-07","objectID":"/2017/08/speed-up-02/:0:0","tags":["VMware"],"title":"加速！加速！加速！（二）","uri":"/2017/08/speed-up-02/"},{"categories":["数据保护"],"content":"一直很少去谈论速度和性能，就像一辆好车，我认为这个是基本配置，然而这个基本配置对于任何一辆车来说都是极其重要的。对于备份领域来说，驱动备份和还原速度的引擎就像汽车的发动机，是一个备份软件真正展现其价值的重要部分。我想就这个问题，来详细讨论 Veeam 的加速技术。今天的内容是加速系列的第一部分 – 备份加速引擎。这一引擎在备份软件中不仅仅是帮助了实现备份功能，更是 Veeam 去帮助客户实现 IT 可用性的重要保障 Veeam 备份加速引擎 和其他使用 VMware vStorage API for Data Protection（VADP）的备份软件不一样，除了软件传输服务中集成了 VMware Virtual Disk DevelopmentKit（VDDK）之外，Veeam 额外加入了一套优化数据提取的组件：Veeam Advanced Data Fetcher（ADF）。这个 ADF 简单来说就是为企业级存储阵列额外增加了超过 2 倍读取性能的列队深度，这个带来的直接的效果就是极大地加快了从 vSphere 平台数据源读取数据的速度。相比同类的备份产品，在从源端读取时，效率上有成倍的提升，并且 ADF 还降低了读取数据需要的 I/O 操作数量，从而有效的降低了读取相同容量的数据时对于生产存储的 I/O 压力。 当然，Veeam 还为这个 ADF 配备了一个智能的调控开关 Backup I/O Control。当从生产读取速度并不快时，其实备份软件完全不需要考虑会不会对生产造成影响，可以说是完全可以忽略生产环境。当我们的速度足够快时，必须考虑到生产存储的负载能力，在生产对外服务的同时还要同时高效的完成备份，这就不是拍脑袋想多少是多少了。 Veeam ADF 和 Backup I/OControl 的协作可以完全智能地去完成对生产存储的控制，通过自动感知生产存储 Latency 技术，动态控制 ADF 的吞吐量来实现在有效的 Latency 范围内进行备份。 在以往，一个备份管理员，通常会设定每天执行一次备份的数据保护策略，并且将这个备份时间段设定在晚上业务相对不繁忙的时间。这样的设定 RPO 就是 24 小时，究其原因并不是说管理员保守，而是因为没有很好的智能控制手段，所以备份要为生产让路，保证可用性的前提下去进行备份。然而现在 Veeam 的引擎，Veeam ADF 和 BackupI/O Control 的协作，可以让备份管理员在不影响生产的情况下，在任何时间段完成备份，从而有效的提升备份的 RPO。 所以，Veeam 不仅仅是完成了备份这么一件大家能用各种方式实现的事情，可能殊途同归，但是 Veeam 的技术是让在完成备份的同时达成可用性目标，关键业务的备份可以在任何时间进行，而不是备份必须在维护停机窗口进行。24×7×365 的可用性保证从做备份做起！ 下期预告： vSphere 通讯加速技术 - 虚拟化备份前，备份软件需要花大量时间与虚拟化平台通讯，这是整个备份作业中第二大耗时作业，全新的 Veeam Broker Service 能够帮助极大提升这个速度，节省时间。 ","date":"2017-08-01","objectID":"/2017/08/speed-up-01/:0:0","tags":["VMware"],"title":"加速！加速！加速！（一）","uri":"/2017/08/speed-up-01/"},{"categories":["数据保护"],"content":"虚拟化技术是一个彻底改变 IT 世界的技术，同样在备份领域随着虚拟化技术的使用引入的无代理备份概念也不断对传统技术带来冲击。但是作为一对互相矛盾的技术 - 代理备份和无代理备份，其各自的优缺点也是相当明显。然而 Veeam 的无代理备份技术则是发挥了两者绝大多数的优势，实现了无代理备份的同时能感知应用程序。 什么是代理（Software Agent）？ 这个 IT 专业词汇其实在中文上来说，并没办法给出很好很明确的定义，以致我们日常在技术交流的时候会含糊其辞，有时候会谈广义的代理，有时候会谈狭义的代理。我试着去从百度百科找找代理的定义，结果还是无功而返。而在 wikipedia 上，倒是有 Software Agent 的定义，不过也只是通过大众的认知给了一些 Software Agent 的应具备的特性： 持续运行 - 通常会保持运行状态，即使空闲时候也会处于等待状态。 自动自主运行 - 无需人工干预和交互就能保持运行状态。 应用程序交互功能 - 能够和其他程序发生交互，激活其他模块、互相通讯、协同工作。 仔细琢磨了下，确实传统领域的代理备份，那些代理软件倒是符合这些 Agent 应具备的特性。 Veeam 无代理备份和应用程序感知 Veeam 的虚拟化备份技术，是不需要在任何的操作系统内安装任何这类的程序，因此备份不需要系统的运行状态。 而应用程序感知则是在备份过程中，Veeam 全自动的到操作系统内运行一个进程，完成相应的应用程序感知、一致性保障和文件系统一致性处理，之后关闭应用程序，退出执行。这一过程只是在备份执行过程中的一个可选进程，因此是完全不同于上述的代理程序。 所以，通常代理程序会面临的问题，对于备份代理一样会碰到： 需要不停的为新部署的虚拟机，手工安装代理程序（我们认为推送虽然方便，但也是“手工”的一种，避免不了远程/本地的配置工作）； 软件更新的时候，需要为每一台机器升级代理； 在长期大规模环境的运行过程中，还需要考虑拿个什么软件去监控这些代理，我们所谓代理保姆，就是干这事的，防止哪天这些代理突然不工作了也没人知道； 以上这些都是长期消耗计算资源的，包括 CPU、内存、网络、存储，并且很多时候是重复的消耗。 而 Veeam 的技术，在深入到应用程序层面的感知进程，仅仅是在备份启动那一刻运行几分钟后立刻被关闭退出，因此完全不存在以上提及的这些问题。无需每次部署/无需更新/不用长期运行监控。 更有意思的是，现在的 IT 世界是一个运行越多风险越大的世界。我们没有任何应用程序的时候，就是一个最最安全的状态，而每增加一个应用程序，就多一份被黑客、病毒、勒索软件攻击的风险。为每一个系统减少一份持续运行应用程序，就是为我们的系统安全增加一份保障。 另外，如果系统关机了，那么需要保持运行才能进行备份的代理程序就彻底歇菜了。备份目标 Offline，这是传统备份软件界面中常常见到的事情，这时候备份管理员能做的唯一事情就是去找到应用或者基础架构的管理员去启动这个操作系统。而对于无代理的技术，即使是系统关机的情况下，备份依然不受影响。而还原过程中，Veeam 的多样化的颗粒度恢复却依然可以手工执行，堪称是完美的备份和还原。 传统代理的更多缺陷 利用代理技术的数据备份，绝大多数依赖网络。当我们为了隔离安全，去架构 DMZ 区域，去进行严格的出入规则的时候，突然发现因为买备份这个保险，我们不得不需要有个数据流去 DMZ 区域完成数据的抽取，以致原先的完全隔离的架构被打破，苦心设计的完美架构失去了其原本的设计目标。 Veeam 的这种应用程序插入运行技术则完全不同于传统代理，在感知应用程序时，这个运行执行可以通过 VIX 在无网络连通的状态下进行 Hypervisor 层面的感知。因此，在 Veeam 的设计理念中，可以为那些 DMZ 区域的备份带来更多一份的安全。 ","date":"2017-07-23","objectID":"/2017/07/agentless-backup/:0:0","tags":["VMware"],"title":"无代理备份和应用程序感知","uri":"/2017/07/agentless-backup/"},{"categories":["黑科技"],"content":"最近这些天，碰到不少在 VMware 环境中使用 NFS 作为 datastore 的用户，发现 NFS 的场景是越来越多了。在以前，可能仅仅会是部分 NetApp 的用户去使用 NFS 作为 VMware 的 datastore，而现在，随着各种超融合技术的兴起，市场上几个主流的超融合平台，比如 Nutanix 和 Cisco HyperFlex 在为 VMware 提供存储服务的时候都采用了 NFS 的方式去提供 datastore。 这在以往来说，并不是一个好消息，当 datastore 是 NFS 协议的时候，虚拟机的备份可用的数据传输方式只能通过效率最差的 Network 方式，受限于备份仅仅能使用 VMKernel 的 40%最大网络吞吐量，即使是有足够的带宽，实际传输时，吞吐量依然低下。 在 Veeam Backup \u0026 Replication v9.0 之后，使用 Veeam 去备份存放在 NFS 数据存储上的虚拟机的时候，有了一种全新的数据传输方式，Veeam 把它称之为 Direct NFS Access。很容易联想到 VMware 备份中的另外一种数据传输方式 Direct SAN Access，在 SAN 备份中遵循 VMware 的数据提取方式，能不经过前端 ESXi 主机而是直接访问 SAN 存储读写数据。同样在 NFS 数据存储上，Veeam 也能够提供类似的直接存储访问，而不经过前端 ESXi 主机。 这么强大的功能，如何使用？ Veeam 的功能向来是强大却又极其简单。这个 Direct NFS Access 的功能也是如此，以下我们来看看如何去进行这个功能的配置。 首先在 VMware 上面，我们有一台虚拟机存放在 NFS 的 datastore 中，如图： 在 NFS 服务器端，设置除了 ESXi 能访问这个卷之外，Veeam 的 Proxy 也有读写的权限，本例中我在我的 FreeNAS 上做了一个访问设定，其中 10.10.1.130 是 ESXi，而 10.10.1.171 则是 Veeam Backup Proxy： 然后，在 Veeam 的控制台，我们指定一下使用备份首选的备份网络，为 NFS 的存储访问网络： 接下来，如果 NFS 数据存储是新添加的，在添加之后还未进行存储扫描，则可以做一个 VMware 基础架构的 Rescan 动作，确保识别到 NFS 数据存储。 好了，所有设定完成，直接去执行备份任务即可，在备份任务执行过程中，Veeam 会自动感知到可以使用 Direct NFS Access 的方式进行数据读取，就会优先采用这种方式读取： 上图中我们看到读取方式标注为 [nfs]，而常规其他的几种分别是 [san]、[hotadd]、[nbd]，这是最大的区别。 而在备份日志文件中，同样能找到数据读取的相关记录： 好了，这就是简单的 Direct NFS Access 的配置方法，具体更详细的说明，可以点击阅读原文，参考 Veeam 官方手册查看详细内容。 ","date":"2017-07-04","objectID":"/2017/07/direct-nfs-access/:0:0","tags":["VMware"],"title":"Veeam 黑科技之 Direct NFS Access","uri":"/2017/07/direct-nfs-access/"},{"categories":["数据备份"],"content":"上周，前方又传来一个激动人心的消息，Veeam 通过了 vSphere 6.5 刚刚开放的 VMware Web Client Plug-in Ready 认证。厉害了，这个太厉害了。具体 VMware 官网查询链接 https://www.vmware.com/resources/compatibility/search.php?deviceCategory=wcp 什么？什么？你还不知道啥是 VMware Ready？好吧，我先来普及下这个认证。简单来说使用通过认证的 plug-in 有这么几个好处： 符合 VMware Web Plug-in 的最佳实践，会被收录至各种白皮书、教科书。 用户体验极佳，可以说是几乎和 VMware 原厂软件完全一致。 插件经过 VMware 原厂严格测试，使用该插件，完全不会影响 vCenter 的性能，不用担心非原厂插件破坏 vCenter。 插件故障，VMware 给保修，这个很重要。一站式解决问题。 那么，这么好的插件，它能做点啥呢，我们来看下这个功能强大的小插件。 这个插件部署完成之后，会在 vSphere Web Client 上出现一个新的图标，和其他的 Web Client 插件一样，点击即可进入。 在这个插件中，我们能够查看到当前的备份基础架构情况： 能够看到最近 24 小时、7 天、14 天的虚拟机备份情况： 能够看到备份任务的执行和计划情况： 还能够看到最近 7 天、14 天、1 个月处理的虚拟机数量： 能够查看备份存储库的容量，再也不担心日常运维的时候忘记存储快满了： 并且以上这些内容，如果有部署 Veeam ONE，能够直接点击跳转查看完整的相关报告。如此这样，基础架构运维，是不是突然发现，简单了好多？ 除此之外，该插件还提供了快速备份的功能，在每个 VM 的右键菜单中，我们可以找到 Backup 选项： VeeamZIP，立即执行 Active Full 类型的全备份，是一种快速备份的简单方法。 VeeamZIP to … 则会跳转至 ZIP 设置界面，该界面也集成在 vSphere Web Client 中，而不用进入 Veeam Console。 Quick Backup 则是进行快速的增量或反向增量备份，用于单次的即时备份。 最后来看下 VeeamZIP 设置界面，该界面位于每台 VM 的 Manage 选项卡下的最后一项 VeeamZIP 中，如图： 这里可以简单设置备份服务器、备份存储库、Key、VeeamZIP 删除时间、压缩级别、是否进行客户端静默等选项，几乎与 Veeam Console 中的 VeeamZIP 设置选项一致。同时这里也提供 VeeamZIP 任务触发按钮。当执行 VeeamZIP 任务或者 Quick Backup 任务时，vSphere Web Client 的任务栏还会出现 Veeam 的任务进度： 好了，以上就是全部 Veeam vSphere Web Client Plugin 的功能，简单小巧，又非常好用，还带保修。 ","date":"2017-06-30","objectID":"/2017/06/another-vmware-ready/:0:0","tags":["VMware"],"title":"好消息好消息，Veeam 又通过一项 VMware Ready 认证！","uri":"/2017/06/another-vmware-ready/"},{"categories":["Veeam 小工具"],"content":"前言 在上个月的 VeeamON 大会上，Veeam 发布了一个全新的产品，这个产品其实和备份是完全没有关系，叫 Veeam PN，全称是 Veeam Powered Network。这是一款轻量级的 SDN 解决方案，能够迅速打通多个站点，实现站点-站点之间的通讯，也可以实现终端-站点的通讯。由于此解决方案功能过于强大，本文不想展开全面介绍，详细内容可以参考 Veeam KB2271 和 VeeamPN 帮助手册。 今天的内容，我想来介绍下我的使用场景，在我的 Home Lab 中使用 Veeam PN。 先来说说需求，其实这个需求并不复杂，我相信绝大多数的 VPN 解决方案都能够实现，也就是当我不在家的时候，任意一个地方，我都能连回家里的实验室，进行工作。 实现这个功能，大多数方法可能是基于 VPN 的方式，也就是说得搭建 VPN 环境，那么各种环境中搭建方法可能各式各样，而 Veeam PN 为我这样的环境提供了一个非常简单的部署方法，只需几分钟，鼠标点击几下，就能完成这样的搭建。 架构组件 这整个架构中里面一共有 3 个组件： Veeam Hub 相当于接入点，充当了集中控制所有端点的一个唯一入口。Veeam Hub 可以部署在任意的位置，任意的一个有互联网接入的站点、云端都可以，唯一的要求就是能够和其他站点通过广域网互联互通，有公网地址。 Veeam Site Gateway 每个站点的出口连接 Hub 的网关。这里的每个站点的概念为 1 个子网，也就是说每个子网都需要一个 site Gateway。对于 Site Gateway 的要求，是有 internet 接入而不必有公网地址。 VPN 客户端 终端连接入私网的客户端，Veeam PN 可以使用任何支持 OpenVPN 的客户端，具体客户端下载可以自行百度查找。 如图，简单架构就是这样。对于我 Home Lab，目前仅有一个网段，是 10.100.1.0/24，所以在我的 Lab 中我需要的组件就是一个 Hub 和一个 Site Gateway。这两个组件的部署非常简单，其实是同一个 OVA 的不同工作模式，具体下载地址可以点击阅读原文查看。 安装配置 在 vSphere Client 中，和常规部署 OVA 一样，导入这个虚拟设备进行部署，导入后，可以进入这个 Ubuntu 系统进行 IP 地址和主机名。 因为我的这个 Hub 和 Site Gateway 都部署在家中，所以我需要重复上面的步骤导入两次，生成 2 个虚拟机，分别配置为 Hub 和 Site Gateway： 接下去，可以通过网页分别访问 Hub 和 Site Gateway 进行详细配置，整个配置过程非常简单，首先来看下 Hub，我们进入 Hub 的网页： Https://10.100.1.40/ Username：root Password:VeeamPN 进去后会提示修改密码并选择角色： 先选择 Hub，进行下一步： 简单填入一些个性化信息后可以点击下一步，其中加密等级保持默认 2048 位就可以了。 设置公网 IP 或者 DNS，我在这里输入了我自己的对外 internet DDNS 域名，端口保持默认。点击 Finish 就能完成 Hub 的基础设置。 然后我们来添加一个 Site 和一个客户端接入点，点击 Clients，Add 按钮就能打开向导 选择添加一个 Site 或者一个计算机，Entire Site 就是加一个 site Gateway，而 standalone computer 就是远程单独接入点： 我们先加一个 Site，选择 Entire Site 后 next： 任意输入一个名字标识，然后添加子网段地址，比如我家 Lab 是 10.100.1.0/24 点击 Finish 之后，就会自动下载一个。xml 文件，这个文件将会在 Site Gateway 配置过程中用到。 然后我们来再重复前面 Add Client 步骤来添加一个接入点： 接入点只需要一个名称来标识，没有更多信息需要配置，点击下一步和 Finish 之后，浏览器会自动下载一个。ovpn 文件，这个文件可以在任何的 OpenVPN 客户端中载入并连接。 接下去可以打开 Site Gateway 的页面进行 Site Gateway 的连接 Hub 配置。 进入 site Gateway 页面之后依旧是修改密码和初始化向导，只是不同的是初始化向导中选择 Site Gateway，而不是 network Hub Next 之后，选择刚刚从 Hub 上下载到的。xml 文件导入点击 Finish 就完成了 Site Gateway 配置，这样这个 Site 就自动连接到 Hub 上了。 最后，我们来配置 OpenVPN Client。目前在所有操作系统平台上，包括手机上，都可以找到合适的 Client，本文就以最常见的 Windows 为例，可以安装** openvpn-install-2.4.2-I601.exe** 过程也极其简单，一路 next 完了之后，双击快捷方式后 import 之前下载下来的。ovpn 文件即可进行连接，整个连接过程也不需要输入用户名密码之类的，就和通常 OpenVPN 的连接是完全一样的。 至此，我就能在外面任何地方轻松的连上自己家里的实验室了。 ","date":"2017-06-16","objectID":"/2017/06/veeam-pn-intro/:0:0","tags":["VeeamON"],"title":"VeeamON 2017 系列之另类 VPN -- Veeam PN","uri":"/2017/06/veeam-pn-intro/"},{"categories":[],"content":"从 5.12 晚爆发开始，一直到今天下午，一直有接到朋友各种求助、紧急取消活动、启动应急预案和恢复数据的电话。这波“想哭”确实如其名，让那些没有准备或者准备不足的朋友们好想好想哭，有没有？ 好了，不管如何，付了钱也好，没付钱恢复了数据也好，在静下来把事情都结束了以后，我们可以好好想想应该如何在以后更好的防范此类事件，做到全方位无漏洞。 让我们先回到病毒爆发前 备份！备份！认真做好备份！重要的事情说三遍，备份在这个环节中是多么的重要，在大规模病毒爆发后，如果拥有了中毒之前的备份数据，我相信，这个勒索病毒可以被轻而易举的化解。那么这个备份该如何做好呢？ 备份数据别和生产数据放一块儿，这是做备份的大忌，放一块儿就相当于把所有钱都放 1 个钱包，掉了一起掉，这个是最容易忽略的常识，但是在备份的时候也是最容易犯的。这里的放一块儿指的不仅仅是一套系统上一套存储上，备份的数据尽量实现和生产环境没有直接关系才是最合理的。 多准备几份备份数据是不会错的，当你有 3 份以上不同的数据的时候，我相信应对这样的场面，你肯定很有信心。 平时如果做过演练，每个恢复点都是验证过一切正常能恢复的话，那么这时候碰到这种情况就是信心百倍了。 来看看病毒爆发时 快速恢复，越快越好！这时候最直接的方式，即时虚拟机恢复，这是有多快恢复多快。2 分钟之内回滚到历史保存点，业务恢复上线。这时候也不用在外面贴告示了。 那么仔细再想一下，本次大规模中毒其实一部分系统层面的工作，可以通过杀毒打补丁进行修复，而解密工作，暂时没有太好的办法，只能通过备份软件进行恢复，而文件有重要和不重要之分，那么在选择恢复时，我们其实可以用到更多更灵活的方式恢复想要的内容。 即时虚拟机恢复，这是简单粗暴的快速恢复方法。 即时文件级恢复，很巧妙的选择性恢复，这时候根据被感染的文件重要级别，选择想要恢复的文件先对应关键业务，是个很不错的选择。 爆发后，系统维护 紧急业务处理完了，回头要看看那些没中毒的系统，防患于未然，补丁也都出来了，这时候要给这些系统打补丁了，发现打个补丁系统蓝屏了，有没有？上千台 Windows，上千次的打补丁重启，失败率 5%以上有没有？是不是又没准备，然后这些没被“想哭”玩死的系统，反而被微软补丁玩死了？ 打补丁前，不管啥时候，记得这么来： 先做一次备份，确保能够回滚到正常状态。 可以在沙盒中测试下补丁是不是能够正常打上，并且不会影响系统正常工作。同时，还可以在沙盒中测试补丁应用情况，是否还会受病毒攻击。 好了，以上就是本次“想哭”的一些 Tips。 ","date":"2017-05-15","objectID":"/2017/05/wannacry/:0:0","tags":[],"title":"关于“想哭”病毒，我也来两句。","uri":"/2017/05/wannacry/"},{"categories":["Veeam 小工具"],"content":"常常在工作中被问及，你们备份软件，重删效果如何？备份数据占多少空间？其实，就效果而言，这往往会和数据类型以及存放方式直接相关，不同的方式以及不同的设备类型，产生的实际效果差异非常大，因此这个问题说实话是非常难用一句话来回答。但是，无论如何，备份数据是需要磁盘空间进行存储的，在备份项目的设计过程中，必然会有备份存储库的容量设计。通常这个设计会直接关系到用户的存储成本、存储效率以及备份的可用性，因此这个设计在备份项目中非常关键，尽可能准确的设计存储容量和带宽，直接关系到项目的成败。 这里我会以一个典型的虚拟化环境为例来说明应该如何去进行这个计算。 环境信息： ESXi Host ：25 台 VM：500 个 每个 VM 平均磁盘容量：200GB 总 Datastore 使用容量：100TB 带宽设计 通常来说，备份过程中会有全备份和增量备份两种模式，一般情况下，首次备份是全备份，它将传输虚拟化环境中的所有数据至备份存储设备，因此这个传输量几乎为所有的 Datastore 的使用量；而后续的所有传输则是增量备份，传输的是虚拟化环境中的变化量，常见比较多的是每日变化量，本文暂时按照每日作为变化量的单位来计算。 每个环境中，每日的变化量可以根据 Veeam ONE 的变化评估报告获取，是相对准确的数值，我这里假设这个变化量为 7%。所以我们的到以下数值： 首次传输数据量 ： 100TB 每天增量传输数据量：7TB 开启 Veeam 的优化压缩重删后，假设这个重删能够达到常规的效果，实际传输数据为 datastore 容量的 50%： 首次真实传输数据量：50TB 每天真实传输数据量：3.5TB 因此我们需要的带宽计算如下，假设首次传输，我们可以开启周六 24 小时连续传输而后续增量备份则在每天业务空闲时 20:00PM~6:00AM 进行，除去备份作业的基础配置耗时后，我们大约估算实际数据传输时间为总耗时的 80%，也就是 10 小时的备份工作时间内 2 小时为备份基础配置和等待时间，8 小时为实际数据传输时间。因此简单的计算公式示例如下： 全备份需要带宽：5010248/(24360080%)=5.93Gbps 增量备份需要带宽：3.510248/(10360080%)=1Gbps 以上，我们可以看到这样的一个大概状况，那么在网络上和磁盘上的读写吞吐量可以按照这个数据去进行规划，配置相应数量的网卡/HBA 卡以实现以上这样的一个备份吞吐量。 容量设计 根据不同的备份模式，在数据存储无任何重删技术的情况下，这个容量设计是最容易进行计算的，以下将以最常见的常见常规增量备份为例来说明计算方法，这也是一个比较简单的计算题。 至少保留 14 份备份数据，每周执行 1 次全备份，每天进行 1 次增量备份。 格式 天 大小 全备份 1 50 TB 增量 2 3.5TB 增量 3 3.5TB 增量 4 3.5TB 增量 5 3.5TB 增量 6 3.5TB 增量 7 3.5TB 全备份 8 50 TB 增量 9 3.5TB 增量 10 3.5TB 增量 11 3.5TB 增量 12 3.5TB 增量 13 3.5TB 增量 14 3.5TB 全备份 15 50 TB 增量 16 3.5TB 增量 17 3.5TB 增量 18 3.5TB 增量 19 3.5TB 增量 20 3.5TB 总容量估算： 209.5TB +15%缓存剩余容量： 31.4TB 总计预估容量： 240.9TB 这就是常规的备份容量的设计思路，在这里我还有一个非常棒的工具推荐给大家，这是 Veeam 国外的同事制作的 Veeam 备份存储库容量规划工具，在这个工具中有更全面更详细的计算方法，可以根据实际情况输入更多数据来进行计算。这个在线工具地址如下，推荐在电脑上打开会比较好： http://vee.am/rps ","date":"2017-05-05","objectID":"/2017/05/how-to-calculate-backup-size/:0:0","tags":["backup"],"title":"数据中心备份容量和带宽的计算方法","uri":"/2017/05/how-to-calculate-backup-size/"},{"categories":["Veeam 小工具"],"content":"vSphere 和 Hyper-V 都拥有自己的一些迁移技术，而 Veeam 作为一个数据保护软件，从数据保护的角度出发，为 IT 管理员提供了另外一种迁移技术。在 Veeam 软件中，该技术通常叫做 Quick Migration。 熟悉 Veeam 的朋友，可能此时能立刻想到，在 Veeam 进行 Instant VM Recovery 的时候，有一个选项叫做 Quick Migration，这是 Instant VM Recovery 执行过程中的一个可选步骤，当我们需要把数据从备份存储迁移至生产存储时，如果没有 VMware Enterprise Plus 许可时，无法使用高大上的 Storage vMotion 完成这个任务时，又或者在恢复时无 vCenter 可用，仅仅是只有单个 ESXi 节点提供服务时，这时候 Quick Migration 是一个非常好的选择。仅仅是付出比 Storage vMotion 略多些许的停机时间，获得的是更广泛的支持性，不失为一个绝佳的补充方案。 然后，Quick Migration 的用法还远不止这些，我简单来举几个例子： ","date":"2017-04-21","objectID":"/2017/04/veeam-quick-migration/:0:0","tags":["迁移"],"title":"Veeam 黑科技之 Quick Migration","uri":"/2017/04/veeam-quick-migration/"},{"categories":["Veeam 小工具"],"content":"跨 vCenter、Datacenter 的 VM 迁移 这个话题通常会是一个复杂的手工操作，又或者是高大上的一些解决方案，而有了 Veeam 的加入，这一操作变得及其简单，Quick Migration 即可完成，只要有合适的 Proxy 可用，那么 Veeam 就可以去做这样的迁移操作，并且这个迁移操作是不需要借助备份的，也就是说 Veeam 的这个迁移是可以直接进行，而不需要备份或者复制操作作为前提条件的。 这个操作非常简单，Veeam 的界面上有这个按钮，只要按了按照向导即可完成。同样迁移过程中，Veeam 一样支持 Thin/Thick 转换和磁盘重定向等基本操作。 ","date":"2017-04-21","objectID":"/2017/04/veeam-quick-migration/:0:1","tags":["迁移"],"title":"Veeam 黑科技之 Quick Migration","uri":"/2017/04/veeam-quick-migration/"},{"categories":["Veeam 小工具"],"content":"LAN free 迁移 什么？迁移虚拟机还能 LAN free？对的你没看错，Veeam 的 Quick Migration 可以通过合理的架设 Proxy，实现 LAN free。利用 Direct SAN Access 技术，无论是 Fiber Channel 还是 Direct NFS 技术都可以用于 Quick Migration 中，从而避免了 VMKernel 带宽不够用的问题，这个在大容量虚拟机的迁移上，能够帮助有效的控制数据流。 当然，以上这些我们也许可以通过其他的方法或者工具进行类似的实现，只是在此 Veeam 提供了一种更多的选择，让我们手上有更多的工具去完成日常虚拟化数据管理中所面临的挑战。 ","date":"2017-04-21","objectID":"/2017/04/veeam-quick-migration/:0:2","tags":["迁移"],"title":"Veeam 黑科技之 Quick Migration","uri":"/2017/04/veeam-quick-migration/"},{"categories":["数据恢复"],"content":"虚拟机备份后，通常会有很多种恢复方法，分别适用于不同的恢复场景。其中有一种广为使用的方法叫文件级恢复，这种方法并不是什么新技术，早在虚拟化备份刚刚诞生的时候，就有了这样的需求，也很早被各大备份软件厂商所实现。粗看这个技术无任何门槛，然而实际上在真正需要恢复时，Veeam可以帮到很多忙。 我们来看一下这样子的情况，我打开了文件级还原的浏览器，这一般都是由备份软件厂商提供的界面： 我们会发现，这里有一堆的PDF格式的文件，不过好像这些文件是啥我都不知道唉(⊙o⊙)…光看文件名，看不懂是啥，我想在恢复之前，能不能先打开看看咧？万一不对，是不是这个恢复就白做了呢？ 好像这事在备份软件厂商提供的界面上，我们无法完成哎。不过，Veeam FLR有个灰常灰常强大的按钮，请大家看看这里： 这是一个神奇的按钮，当我们点下去这个按钮后，我们竟然这样了： 然后，我发现，这些我无法打开的pdf，我可以在我的本地先打开看看内容，再决定恢复啦~。是不是很棒？ 再来一个，好像zip包，我其实只想恢复zip包内的文件，这时候咋办？ 一样神通广大的这个按钮来干这事 这是一个神奇的按钮，可以为恢复提供无限多想象，各种只有特殊应用程序才能识别的对象，只要预先安装了应用程序，能识别数据格式，这一神奇的按钮，就能帮我们提取对象，恢复内容。数据内容才是我们信息化的核心，任何不关心内容的恢复都是赤裸裸的欺骗，所以，请在恢复之前用一下这个按钮！ ","date":"2017-04-20","objectID":"/2017/04/secret-in-file-level-recovery/:0:0","tags":["恢复"],"title":"文件级恢复的秘密","uri":"/2017/04/secret-in-file-level-recovery/"}]